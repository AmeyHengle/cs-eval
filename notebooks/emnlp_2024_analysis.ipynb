{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n",
      "/home/amey/miniconda3/envs/socionet/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import extract_score, postprocess_llm_pred, postprocess_llm_response\n",
    "import glob\n",
    "tqdm.pandas()\n",
    "import uuid\n",
    "from utils import dashed_line\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def get_aspect_name(pred_col):\n",
    "    if 'aggressiveness' in pred_col.lower():\n",
    "        return 'aggressiveness'\n",
    "    elif 'relevance' in pred_col.lower():\n",
    "        return 'relevance'\n",
    "    elif 'coherence' in pred_col.lower():\n",
    "        return 'coherence'\n",
    "    elif 'suitableness' in pred_col.lower():\n",
    "        return 'suitableness'\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"Invalid column name\"\n",
    "        )\n",
    "    \n",
    "def rename_similar_columns(df, suffix='_dup', similarity_threshold=1.0):\n",
    "    # Create a dictionary to hold the new column names\n",
    "    new_column_names = {}\n",
    "    \n",
    "    # Get a list of existing column names\n",
    "    column_names = df.columns.tolist()\n",
    "    \n",
    "    # Iterate through each column name\n",
    "    for i, col in enumerate(column_names):\n",
    "        # Find close matches for the current column name\n",
    "        close_matches = get_close_matches(col, column_names, n=len(column_names), cutoff=similarity_threshold)\n",
    "        \n",
    "        # If there are close matches, rename them\n",
    "        for match in close_matches:\n",
    "            if match != col:  # Avoid renaming the same column\n",
    "                new_column_name = f\"{match}{suffix}\"\n",
    "                new_column_names[match] = new_column_name\n",
    "    \n",
    "    # Rename the columns in the DataFrame\n",
    "    df.rename(columns=new_column_names, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6526, 69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>suitableness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>aggressiveness_score</th>\n",
       "      <th>annotator</th>\n",
       "      <th>...</th>\n",
       "      <th>zs_Llama-3-8b-chat-hf_suitableness_score</th>\n",
       "      <th>zs_Llama-3-8b-chat-hf_aggressiveness_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_relevance_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_coherence_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_suitableness_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_aggressiveness_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_relevance_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_coherence_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_suitableness_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_aggressiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Jews have no place here. They are not a part o...</td>\n",
       "      <td>Jews are part of most societies, why should we...</td>\n",
       "      <td>Why do you believe that jews are not part of t...</td>\n",
       "      <td>Questioning</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>(amey,osho,apoorv)_mean</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         hatespeech  \\\n",
       "0    0.0  Jews have no place here. They are not a part o...   \n",
       "\n",
       "                                       counterspeech  \\\n",
       "0  Jews are part of most societies, why should we...   \n",
       "\n",
       "                             predicted_counterspeech       csType  \\\n",
       "0  Why do you believe that jews are not part of t...  Questioning   \n",
       "\n",
       "   suitableness_score  relevance_score  coherence_score  aggressiveness_score  \\\n",
       "0            1.666667         3.333333         2.333333              1.666667   \n",
       "\n",
       "                 annotator  ... zs_Llama-3-8b-chat-hf_suitableness_score  \\\n",
       "0  (amey,osho,apoorv)_mean  ...                                      3.0   \n",
       "\n",
       "  zs_Llama-3-8b-chat-hf_aggressiveness_score  \\\n",
       "0                                        1.0   \n",
       "\n",
       "   Mistral-7B-Instruct-v03_relevance_score  \\\n",
       "0                                     -1.0   \n",
       "\n",
       "   Mistral-7B-Instruct-v03_coherence_score  \\\n",
       "0                                     -1.0   \n",
       "\n",
       "   Mistral-7B-Instruct-v03_suitableness_score  \\\n",
       "0                                        -1.0   \n",
       "\n",
       "   Mistral-7B-Instruct-v03_aggressiveness_score  \\\n",
       "0                                          -1.0   \n",
       "\n",
       "   zs_Mistral-7B-Instruct-v03_relevance_score  \\\n",
       "0                                         5.0   \n",
       "\n",
       "   zs_Mistral-7B-Instruct-v03_coherence_score  \\\n",
       "0                                         3.0   \n",
       "\n",
       "   zs_Mistral-7B-Instruct-v03_suitableness_score  \\\n",
       "0                                            3.0   \n",
       "\n",
       "   zs_Mistral-7B-Instruct-v03_aggressiveness_score  \n",
       "0                                              2.0  \n",
       "\n",
       "[1 rows x 69 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anal = pd.read_csv('/home/amey/depository/cs-eval/emnlp_2024_analysis/analysis_metrics_computed.csv')\n",
    "df_anal = df_anal[df_anal['predicted_counterspeech'].notna()]\n",
    "print(df_anal.shape)\n",
    "df_anal.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "automated_metrics = ['bleu_1_(pred_cs, cs)',\n",
    " 'bleu_2_(pred_cs, cs)',\n",
    " 'bleu_3_(pred_cs, cs)',\n",
    " 'bleu_4_(pred_cs, cs)',\n",
    " 'rouge_1_(pred_cs, cs)',\n",
    " 'rouge_2_(pred_cs, cs)',\n",
    " 'rouge_l_(pred_cs, cs)',\n",
    " 'meteor_score_(pred_cs, cs)',\n",
    " 'bert_score_(hs, pred_cs)',\n",
    " 'bert_score_(pred_cs, cs)',\n",
    " 'bm25_score_(hs, pred_cs)',\n",
    " 'bm25_score_(pred_cs, cs)',\n",
    " 'bart_score_(hs, pred_cs)',\n",
    " 'bart_score_(cs, pred_cs)',\n",
    " 'bart_score_(pred_cs, cs)',\n",
    " 'bart_score_(hs, pred_cs)',\n",
    " 'aggressiveness_UniEval',\n",
    " 'coherence_UniEval',\n",
    " 'relevance_UniEval',\n",
    " 'suitableness_UniEval',\n",
    " 'pc_score_(hs, pred_cs)',\n",
    " 'aq_score_(pred_cs)',\n",
    " 'cd_score_(hs, pred_cs)',\n",
    " 'pd_score(hs, pred_cs)',\n",
    " 'negative_pc_score_(hs, pred_cs)',\n",
    " 'toxicity_(pred_cs)',\n",
    " 'obscenity_(pred_cs)',\n",
    " 'identity_attack_(pred_cs)',\n",
    " 'insult_(pred_cs)',\n",
    " 'gpt-4_relevance_score',\n",
    " 'gpt-4_aggressiveness_score',\n",
    " 'gpt-4_coherence_score',\n",
    " 'gpt-4_suitableness_score',\n",
    " 'gpt-4-zs_relevance_score',\n",
    " 'gpt-4-zs_coherence_score',\n",
    " 'gpt-4-zs_aggressiveness_score',\n",
    " 'gpt-4-zs_suitableness_score',\n",
    " 'relevance_score',\n",
    " 'aggressiveness_score',\n",
    " 'coherence_score',\n",
    " 'suitableness_score',\n",
    " 'Llama-3-8b-chat-hf_relevance_score',\n",
    " 'Llama-3-8b-chat-hf_coherence_score',\n",
    " 'Llama-3-8b-chat-hf_suitableness_score',\n",
    " 'Llama-3-8b-chat-hf_aggressiveness_score',\n",
    " 'Llama-3-8b-chat-hf_relevance_score',\n",
    " 'Llama-3-8b-chat-hf_coherence_score',\n",
    " 'Llama-3-8b-chat-hf_suitableness_score',\n",
    " 'Llama-3-8b-chat-hf_aggressiveness_score',\n",
    " 'zs_Llama-3-8b-chat-hf_relevance_score',\n",
    " 'zs_Llama-3-8b-chat-hf_coherence_score',\n",
    " 'zs_Llama-3-8b-chat-hf_suitableness_score',\n",
    " 'zs_Llama-3-8b-chat-hf_aggressiveness_score',\n",
    " 'Mistral-7B-Instruct-v03_relevance_score',\n",
    " 'Mistral-7B-Instruct-v03_coherence_score',\n",
    " 'Mistral-7B-Instruct-v03_suitableness_score',\n",
    " 'Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_relevance_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_coherence_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_suitableness_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_aggressiveness_score']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6526, 69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>suitableness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>aggressiveness_score</th>\n",
       "      <th>annotator</th>\n",
       "      <th>...</th>\n",
       "      <th>zs_Llama-3-8b-chat-hf_suitableness_score</th>\n",
       "      <th>zs_Llama-3-8b-chat-hf_aggressiveness_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_relevance_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_coherence_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_suitableness_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_aggressiveness_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_relevance_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_coherence_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_suitableness_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_aggressiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Jews have no place here. They are not a part o...</td>\n",
       "      <td>Jews are part of most societies, why should we...</td>\n",
       "      <td>Why do you believe that jews are not part of t...</td>\n",
       "      <td>Questioning</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>(amey,osho,apoorv)_mean</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         hatespeech  \\\n",
       "0    0.0  Jews have no place here. They are not a part o...   \n",
       "\n",
       "                                       counterspeech  \\\n",
       "0  Jews are part of most societies, why should we...   \n",
       "\n",
       "                             predicted_counterspeech       csType  \\\n",
       "0  Why do you believe that jews are not part of t...  Questioning   \n",
       "\n",
       "   suitableness_score  relevance_score  coherence_score  aggressiveness_score  \\\n",
       "0            1.666667         3.333333         2.333333              1.666667   \n",
       "\n",
       "                 annotator  ... zs_Llama-3-8b-chat-hf_suitableness_score  \\\n",
       "0  (amey,osho,apoorv)_mean  ...                                      3.0   \n",
       "\n",
       "  zs_Llama-3-8b-chat-hf_aggressiveness_score  \\\n",
       "0                                        1.0   \n",
       "\n",
       "   Mistral-7B-Instruct-v03_relevance_score  \\\n",
       "0                                     -1.0   \n",
       "\n",
       "   Mistral-7B-Instruct-v03_coherence_score  \\\n",
       "0                                     -1.0   \n",
       "\n",
       "   Mistral-7B-Instruct-v03_suitableness_score  \\\n",
       "0                                        -1.0   \n",
       "\n",
       "   Mistral-7B-Instruct-v03_aggressiveness_score  \\\n",
       "0                                          -1.0   \n",
       "\n",
       "   zs_Mistral-7B-Instruct-v03_relevance_score  \\\n",
       "0                                         5.0   \n",
       "\n",
       "   zs_Mistral-7B-Instruct-v03_coherence_score  \\\n",
       "0                                         3.0   \n",
       "\n",
       "   zs_Mistral-7B-Instruct-v03_suitableness_score  \\\n",
       "0                                            3.0   \n",
       "\n",
       "   zs_Mistral-7B-Instruct-v03_aggressiveness_score  \n",
       "0                                              2.0  \n",
       "\n",
       "[1 rows x 69 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anal = pd.read_csv('/home/amey/depository/cs-eval/emnlp_2024_analysis/analysis_metrics_computed.csv')\n",
    "df_anal = df_anal[df_anal['predicted_counterspeech'].notna()]\n",
    "print(df_anal.shape)\n",
    "df_anal.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "automated_metrics = [\n",
    "    'bleu_1_(pred_cs, cs)',\n",
    "    'bleu_2_(pred_cs, cs)', \n",
    "    'bleu_3_(pred_cs, cs)', \n",
    "    'bleu_4_(pred_cs, cs)', \n",
    "    'rouge_1_(pred_cs, cs)', \n",
    "    'rouge_2_(pred_cs, cs)', \n",
    "    'rouge_l_(pred_cs, cs)', \n",
    "    'meteor_score_(pred_cs, cs)', \n",
    "    'bert_score_(hs, pred_cs)', \n",
    "    'bert_score_(pred_cs, cs)', \n",
    "    'bm25_score_(hs, pred_cs)',\n",
    "    'bm25_score_(pred_cs, cs)',\n",
    "    'bart_score_(hs, pred_cs)',\n",
    "    'bart_score_(cs, pred_cs)',\n",
    "    'bart_score_(pred_cs, cs)',\n",
    "    'bart_score_(hs, pred_cs)',\n",
    "    'aggressiveness_UniEval',\n",
    "    'coherence_UniEval',\n",
    "    'relevance_UniEval',\n",
    "    'suitableness_UniEval',\n",
    "    'pc_score_(hs, pred_cs)',\n",
    "    'aq_score_(pred_cs)',\n",
    "    'cd_score_(hs, pred_cs)',\n",
    "    'pd_score(hs, pred_cs)',\n",
    "    'negative_pc_score_(hs, pred_cs)',\n",
    "    'toxicity_(pred_cs)',\n",
    "    'obscenity_(pred_cs)',\n",
    "    'identity_attack_(pred_cs)',\n",
    "    'insult_(pred_cs)',\n",
    "    'gpt-4_relevance_score',\n",
    "    'gpt-4_aggressiveness_score',\n",
    "    'gpt-4_coherence_score',\n",
    "    'gpt-4_suitableness_score',\n",
    "    'gpt-4-zs_relevance_score',\n",
    "    'gpt-4-zs_coherence_score',\n",
    "    'gpt-4-zs_aggressiveness_score',\n",
    "    'gpt-4-zs_suitableness_score',\n",
    "    'relevance_score',\n",
    "    'aggressiveness_score',\n",
    "    'coherence_score',\n",
    "    'suitableness_score',\n",
    "    'Llama-3-8b-chat-hf_relevance_score',\n",
    "    'Llama-3-8b-chat-hf_coherence_score',\n",
    "    'Llama-3-8b-chat-hf_suitableness_score',\n",
    "    'Llama-3-8b-chat-hf_aggressiveness_score',\n",
    "    'Llama-3-8b-chat-hf_relevance_score',\n",
    "    'Llama-3-8b-chat-hf_coherence_score',\n",
    "    'Llama-3-8b-chat-hf_suitableness_score',\n",
    "    'Llama-3-8b-chat-hf_aggressiveness_score',\n",
    "    'zs_Llama-3-8b-chat-hf_relevance_score',\n",
    "    'zs_Llama-3-8b-chat-hf_coherence_score',\n",
    "    'zs_Llama-3-8b-chat-hf_suitableness_score',\n",
    "    'zs_Llama-3-8b-chat-hf_aggressiveness_score',\n",
    "    'Mistral-7B-Instruct-v03_relevance_score',\n",
    "    'Mistral-7B-Instruct-v03_coherence_score',\n",
    "    'Mistral-7B-Instruct-v03_suitableness_score',\n",
    "    'Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    "    'zs_Mistral-7B-Instruct-v03_relevance_score',\n",
    "    'zs_Mistral-7B-Instruct-v03_coherence_score',\n",
    "    'zs_Mistral-7B-Instruct-v03_suitableness_score',\n",
    "    'zs_Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    "    # 'GEVAL-4_relevance_score',\n",
    "    # 'GEVAL-4_coherence_score',\n",
    "    # 'GEVAL-4_aggressiveness_score',\n",
    "    # 'GEVAL-4_suitableness_score',\n",
    "    # 'GPTScore_relevance_score',\n",
    "    # 'GPTScore_coherence_score',\n",
    "    # 'GPTScore_aggressiveness_score',\n",
    "    # 'GPTScore_suitableness_score',\n",
    "]\n",
    "\n",
    "for x in automated_metrics:\n",
    "    if x not in df_anal.columns:\n",
    "        print(x)\n",
    "        print('-'*50)\n",
    "\n",
    "# cols = []\n",
    "# for x in df_anal.columns:\n",
    "#     if x not in automated_metrics:\n",
    "#         cols.append(x)\n",
    "\n",
    "# print(',\\n'.join([f\"'{x}'\" for x in cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bleu_1_(pred_cs, cs)',\n",
       " 'bleu_2_(pred_cs, cs)',\n",
       " 'bleu_3_(pred_cs, cs)',\n",
       " 'bleu_4_(pred_cs, cs)',\n",
       " 'rouge_1_(pred_cs, cs)',\n",
       " 'rouge_2_(pred_cs, cs)',\n",
       " 'rouge_l_(pred_cs, cs)',\n",
       " 'meteor_score_(pred_cs, cs)',\n",
       " 'bert_score_(hs, pred_cs)',\n",
       " 'bert_score_(pred_cs, cs)',\n",
       " 'bm25_score_(hs, pred_cs)',\n",
       " 'bm25_score_(pred_cs, cs)',\n",
       " 'bart_score_(hs, pred_cs)',\n",
       " 'bart_score_(cs, pred_cs)',\n",
       " 'bart_score_(pred_cs, cs)',\n",
       " 'bart_score_(hs, pred_cs)',\n",
       " 'aggressiveness_UniEval',\n",
       " 'coherence_UniEval',\n",
       " 'relevance_UniEval',\n",
       " 'suitableness_UniEval',\n",
       " 'pc_score_(hs, pred_cs)',\n",
       " 'aq_score_(pred_cs)',\n",
       " 'cd_score_(hs, pred_cs)',\n",
       " 'pd_score(hs, pred_cs)',\n",
       " 'negative_pc_score_(hs, pred_cs)',\n",
       " 'toxicity_(pred_cs)',\n",
       " 'obscenity_(pred_cs)',\n",
       " 'identity_attack_(pred_cs)',\n",
       " 'insult_(pred_cs)',\n",
       " 'gpt-4_relevance_score',\n",
       " 'gpt-4_aggressiveness_score',\n",
       " 'gpt-4_coherence_score',\n",
       " 'gpt-4_suitableness_score',\n",
       " 'gpt-4-zs_relevance_score',\n",
       " 'gpt-4-zs_coherence_score',\n",
       " 'gpt-4-zs_aggressiveness_score',\n",
       " 'gpt-4-zs_suitableness_score',\n",
       " 'relevance_score',\n",
       " 'aggressiveness_score',\n",
       " 'coherence_score',\n",
       " 'suitableness_score',\n",
       " 'Llama-3-8b-chat-hf_relevance_score',\n",
       " 'Llama-3-8b-chat-hf_coherence_score',\n",
       " 'Llama-3-8b-chat-hf_suitableness_score',\n",
       " 'Llama-3-8b-chat-hf_aggressiveness_score',\n",
       " 'Llama-3-8b-chat-hf_relevance_score',\n",
       " 'Llama-3-8b-chat-hf_coherence_score',\n",
       " 'Llama-3-8b-chat-hf_suitableness_score',\n",
       " 'Llama-3-8b-chat-hf_aggressiveness_score',\n",
       " 'zs_Llama-3-8b-chat-hf_relevance_score',\n",
       " 'zs_Llama-3-8b-chat-hf_coherence_score',\n",
       " 'zs_Llama-3-8b-chat-hf_suitableness_score',\n",
       " 'zs_Llama-3-8b-chat-hf_aggressiveness_score',\n",
       " 'Mistral-7B-Instruct-v03_relevance_score',\n",
       " 'Mistral-7B-Instruct-v03_coherence_score',\n",
       " 'Mistral-7B-Instruct-v03_suitableness_score',\n",
       " 'Mistral-7B-Instruct-v03_aggressiveness_score',\n",
       " 'zs_Mistral-7B-Instruct-v03_relevance_score',\n",
       " 'zs_Mistral-7B-Instruct-v03_coherence_score',\n",
       " 'zs_Mistral-7B-Instruct-v03_suitableness_score',\n",
       " 'zs_Mistral-7B-Instruct-v03_aggressiveness_score']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in automated_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_cols_llm = [\n",
    "# # 'prediction_gpt-4o_relevance_score',\n",
    "# # 'prediction_gpt-4o_coherence_score',\n",
    "# # 'prediction_gpt-4o_suitableness_score',\n",
    "# # 'prediction_gpt-4o_aggressiveness_score',\n",
    "# # 'prediction_meta-llama/Llama-3-8b-chat-hf_relevance_score',\n",
    "# # 'prediction_meta-llama/Llama-3-8b-chat-hf_coherence_score',\n",
    "# # 'prediction_meta-llama/Llama-3-8b-chat-hf_suitableness_score',\n",
    "# # 'prediction_meta-llama/Llama-3-8b-chat-hf_aggressiveness_score',\n",
    "# # 'zeroshot_prediction_meta-llama/Llama-3-8b-chat-hf_suitableness_score',\n",
    "# # 'zeroshot_prediction_meta-llama/Llama-3-8b-chat-hf_relevance_score',\n",
    "# # 'zeroshot_prediction_meta-llama/Llama-3-8b-chat-hf_coherence_score',\n",
    "# # 'zeroshot_prediction_meta-llama/Llama-3-8b-chat-hf_aggressiveness_score',\n",
    "# # 'zeroshot_prediction_mistralai/Mistral-7B-Instruct-v0.3_relevance_score',\n",
    "# # 'zeroshot_prediction_mistralai/Mistral-7B-Instruct-v0.3_coherence_score',\n",
    "# # 'zeroshot_prediction_mistralai/Mistral-7B-Instruct-v0.3_suitableness_score',\n",
    "# # 'zeroshot_prediction_mistralai/Mistral-7B-Instruct-v0.3_aggressiveness_score'\n",
    "# ]\n",
    "\n",
    "# for col in pred_cols_llm:\n",
    "#     print(col)\n",
    "#     print(df_anal[col].value_counts().items)\n",
    "#     print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_cols_llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rename_dict \u001b[38;5;241m=\u001b[39m {x:x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpred_cols_llm\u001b[49m}\n\u001b[1;32m      2\u001b[0m rename_dict\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_cols_llm' is not defined"
     ]
    }
   ],
   "source": [
    "rename_dict = {x:x for x in pred_cols_llm}\n",
    "rename_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Llama-3_relevance_score', 'Llama-3_coherence_score', 'Llama-3_suitableness_score', 'Llama-3_aggressiveness_score', 'Llama-3-zs_suitableness_score', 'Llama-3-zs_relevance_score', 'Llama-3-zs_coherence_score', 'Llama-3-zs_aggressiveness_score', 'Mistral-zs_relevance_score', 'Mistral-zs_coherence_score', 'Mistral-zs_suitableness_score', 'Mistral-zs_aggressiveness_score']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>suitableness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>aggressiveness_score</th>\n",
       "      <th>...</th>\n",
       "      <th>identity_attack_(pred_cs)</th>\n",
       "      <th>insult_(pred_cs)</th>\n",
       "      <th>uuid</th>\n",
       "      <th>bart_score_(pred_cs, cs)</th>\n",
       "      <th>bart_score_(cs, pred_cs)</th>\n",
       "      <th>bart_score_(hs, pred_cs)</th>\n",
       "      <th>coherence_UniEval</th>\n",
       "      <th>relevance_UniEval</th>\n",
       "      <th>aggressiveness_UniEval</th>\n",
       "      <th>suitableness_UniEval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jews have no place here. They are not a part o...</td>\n",
       "      <td>Jews are part of most societies, why should we...</td>\n",
       "      <td>Why do you believe that jews are not part of t...</td>\n",
       "      <td>Questioning</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>91761985-3ea5-482d-b20f-d855df5909d0</td>\n",
       "      <td>-3.372657</td>\n",
       "      <td>-2.945376</td>\n",
       "      <td>-2.892705</td>\n",
       "      <td>0.92566</td>\n",
       "      <td>0.931815</td>\n",
       "      <td>0.921574</td>\n",
       "      <td>0.920361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                                         hatespeech  \\\n",
       "0        0    0.0  Jews have no place here. They are not a part o...   \n",
       "\n",
       "                                       counterspeech  \\\n",
       "0  Jews are part of most societies, why should we...   \n",
       "\n",
       "                             predicted_counterspeech       csType  \\\n",
       "0  Why do you believe that jews are not part of t...  Questioning   \n",
       "\n",
       "   suitableness_score  relevance_score  coherence_score  aggressiveness_score  \\\n",
       "0            1.666667         3.333333         2.333333              1.666667   \n",
       "\n",
       "   ... identity_attack_(pred_cs) insult_(pred_cs)  \\\n",
       "0  ...                  0.026416         0.001635   \n",
       "\n",
       "                                   uuid bart_score_(pred_cs, cs)  \\\n",
       "0  91761985-3ea5-482d-b20f-d855df5909d0                -3.372657   \n",
       "\n",
       "  bart_score_(cs, pred_cs) bart_score_(hs, pred_cs) coherence_UniEval  \\\n",
       "0                -2.945376                -2.892705           0.92566   \n",
       "\n",
       "  relevance_UniEval  aggressiveness_UniEval  suitableness_UniEval  \n",
       "0          0.931815                0.921574              0.920361  \n",
       "\n",
       "[1 rows x 96 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_dict = {\n",
    "'prediction_meta-llama/Llama-3-8b-chat-hf_relevance_score': 'Llama-3_relevance_score',\n",
    " 'prediction_meta-llama/Llama-3-8b-chat-hf_coherence_score': 'Llama-3_coherence_score',\n",
    " 'prediction_meta-llama/Llama-3-8b-chat-hf_suitableness_score': 'Llama-3_suitableness_score',\n",
    " 'prediction_meta-llama/Llama-3-8b-chat-hf_aggressiveness_score': 'Llama-3_aggressiveness_score',\n",
    " 'zeroshot_prediction_meta-llama/Llama-3-8b-chat-hf_suitableness_score': 'Llama-3-zs_suitableness_score',\n",
    " 'zeroshot_prediction_meta-llama/Llama-3-8b-chat-hf_relevance_score': 'Llama-3-zs_relevance_score',\n",
    " 'zeroshot_prediction_meta-llama/Llama-3-8b-chat-hf_coherence_score': 'Llama-3-zs_coherence_score',\n",
    " 'zeroshot_prediction_meta-llama/Llama-3-8b-chat-hf_aggressiveness_score': 'Llama-3-zs_aggressiveness_score',\n",
    " 'zeroshot_prediction_mistralai/Mistral-7B-Instruct-v0.3_relevance_score': 'Mistral-zs_relevance_score',\n",
    " 'zeroshot_prediction_mistralai/Mistral-7B-Instruct-v0.3_coherence_score': 'Mistral-zs_coherence_score',\n",
    " 'zeroshot_prediction_mistralai/Mistral-7B-Instruct-v0.3_suitableness_score': 'Mistral-zs_suitableness_score',\n",
    " 'zeroshot_prediction_mistralai/Mistral-7B-Instruct-v0.3_aggressiveness_score': 'Mistral-zs_aggressiveness_score'\n",
    "}\n",
    "\n",
    "pred_cols_llm = list(rename_dict.values())\n",
    "print(list(rename_dict.values()))\n",
    "automated_metrics.extend(list(rename_dict.values()))\n",
    "\n",
    "df_anal = df_anal.rename(\n",
    "    columns=rename_dict\n",
    ")\n",
    "\n",
    "df_anal.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table1 - Correlation between metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, kendalltau\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_correlations_with_scaling(df, col1, col2):\n",
    "    \"\"\"\n",
    "    Calculate Spearman's rho and Kendall's tau for two columns in a DataFrame after scaling.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame containing the data.\n",
    "    - col1: str, name of the first column.\n",
    "    - col2: str, name of the second column.\n",
    "\n",
    "    Returns:\n",
    "    - spearman_rho: Spearman's rho coefficient after scaling.\n",
    "    - kendall_tau: Kendall's tau coefficient after scaling.\n",
    "    \"\"\"\n",
    "    df[col1] = df[col1].apply(lambda x: 3 if x == -1 else x)\n",
    "    df[col2] = df[col2].apply(lambda x: 3 if x == -1 else x)\n",
    "    \"\"\"\n",
    "    # Initialize the MinMaxScaler to scale between -1 and 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    # Scale the specified columns\n",
    "    scaled_values = scaler.fit_transform(df[[col1, col2]])\n",
    "    \n",
    "    # Update the DataFrame with the scaled values\n",
    "    # df_scaled = df\n",
    "    df_scaled = pd.DataFrame(scaled_values, columns=[col1, col2])\n",
    "    \n",
    "    # Calculate Spearman's rho on the scaled data\n",
    "    spearman_rho, spearman_p_value = spearmanr(df_scaled[col1], df_scaled[col2])\n",
    "    \n",
    "    # Calculate Kendall's tau on the scaled data\n",
    "    kendall_tau, kendall_p_value = kendalltau(df_scaled[col1], df_scaled[col2])\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.array(df[col1].values.tolist())\n",
    "    y = np.array(df[col2].values.tolist())\n",
    "    x = minmax_scale(x)\n",
    "    y = minmax_scale(y)   \n",
    "    \n",
    "    spearman_rho = stats.spearmanr(x,y).statistic\n",
    "    kendall_tau = stats.kendalltau(x,y).statistic\n",
    "    \n",
    "    # print(spearman_rho, kendall_tau)\n",
    "\n",
    "    return spearman_rho, kendall_tau\n",
    "\n",
    "\n",
    "def calculate_correlation_matrices(df, automated_metrics, human_ratings):\n",
    "    \"\"\"\n",
    "    Calculate Spearman's rho and Kendall's tau matrices for multiple automated metrics against human ratings.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame containing the data.\n",
    "    - automated_metrics: list of str, names of the automated metric columns.\n",
    "    - human_ratings: list of str, names of the human rating columns.\n",
    "\n",
    "    Returns:\n",
    "    - spearman_df: DataFrame containing Spearman's rho values.\n",
    "    - kendall_df: DataFrame containing Kendall's tau values.\n",
    "    \"\"\"\n",
    "    spearman_results = []\n",
    "    kendall_results = []\n",
    "    \n",
    "    # Iterate over each combination of automated metric and human rating\n",
    "    for metric in automated_metrics:\n",
    "        spearman_row = []\n",
    "        kendall_row = []\n",
    "        for rating in human_ratings:\n",
    "            # spearman_rho, _ = spearmanr(df[metric], df[rating])\n",
    "            # kendall_tau, _ = kendalltau(df[metric], df[rating])\n",
    "            spearman_rho, kendall_tau = calculate_correlations_with_scaling(df, metric, rating)\n",
    "            # print(spearman_rho, kendall_tau)\n",
    "            spearman_row.append(spearman_rho)\n",
    "            kendall_row.append(kendall_tau)\n",
    "        \n",
    "        spearman_results.append(spearman_row)\n",
    "        kendall_results.append(kendall_row)\n",
    "        \n",
    "    # Convert the results to DataFrames\n",
    "    spearman_df = pd.DataFrame(spearman_results, index=automated_metrics, columns=human_ratings)\n",
    "    kendall_df = pd.DataFrame(kendall_results, index=automated_metrics, columns=human_ratings)\n",
    "    \n",
    "    return spearman_df, kendall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6526, 81)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>suitableness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>aggressiveness_score</th>\n",
       "      <th>annotator</th>\n",
       "      <th>...</th>\n",
       "      <th>GEVAL_Llama-3-8b-chat-hf_aggressiveness_score</th>\n",
       "      <th>GEVAL_gpt-4_coherence_score</th>\n",
       "      <th>GEVAL_Llama-3-8b-chat-hf_coherence_score</th>\n",
       "      <th>GEVAL_Mistral-7B-Instruct-v03_coherence_score</th>\n",
       "      <th>GEVAL_gpt-4_relevance_score</th>\n",
       "      <th>GEVAL_Llama-3-8b-chat-hf_relevance_score</th>\n",
       "      <th>GEVAL_Mistral-7B-Instruct-v03_relevance_score</th>\n",
       "      <th>GEVAL_gpt-4_suitableness_score</th>\n",
       "      <th>GEVAL_Mistral-7B-Instruct-v03_suitableness_score</th>\n",
       "      <th>GEVAL_Llama-3-8b-chat-hf_suitableness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Jews have no place here. They are not a part o...</td>\n",
       "      <td>Jews are part of most societies, why should we...</td>\n",
       "      <td>Why do you believe that jews are not part of t...</td>\n",
       "      <td>Questioning</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>(amey,osho,apoorv)_mean</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Islam is a destructive and violent religion.</td>\n",
       "      <td>It is important to approach religious discussi...</td>\n",
       "      <td>I understand that you may have concerns about ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(amey,osho,apoorv)_mean</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Muslims are all terrorists, they have nothing ...</td>\n",
       "      <td>There is no evidence to suggest that terrorist...</td>\n",
       "      <td>It is important to recognize that terrorism is...</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(amey,osho,apoorv)_mean</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         hatespeech  \\\n",
       "0    0.0  Jews have no place here. They are not a part o...   \n",
       "1    1.0       Islam is a destructive and violent religion.   \n",
       "2    2.0  Muslims are all terrorists, they have nothing ...   \n",
       "\n",
       "                                       counterspeech  \\\n",
       "0  Jews are part of most societies, why should we...   \n",
       "1  It is important to approach religious discussi...   \n",
       "2  There is no evidence to suggest that terrorist...   \n",
       "\n",
       "                             predicted_counterspeech       csType  \\\n",
       "0  Why do you believe that jews are not part of t...  Questioning   \n",
       "1  I understand that you may have concerns about ...     Positive   \n",
       "2  It is important to recognize that terrorism is...   Denouncing   \n",
       "\n",
       "   suitableness_score  relevance_score  coherence_score  aggressiveness_score  \\\n",
       "0            1.666667         3.333333         2.333333              1.666667   \n",
       "1            2.333333         3.666667         4.333333              1.000000   \n",
       "2            2.666667         3.333333         3.333333              1.000000   \n",
       "\n",
       "                 annotator  ... GEVAL_Llama-3-8b-chat-hf_aggressiveness_score  \\\n",
       "0  (amey,osho,apoorv)_mean  ...                                           1.0   \n",
       "1  (amey,osho,apoorv)_mean  ...                                           2.0   \n",
       "2  (amey,osho,apoorv)_mean  ...                                           1.0   \n",
       "\n",
       "  GEVAL_gpt-4_coherence_score  GEVAL_Llama-3-8b-chat-hf_coherence_score  \\\n",
       "0                         1.0                                       4.0   \n",
       "1                         3.0                                       4.0   \n",
       "2                         3.0                                       4.0   \n",
       "\n",
       "   GEVAL_Mistral-7B-Instruct-v03_coherence_score  GEVAL_gpt-4_relevance_score  \\\n",
       "0                                            3.0                          5.0   \n",
       "1                                            4.0                          5.0   \n",
       "2                                            5.0                          5.0   \n",
       "\n",
       "   GEVAL_Llama-3-8b-chat-hf_relevance_score  \\\n",
       "0                                       4.0   \n",
       "1                                       5.0   \n",
       "2                                       4.0   \n",
       "\n",
       "   GEVAL_Mistral-7B-Instruct-v03_relevance_score  \\\n",
       "0                                            4.0   \n",
       "1                                            5.0   \n",
       "2                                            5.0   \n",
       "\n",
       "   GEVAL_gpt-4_suitableness_score  \\\n",
       "0                             3.0   \n",
       "1                             2.0   \n",
       "2                             3.0   \n",
       "\n",
       "   GEVAL_Mistral-7B-Instruct-v03_suitableness_score  \\\n",
       "0                                               2.0   \n",
       "1                                               3.0   \n",
       "2                                               3.0   \n",
       "\n",
       "   GEVAL_Llama-3-8b-chat-hf_suitableness_score  \n",
       "0                                          2.0  \n",
       "1                                          3.0  \n",
       "2                                          2.0  \n",
       "\n",
       "[3 rows x 81 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = '/home/amey/depository/cs-eval/emnlp_2024_analysis/analysis_metrics_computed_refurbished.csv'\n",
    "df_anal = pd.read_csv(dataset_path)\n",
    "print(df_anal.shape)\n",
    "df_anal.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_anal.to_csv('/home/amey/depository/cs-eval/emnlp_2024_analysis/analysis_metrics_computed_refurbished.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "traditional_metrics = [\n",
    "'bleu_1_(pred_cs, cs)',\n",
    " 'bleu_2_(pred_cs, cs)',\n",
    " 'bleu_3_(pred_cs, cs)',\n",
    " 'bleu_4_(pred_cs, cs)',\n",
    " 'rouge_1_(pred_cs, cs)',\n",
    " 'rouge_2_(pred_cs, cs)',\n",
    " 'rouge_l_(pred_cs, cs)',\n",
    " 'meteor_score_(pred_cs, cs)',\n",
    "#  'bert_score_(hs, pred_cs)',\n",
    " 'bert_score_(pred_cs, cs)',\n",
    "#  'bart_score_(hs, pred_cs)',\n",
    "#  'bart_score_(cs, pred_cs)',\n",
    "#  'bart_score_(hs, pred_cs)',\n",
    " 'pc_score_(hs, pred_cs)',\n",
    " 'aq_score_(pred_cs)',\n",
    "#  'cd_score_(hs, pred_cs)',\n",
    " 'pd_score(hs, pred_cs)',\n",
    "#  'negative_pc_score_(hs, pred_cs)',\n",
    " 'toxicity_(pred_cs)',\n",
    "#  'obscenity_(pred_cs)',\n",
    "#  'identity_attack_(pred_cs)',\n",
    "#  'insult_(pred_cs)'\n",
    " 'bart_score_(pred_cs, cs)',\n",
    "]\n",
    "\n",
    "unieval_cols = [\n",
    "    'aggressiveness_UniEval',\n",
    "    'coherence_UniEval',\n",
    "    'relevance_UniEval',\n",
    "    'suitableness_UniEval',\n",
    "]\n",
    "\n",
    "prediction_cols = [\n",
    "\n",
    " 'gpt-4-zs_relevance_score',\n",
    " 'gpt-4-zs_coherence_score',\n",
    " 'gpt-4-zs_aggressiveness_score',\n",
    " 'gpt-4-zs_suitableness_score',\n",
    " 'zs_Llama-3-8b-chat-hf_relevance_score',\n",
    " 'zs_Llama-3-8b-chat-hf_coherence_score',\n",
    " 'zs_Llama-3-8b-chat-hf_suitableness_score',\n",
    " 'zs_Llama-3-8b-chat-hf_aggressiveness_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_relevance_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_coherence_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_suitableness_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    " 'GEVAL_gpt-4_aggressiveness_score',\n",
    "  'GEVAL_gpt-4_coherence_score',\n",
    "  'GEVAL_gpt-4_relevance_score',\n",
    "  'GEVAL_gpt-4_suitableness_score',\n",
    " 'GEVAL_Llama-3-8b-chat-hf_aggressiveness_score',\n",
    " 'GEVAL_Llama-3-8b-chat-hf_coherence_score',\n",
    " 'GEVAL_Llama-3-8b-chat-hf_relevance_score',\n",
    " 'GEVAL_Llama-3-8b-chat-hf_suitableness_score',\n",
    " 'GEVAL_Mistral-7B-Instruct-v03_coherence_score',\n",
    " 'GEVAL_Mistral-7B-Instruct-v03_relevance_score',\n",
    " 'GEVAL_Mistral-7B-Instruct-v03_suitableness_score',\n",
    " 'GEVAL_Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    " 'Llama-3-8b-chat-hf_relevance_score',\n",
    " 'Llama-3-8b-chat-hf_coherence_score',\n",
    " 'Llama-3-8b-chat-hf_suitableness_score',\n",
    " 'Llama-3-8b-chat-hf_aggressiveness_score',\n",
    " 'Mistral-7B-Instruct-v03_relevance_score',\n",
    " 'Mistral-7B-Instruct-v03_coherence_score',\n",
    " 'Mistral-7B-Instruct-v03_suitableness_score',\n",
    " 'Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    " 'gpt-4_relevance_score',\n",
    " 'gpt-4_aggressiveness_score',\n",
    " 'gpt-4_coherence_score',\n",
    " 'gpt-4_suitableness_score'\n",
    " ]\n",
    "\n",
    "human_ratings = ['relevance_score', 'aggressiveness_score', 'coherence_score', 'suitableness_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_anal['gpt-4-zs_aggressiveness_score_reversed'] = df_anal['gpt-4-zs_aggressiveness_score'].apply(lambda x: 5-x)\n",
    "# df_anal = df_anal[df_anal.annotator != '(amey,osho,apoorv)_mean'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_name = 'suitableness_score'\n",
    "y_pred_cols = [col for col in prediction_cols if aspect_name in col or f'{aspect_name}_UniEval' in col]\n",
    "y_true_cols = [col for col in human_ratings if aspect_name in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automated_metrics = pred_cols_llm\n",
    "# spearman_df, kendall_df = calculate_correlation_matrices(df_anal, y_pred_cols, y_true_cols)\n",
    "# spearman_df, kendall_df = calculate_correlation_matrices(df_anal, prediction_cols, human_ratings)\n",
    "# spearman_df, kendall_df = calculate_correlation_matrices(df_anal, [x for x in y_pred_cols if 'Llama' in x], [x for x in y_pred_cols if 'Llama' in x])\n",
    "# spearman_df, kendall_df = calculate_correlation_matrices(df_anal, y_pred_cols + y_true_cols, y_pred_cols)\n",
    "# spearman_df, kendall_df = calculate_correlation_matrices(df_anal, traditional_metrics + y_pred_cols, y_true_cols)\n",
    "spearman_df, kendall_df = calculate_correlation_matrices(df_anal, unieval_cols, human_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>aggressiveness_score</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>suitableness_score</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aggressiveness_UniEval</th>\n",
       "      <td>0.180438</td>\n",
       "      <td>0.034082</td>\n",
       "      <td>0.130518</td>\n",
       "      <td>0.203661</td>\n",
       "      <td>aggressiveness_UniEval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coherence_UniEval</th>\n",
       "      <td>0.181532</td>\n",
       "      <td>-0.045066</td>\n",
       "      <td>0.175622</td>\n",
       "      <td>0.198070</td>\n",
       "      <td>coherence_UniEval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance_UniEval</th>\n",
       "      <td>0.196517</td>\n",
       "      <td>-0.055376</td>\n",
       "      <td>0.185655</td>\n",
       "      <td>0.208016</td>\n",
       "      <td>relevance_UniEval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suitableness_UniEval</th>\n",
       "      <td>0.204487</td>\n",
       "      <td>-0.047551</td>\n",
       "      <td>0.193047</td>\n",
       "      <td>0.212462</td>\n",
       "      <td>suitableness_UniEval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        relevance_score  aggressiveness_score  \\\n",
       "metric                                                          \n",
       "aggressiveness_UniEval         0.180438              0.034082   \n",
       "coherence_UniEval              0.181532             -0.045066   \n",
       "relevance_UniEval              0.196517             -0.055376   \n",
       "suitableness_UniEval           0.204487             -0.047551   \n",
       "\n",
       "                        coherence_score  suitableness_score  \\\n",
       "metric                                                        \n",
       "aggressiveness_UniEval         0.130518            0.203661   \n",
       "coherence_UniEval              0.175622            0.198070   \n",
       "relevance_UniEval              0.185655            0.208016   \n",
       "suitableness_UniEval           0.193047            0.212462   \n",
       "\n",
       "                                        metric  \n",
       "metric                                          \n",
       "aggressiveness_UniEval  aggressiveness_UniEval  \n",
       "coherence_UniEval            coherence_UniEval  \n",
       "relevance_UniEval            relevance_UniEval  \n",
       "suitableness_UniEval      suitableness_UniEval  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearman_df, kendall_df = calculate_correlation_matrices(df_anal, unieval_cols, human_ratings)\n",
    "spearman_df = spearman_df.rename_axis('metric')\n",
    "spearman_df['metric'] = spearman_df.index\n",
    "spearman_df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aggressiveness_UniEval', 'coherence_UniEval', 'relevance_UniEval',\n",
       "       'suitableness_UniEval'],\n",
       "      dtype='object', name='metric')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearman_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spearman_df.to_csv(f'/home/amey/depository/cs-eval/results/spearman_{aspect_name}.csv', index=False)\n",
    "spearman_df.to_csv(f'/home/amey/depository/cs-eval/results/spearman_unieval.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kendal Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>aggressiveness_score</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>suitableness_score</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aggressiveness_UniEval</th>\n",
       "      <td>0.131509</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>0.092708</td>\n",
       "      <td>0.152532</td>\n",
       "      <td>aggressiveness_UniEval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coherence_UniEval</th>\n",
       "      <td>0.131973</td>\n",
       "      <td>-0.034409</td>\n",
       "      <td>0.127004</td>\n",
       "      <td>0.147499</td>\n",
       "      <td>coherence_UniEval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance_UniEval</th>\n",
       "      <td>0.142907</td>\n",
       "      <td>-0.042309</td>\n",
       "      <td>0.134498</td>\n",
       "      <td>0.154863</td>\n",
       "      <td>relevance_UniEval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suitableness_UniEval</th>\n",
       "      <td>0.148751</td>\n",
       "      <td>-0.036423</td>\n",
       "      <td>0.139487</td>\n",
       "      <td>0.158593</td>\n",
       "      <td>suitableness_UniEval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        relevance_score  aggressiveness_score  \\\n",
       "aggressiveness_UniEval         0.131509              0.024440   \n",
       "coherence_UniEval              0.131973             -0.034409   \n",
       "relevance_UniEval              0.142907             -0.042309   \n",
       "suitableness_UniEval           0.148751             -0.036423   \n",
       "\n",
       "                        coherence_score  suitableness_score  \\\n",
       "aggressiveness_UniEval         0.092708            0.152532   \n",
       "coherence_UniEval              0.127004            0.147499   \n",
       "relevance_UniEval              0.134498            0.154863   \n",
       "suitableness_UniEval           0.139487            0.158593   \n",
       "\n",
       "                                        metric  \n",
       "aggressiveness_UniEval  aggressiveness_UniEval  \n",
       "coherence_UniEval            coherence_UniEval  \n",
       "relevance_UniEval            relevance_UniEval  \n",
       "suitableness_UniEval      suitableness_UniEval  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_df['metric'] = kendall_df.index\n",
    "kendall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kendall_df.to_csv(f'/home/amey/depository/cs-eval/results/kendalltau_{aspect_name}.csv', index=False)\n",
    "kendall_df.to_csv(f'/home/amey/depository/cs-eval/results/kendalltau_unieval.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table2 - System level ranking accuracy / NDCG score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>islam only a religion of per just wrong. peace...</td>\n",
       "      <td>GPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   hatespeech      csType  \\\n",
       "0  Above all Islam is a religion of conquest.  Denouncing   \n",
       "\n",
       "                                       counterspeech  \\\n",
       "0  No, islam is a religion of 1.6 billion people ...   \n",
       "\n",
       "                             predicted_counterspeech source  \n",
       "0  islam only a religion of per just wrong. peace...    GPS  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_eval = pd.read_csv('/home/amey/depository/cs-eval/data/annotations/human_eval.csv')\n",
    "print(df_human_eval.shape)\n",
    "df_human_eval.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human_eval = df_human_eval[df_human_eval.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_141295/824629732.py:1: DtypeWarning: Columns (6,7,41,42,43,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('//home/amey/NLG-metrics/annotations_final_for_gods_sake.csv_metrics_calculated.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>source</th>\n",
       "      <th>prediction_(prompt_aggressiveness_score)_(gpt-4)</th>\n",
       "      <th>prediction_(prompt_relevance_score)_(gpt-4)</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prediction_(prompt_aggressiveness_score)_(gpt3.5-turbo)</th>\n",
       "      <th>...</th>\n",
       "      <th>GEVAL-4_relevance_score</th>\n",
       "      <th>GEVAL-4_coherence_score</th>\n",
       "      <th>GEVAL-4_aggressiveness_score</th>\n",
       "      <th>GEVAL-4_suitableness_score</th>\n",
       "      <th>GPTScore_relevance_score</th>\n",
       "      <th>GPTScore_coherence_score</th>\n",
       "      <th>GPTScore_aggressiveness_score</th>\n",
       "      <th>GPTScore_suitableness_score</th>\n",
       "      <th>bleu_3_(pred_cs, cs)</th>\n",
       "      <th>bleu_4_(pred_cs, cs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Minorities vote to strip wealth and power from...</td>\n",
       "      <td>This is incorrect. jews could never be able to...</td>\n",
       "      <td>People's right to vote is not determined by ra...</td>\n",
       "      <td>Informative</td>\n",
       "      <td>dialoGPT</td>\n",
       "      <td>{ \\n'Aggressiveness': '1'\\n}</td>\n",
       "      <td>{ \\n'Relevance': '5'\\n}</td>\n",
       "      <td>16229ec9-79d2-4b81-86aa-7a81335584b2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.001259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0                                         hatespeech  \\\n",
       "0        3  Minorities vote to strip wealth and power from...   \n",
       "\n",
       "                                       counterspeech  \\\n",
       "0  This is incorrect. jews could never be able to...   \n",
       "\n",
       "                             predicted_counterspeech       csType    source  \\\n",
       "0  People's right to vote is not determined by ra...  Informative  dialoGPT   \n",
       "\n",
       "  prediction_(prompt_aggressiveness_score)_(gpt-4)  \\\n",
       "0                     { \\n'Aggressiveness': '1'\\n}   \n",
       "\n",
       "  prediction_(prompt_relevance_score)_(gpt-4)  \\\n",
       "0                     { \\n'Relevance': '5'\\n}   \n",
       "\n",
       "                                   uuid  \\\n",
       "0  16229ec9-79d2-4b81-86aa-7a81335584b2   \n",
       "\n",
       "  prediction_(prompt_aggressiveness_score)_(gpt3.5-turbo)  ...  \\\n",
       "0                                                NaN       ...   \n",
       "\n",
       "  GEVAL-4_relevance_score GEVAL-4_coherence_score  \\\n",
       "0                       5                     2.0   \n",
       "\n",
       "  GEVAL-4_aggressiveness_score  GEVAL-4_suitableness_score  \\\n",
       "0                            1                           3   \n",
       "\n",
       "   GPTScore_relevance_score  GPTScore_coherence_score  \\\n",
       "0                         5                       1.0   \n",
       "\n",
       "   GPTScore_aggressiveness_score  GPTScore_suitableness_score  \\\n",
       "0                              2                            2   \n",
       "\n",
       "   bleu_3_(pred_cs, cs)  bleu_4_(pred_cs, cs)  \n",
       "0               0.00249              0.001259  \n",
       "\n",
       "[1 rows x 74 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('//home/amey/NLG-metrics/annotations_final_for_gods_sake.csv_metrics_calculated.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>source</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>islam only a religion of per just wrong. peace...</td>\n",
       "      <td>GPS</td>\n",
       "      <td>944ec738-ee5e-40d6-8493-93c1eb8b403e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Is it fair to judge an entire religious group ...</td>\n",
       "      <td>QUARC</td>\n",
       "      <td>b0e53c71-0567-4052-971c-d777b9fcdc1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>I must strongly denounce your offensive statem...</td>\n",
       "      <td>GPT3.5_ZS</td>\n",
       "      <td>b0449292-e5b5-4e0a-b36e-8eaabc0d3915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Generalizing about Muslims based on the action...</td>\n",
       "      <td>GPT3.5_FS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Stereotyping Muslims based on the actions of a...</td>\n",
       "      <td>dialoGPT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>immigrants dont belong here they are the sourc...</td>\n",
       "      <td>Informative</td>\n",
       "      <td>You can't blame immigrants for all the problem...</td>\n",
       "      <td>There is no such thing as a mongrelisation of ...</td>\n",
       "      <td>GPS</td>\n",
       "      <td>b700bfe8-1962-4f35-bdbd-eb21cdd0132d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>immigrants dont belong here they are the sourc...</td>\n",
       "      <td>Informative</td>\n",
       "      <td>You can't blame immigrants for all the problem...</td>\n",
       "      <td>Many immigrants come here seeking a better lif...</td>\n",
       "      <td>QUARC</td>\n",
       "      <td>6fbe44d4-0dcc-49bd-bec1-8a2f77724311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>immigrants dont belong here they are the sourc...</td>\n",
       "      <td>Informative</td>\n",
       "      <td>You can't blame immigrants for all the problem...</td>\n",
       "      <td>Actually, immigrants contribute significantly ...</td>\n",
       "      <td>dialoGPT</td>\n",
       "      <td>f1fecffd-f101-47fd-8ced-1c90ab9bb2d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>immigrants dont belong here they are the sourc...</td>\n",
       "      <td>Informative</td>\n",
       "      <td>You can't blame immigrants for all the problem...</td>\n",
       "      <td>I understand that you may have concerns about ...</td>\n",
       "      <td>GPT3.5_ZS</td>\n",
       "      <td>bca91e41-aa95-436b-bcc3-1f6c0760124b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>immigrants dont belong here they are the sourc...</td>\n",
       "      <td>Informative</td>\n",
       "      <td>You can't blame immigrants for all the problem...</td>\n",
       "      <td>I understand that you may have concerns about ...</td>\n",
       "      <td>GPT3.5_FS</td>\n",
       "      <td>f9ae7b99-e905-46d3-8ed2-98caf5d4f072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            hatespeech       csType  \\\n",
       "0           Above all Islam is a religion of conquest.   Denouncing   \n",
       "1           Above all Islam is a religion of conquest.   Denouncing   \n",
       "2           Above all Islam is a religion of conquest.   Denouncing   \n",
       "3           Above all Islam is a religion of conquest.   Denouncing   \n",
       "4           Above all Islam is a religion of conquest.   Denouncing   \n",
       "..                                                 ...          ...   \n",
       "305  immigrants dont belong here they are the sourc...  Informative   \n",
       "306  immigrants dont belong here they are the sourc...  Informative   \n",
       "307  immigrants dont belong here they are the sourc...  Informative   \n",
       "308  immigrants dont belong here they are the sourc...  Informative   \n",
       "309  immigrants dont belong here they are the sourc...  Informative   \n",
       "\n",
       "                                         counterspeech  \\\n",
       "0    No, islam is a religion of 1.6 billion people ...   \n",
       "1    No, islam is a religion of 1.6 billion people ...   \n",
       "2    No, islam is a religion of 1.6 billion people ...   \n",
       "3    No, islam is a religion of 1.6 billion people ...   \n",
       "4    No, islam is a religion of 1.6 billion people ...   \n",
       "..                                                 ...   \n",
       "305  You can't blame immigrants for all the problem...   \n",
       "306  You can't blame immigrants for all the problem...   \n",
       "307  You can't blame immigrants for all the problem...   \n",
       "308  You can't blame immigrants for all the problem...   \n",
       "309  You can't blame immigrants for all the problem...   \n",
       "\n",
       "                               predicted_counterspeech     source  \\\n",
       "0    islam only a religion of per just wrong. peace...        GPS   \n",
       "1    Is it fair to judge an entire religious group ...      QUARC   \n",
       "2    I must strongly denounce your offensive statem...  GPT3.5_ZS   \n",
       "3    Generalizing about Muslims based on the action...  GPT3.5_FS   \n",
       "4    Stereotyping Muslims based on the actions of a...   dialoGPT   \n",
       "..                                                 ...        ...   \n",
       "305  There is no such thing as a mongrelisation of ...        GPS   \n",
       "306  Many immigrants come here seeking a better lif...      QUARC   \n",
       "307  Actually, immigrants contribute significantly ...   dialoGPT   \n",
       "308  I understand that you may have concerns about ...  GPT3.5_ZS   \n",
       "309  I understand that you may have concerns about ...  GPT3.5_FS   \n",
       "\n",
       "                                     uuid  \n",
       "0    944ec738-ee5e-40d6-8493-93c1eb8b403e  \n",
       "1    b0e53c71-0567-4052-971c-d777b9fcdc1a  \n",
       "2    b0449292-e5b5-4e0a-b36e-8eaabc0d3915  \n",
       "3                                     NaN  \n",
       "4                                     NaN  \n",
       "..                                    ...  \n",
       "305  b700bfe8-1962-4f35-bdbd-eb21cdd0132d  \n",
       "306  6fbe44d4-0dcc-49bd-bec1-8a2f77724311  \n",
       "307  f1fecffd-f101-47fd-8ced-1c90ab9bb2d9  \n",
       "308  bca91e41-aa95-436b-bcc3-1f6c0760124b  \n",
       "309  f9ae7b99-e905-46d3-8ed2-98caf5d4f072  \n",
       "\n",
       "[310 rows x 6 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = df_human_eval.merge(df, on=['hatespeech','csType','counterspeech','predicted_counterspeech','source'])\n",
    "# assert df_.shape[0] == df_human_eval.shape[0]\n",
    "df_[['hatespeech','csType','counterspeech','predicted_counterspeech','source','uuid']]\n",
    "\n",
    "# for i in range(df_human_eval.shape[0]):\n",
    "#     match = df[\n",
    "#         (df['hatespeech'] == df_human_eval.iloc[i]['hatespeech']) &\n",
    "#         (df['csType'] == df_human_eval.iloc[i]['csType']) &\n",
    "#         (df['counterspeech'] == df_human_eval.iloc[i]['counterspeech']) &\n",
    "#         (df['predicted_counterspeech'] == df_human_eval.iloc[i]['predicted_counterspeech']) &\n",
    "#         (df['source'] == df_human_eval.iloc[i]['source'])\n",
    "#     ]\n",
    "#     # assert match.shape[0] == 1\n",
    "#     if match.shape[0] < 1:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['uuid'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_[['hatespeech','csType','counterspeech','predicted_counterspeech','source','uuid']].to_csv('/home/amey/depository/cs-eval/data/annotations/human_eval_formatted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_human_eval['predicted_counterspeech'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hatespeech                  0\n",
       "csType                      0\n",
       "counterspeech               0\n",
       "predicted_counterspeech     0\n",
       "source                      0\n",
       "uuid                       49\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_[['hatespeech','csType','counterspeech','predicted_counterspeech','source','uuid']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table3 - Human EVAL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_human_annotation = pd.read_csv('/home/amey/depository/cs-eval/data/annotations/Human Evaluation - EMNLP 2024 - annotations (1).csv')\n",
    "# df_human_annotation.shape\n",
    "# # df_human_annotation['Rank'].isna().sum()\n",
    "# df_human_annotation = df_human_annotation[df_human_annotation['Rank'].notna()]\n",
    "# df_human_annotation = df_human_annotation.rename(columns={'Rank': 'rank_human_annotation'})\n",
    "# df_human_annotation.head(6)\n",
    "# assert df_human_annotation.shape[0] == 310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 2.0, 1.0, 4.0, 3.0]  --  [5.0, 4.0, 1.0, 2.0, 3.0]  --  [3, 5, 4, 2, 1]\n",
      "[3.0, 4.0, 2.0, 5.0, 1.0]  --  [4.0, 2.0, 1.0, 5.0, 3.0]  --  [3, 5, 2, 1, 4]\n",
      "[4.0, 1.0, 2.0, 3.0, 5.0]  --  [4.0, 1.0, 2.0, 3.0, 5.0]  --  [2, 3, 4, 1, 5]\n",
      "[5.0, 4.0, 3.0, 1.0, 2.0]  --  [5.0, 4.0, 2.0, 1.0, 3.0]  --  [4, 5, 3, 2, 1]\n",
      "[2.0, 1.0, 3.0, 5.0, 4.0]  --  [2.0, 1.0, 3.0, 5.0, 4.0]  --  [2, 1, 3, 5, 4]\n",
      "[5.0, 5.0, 3.0, 1.0, 2.0]  --  [4.0, 5.0, 3.0, 2.0, 1.0]  --  [5, 4, 3, 1, 2]\n",
      "[5.0, 5.0, 5.0, 5.0, 5.0]  --  [5.0, 1.0, 5.0, 5.0, 5.0]  --  [2, 5, 4, 3, 1]\n",
      "[1.0, 4.0, 5.0, 3.0, 2.0]  --  [1.0, 4.0, 5.0, 2.0, 3.0]  --  [1, 5, 4, 2, 3]\n",
      "[4.0, 5.0, 1.0, 3.0, 2.0]  --  [1.0, 5.0, 2.0, 4.0, 3.0]  --  [3, 5, 1, 4, 2]\n",
      "[2.0, 5.0, 4.0, 3.0, 1.0]  --  [3.0, 5.0, 4.0, 2.0, 1.0]  --  [5, 4, 1, 3, 2]\n",
      "[3.0, 2.0, 5.0, 4.0, 1.0]  --  [3.0, 2.0, 5.0, 4.0, 1.0]  --  [5, 2, 1, 4, 3]\n",
      "[3.0, 2.0, 5.0, 4.0, 1.0]  --  [1.0, 3.0, 5.0, 4.0, 2.0]  --  [5, 1, 2, 4, 3]\n",
      "[5.0, 3.0, 4.0, 2.0, 1.0]  --  [4.0, 3.0, 5.0, 1.0, 2.0]  --  [5, 4, 2, 3, 1]\n",
      "[1.0, 2.0, 5.0, 4.0, 3.0]  --  [1.0, 2.0, 4.0, 5.0, 3.0]  --  [1, 2, 5, 4, 3]\n",
      "[5.0, 2.0, 3.0, 1.0, 4.0]  --  [5.0, 4.0, 3.0, 1.0, 2.0]  --  [4, 5, 3, 2, 1]\n",
      "[5.0, 2.0, 3.0, 1.0, 4.0]  --  [5.0, 2.0, 1.0, 3.0, 4.0]  --  [4, 3, 2, 5, 1]\n",
      "[1.0, 3.0, 5.0, 4.0, 2.0]  --  [1.0, 3.0, 5.0, 4.0, 2.0]  --  [1, 5, 2, 4, 3]\n",
      "[4.0, 2.0, 3.0, 5.0, 1.0]  --  [3.0, 1.0, 5.0, 4.0, 2.0]  --  [5, 2, 1, 3, 4]\n",
      "[2.0, 5.0, 4.0, 1.0, 3.0]  --  [5.0, 3.0, 4.0, 1.0, 2.0]  --  [4, 5, 1, 3, 2]\n",
      "[5.0, 1.0, 4.0, 2.0, 3.0]  --  [5.0, 2.0, 3.0, 4.0, 1.0]  --  [2, 5, 4, 3, 1]\n",
      "[4.0, 1.0, 5.0, 2.0, 3.0]  --  [1.0, 2.0, 4.0, 3.0, 5.0]  --  [2, 4, 1, 5, 3]\n",
      "[5.0, 4.0, 1.0, 2.0, 3.0]  --  [5.0, 3.0, 1.0, 2.0, 4.0]  --  [3, 4, 5, 2, 1]\n",
      "[1.0, 3.0, 5.0, 2.0, 4.0]  --  [1.0, 4.0, 5.0, 3.0, 2.0]  --  [1, 4, 5, 2, 3]\n",
      "[1.0, 2.0, 5.0, 4.0, 3.0]  --  [1.0, 2.0, 4.0, 5.0, 3.0]  --  [1, 2, 5, 4, 3]\n",
      "[4.0, 1.0, 5.0, 3.0, 2.0]  --  [4.0, 1.0, 5.0, 3.0, 2.0]  --  [2, 5, 4, 1, 3]\n",
      "[3.0, 5.0, 4.0, 2.0, 1.0]  --  [1.0, 5.0, 4.0, 3.0, 2.0]  --  [5, 1, 4, 3, 2]\n",
      "[4.0, 5.0, 3.0, 1.0, 2.0]  --  [4.0, 3.0, 5.0, 1.0, 2.0]  --  [4, 5, 3, 2, 1]\n",
      "[3.0, 5.0, 4.0, 1.0, 2.0]  --  [1.0, 5.0, 4.0, 2.0, 3.0]  --  [4, 1, 5, 3, 2]\n",
      "[4.0, 3.0, 1.0, 5.0, 2.0]  --  [4.0, 3.0, 1.0, 5.0, 2.0]  --  [3, 5, 2, 1, 4]\n",
      "[3.0, 5.0, 4.0, 1.0, 2.0]  --  [5.0, 4.0, 3.0, 1.0, 2.0]  --  [4, 5, 3, 1, 2]\n",
      "[5.0, 1.0, 4.0, 3.0, 2.0]  --  [4.0, 2.0, 5.0, 3.0, 1.0]  --  [5, 2, 4, 3, 1]\n",
      "[4.0, 1.0, 3.0, 5.0, 2.0]  --  [4.0, 3.0, 1.0, 5.0, 2.0]  --  [5, 3, 2, 1, 4]\n",
      "[5.0, 3.0, 2.0, 4.0, 1.0]  --  [5.0, 4.0, 3.0, 2.0, 1.0]  --  [5, 3, 4, 2, 1]\n",
      "[5.0, 4.0, 1.0, 2.0, 3.0]  --  [5.0, 1.0, 2.0, 3.0, 4.0]  --  [3, 4, 2, 5, 1]\n",
      "[1.0, 2.0, 5.0, 4.0, 3.0]  --  [1.0, 2.0, 4.0, 5.0, 3.0]  --  [1, 2, 5, 4, 3]\n",
      "[3.0, 5.0, 4.0, 2.0, 1.0]  --  [1.0, 5.0, 4.0, 3.0, 2.0]  --  [5, 1, 4, 3, 2]\n",
      "[5.0, 1.0, 3.0, 4.0, 2.0]  --  [5.0, 2.0, 1.0, 4.0, 3.0]  --  [2, 3, 5, 4, 1]\n",
      "[5.0, 4.0, 3.0, 2.0, 1.0]  --  [5.0, 1.0, 4.0, 2.0, 3.0]  --  [5, 4, 2, 3, 1]\n",
      "[5.0, 4.0, 3.0, 2.0, 1.0]  --  [5.0, 1.0, 4.0, 2.0, 3.0]  --  [5, 4, 2, 3, 1]\n",
      "[5.0, 3.0, 4.0, 1.0, 2.0]  --  [4.0, 3.0, 5.0, 1.0, 2.0]  --  [4, 5, 2, 3, 1]\n",
      "[3.0, 5.0, 4.0, 1.0, 2.0]  --  [2.0, 5.0, 4.0, 3.0, 1.0]  --  [5, 4, 1, 3, 2]\n",
      "[1.0, 5.0, 2.0, 3.0, 4.0]  --  [1.0, 5.0, 4.0, 2.0, 3.0]  --  [1, 4, 3, 5, 2]\n",
      "[1.0, 5.0, 3.0, 2.0, 4.0]  --  [3.0, 5.0, 4.0, 1.0, 2.0]  --  [4, 1, 5, 3, 2]\n",
      "[4.0, 5.0, 1.0, 3.0, 2.0]  --  [1.0, 5.0, 2.0, 3.0, 4.0]  --  [3, 1, 5, 4, 2]\n",
      "[3.0, 4.0, 5.0, 2.0, 1.0]  --  [3.0, 5.0, 4.0, 1.0, 2.0]  --  [5, 4, 1, 3, 2]\n",
      "[4.0, 5.0, 3.0, 2.0, 1.0]  --  [5.0, 1.0, 4.0, 2.0, 3.0]  --  [5, 4, 2, 3, 1]\n",
      "[5.0, 2.0, 3.0, 4.0, 1.0]  --  [5.0, 3.0, 4.0, 1.0, 2.0]  --  [5, 4, 2, 3, 1]\n",
      "[5.0, 3.0, 1.0, 2.0, 4.0]  --  [5.0, 1.0, 5.0, 5.0, 5.0]  --  [2, 3, 4, 5, 1]\n",
      "[2.0, 5.0, 1.0, 4.0, 3.0]  --  [3.0, 5.0, 4.0, 2.0, 1.0]  --  [5, 3, 1, 4, 2]\n",
      "[3.0, 4.0, 5.0, 2.0, 1.0]  --  [3.0, 2.0, 5.0, 4.0, 1.0]  --  [5, 4, 2, 1, 3]\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0]  --  [2.0, 1.0, 3.0, 4.0, 5.0]  --  [2, 1, 3, 4, 5]\n",
      "[4.0, 2.0, 1.0, 3.0, 5.0]  --  [1.0, 5.0, 5.0, 5.0, 5.0]  --  [1, 3, 2, 4, 5]\n",
      "[4.0, 5.0, 1.0, 2.0, 3.0]  --  [2.0, 5.0, 3.0, 4.0, 1.0]  --  [5, 3, 4, 1, 2]\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0]  --  [1.0, 4.0, 3.0, 5.0, 2.0]  --  [1, 3, 2, 5, 4]\n",
      "[5.0, 4.0, 3.0, 2.0, 1.0]  --  [5.0, 4.0, 2.0, 1.0, 3.0]  --  [4, 5, 3, 2, 1]\n",
      "[5.0, 3.0, 1.0, 2.0, 4.0]  --  [4.0, 5.0, 3.0, 1.0, 2.0]  --  [4, 3, 5, 2, 1]\n",
      "[1.0, 5.0, 3.0, 2.0, 4.0]  --  [1.0, 3.0, 2.0, 4.0, 5.0]  --  [1, 3, 4, 2, 5]\n",
      "[1.0, 3.0, 2.0, 4.0, 5.0]  --  [2.0, 1.0, 3.0, 4.0, 5.0]  --  [1, 2, 3, 4, 5]\n",
      "[1.0, 4.0, 5.0, 3.0, 2.0]  --  [2.0, 4.0, 5.0, 1.0, 3.0]  --  [1, 4, 5, 2, 3]\n",
      "[5.0, 1.0, 4.0, 3.0, 2.0]  --  [5.0, 2.0, 3.0, 1.0, 4.0]  --  [2, 4, 5, 3, 1]\n",
      "[2.0, 5.0, 4.0, 1.0, 3.0]  --  [3.0, 5.0, 4.0, 1.0, 2.0]  --  [4, 5, 1, 3, 2]\n",
      "[4.0, 5.0, 2.0, 3.0, 1.0]  --  [5.0, 4.0, 3.0, 1.0, 2.0]  --  [5, 4, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "def combine_rankings(rankings_a, rankings_b):\n",
    "    # Convert ranks to scores\n",
    "    scores_a = [5 - rank + 1 for rank in rankings_a]\n",
    "    scores_b = [5 - rank + 1 for rank in rankings_b]\n",
    "\n",
    "    # Calculate the average score for each item\n",
    "    average_scores = [(score_a + score_b) / 2 for score_a, score_b in zip(scores_a, scores_b)]\n",
    "\n",
    "    # Rank the items based on the average scores\n",
    "    final_ranks = sorted(((score, rank) for rank, score in enumerate(average_scores)), reverse=True)\n",
    "    final_ranks = [rank + 1 for score, rank in final_ranks]\n",
    "\n",
    "    return final_ranks\n",
    "\n",
    "df_human_annotation1 = pd.read_csv('/home/amey/depository/cs-eval/data/human_eval/Human Evaluation - EMNLP 2024 - annotations_amey.csv')\n",
    "df_human_annotation1.shape\n",
    "# df_human_annotation1['Rank'].isna().sum()\n",
    "df_human_annotation1 = df_human_annotation1[df_human_annotation1['Rank'].notna()]\n",
    "df_human_annotation1 = df_human_annotation1.rename(columns={'Rank': 'rank_human_annotation'})\n",
    "df_human_annotation1.head(6)\n",
    "assert df_human_annotation1.shape[0] == 310\n",
    "\n",
    "df_human_annotation2 = pd.read_csv('/home/amey/depository/cs-eval/data/human_eval/Human Evaluation - EMNLP 2024 - annotations_kanupriya.csv')\n",
    "df_human_annotation2.shape\n",
    "# df_human_annotation2['Rank'].isna().sum()\n",
    "df_human_annotation2 = df_human_annotation2[df_human_annotation2['Rank'].notna()]\n",
    "df_human_annotation2 = df_human_annotation2.rename(columns={'Rank': 'rank_human_annotation'})\n",
    "df_human_annotation2.head(6)\n",
    "assert df_human_annotation2.shape[0] == 310\n",
    "\n",
    "combined_rankings = []\n",
    "\n",
    "# Assuming df1 and df2 are your dataframes\n",
    "for i in range(0, len(df_human_annotation1), 5):\n",
    "    df1_batch = df_human_annotation1.iloc[i:i+5]['rank_human_annotation'].values.tolist()\n",
    "    df2_batch = df_human_annotation2.iloc[i:i+5]['rank_human_annotation'].values.tolist()\n",
    "    # Process df1_batch and df2_batch here\n",
    "    final_ranks = combine_rankings(df1_batch, df2_batch)\n",
    "    combined_rankings.extend(final_ranks)\n",
    "    print(df1_batch, ' -- ', df2_batch, ' -- ', final_ranks)\n",
    "\n",
    "df_human_annotation = df_human_annotation2\n",
    "df_human_annotation['rank_human_annotation'] = combined_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human_annotation.head(1)\n",
    "df_human_annotation = df_human_annotation1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistralai-Mistral-7B-Instruct-v0.3_zeroshot\n",
      "gpt-4o\n",
      "meta-llama-Llama-3-8b-chat-hf\n",
      "mistralai-Mistral-7B-Instruct-v0.3\n",
      "meta-llama-Llama-3-8b-chat-hf_zeroshot\n",
      "gpt-4o_zeroshot\n",
      "(310, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>source</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_relevance</th>\n",
       "      <th>prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_coherence</th>\n",
       "      <th>prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_suitableness</th>\n",
       "      <th>...</th>\n",
       "      <th>prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_relevance</th>\n",
       "      <th>prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_coherence</th>\n",
       "      <th>prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_suitableness</th>\n",
       "      <th>prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_aggressiveness</th>\n",
       "      <th>prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_avg_score</th>\n",
       "      <th>prediction_gpt-4o_zeroshot_relevance</th>\n",
       "      <th>prediction_gpt-4o_zeroshot_aggressiveness</th>\n",
       "      <th>prediction_gpt-4o_zeroshot_coherence</th>\n",
       "      <th>prediction_gpt-4o_zeroshot_suitableness</th>\n",
       "      <th>prediction_gpt-4o_zeroshot_avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>islam only a religion of per just wrong. peace...</td>\n",
       "      <td>GPS</td>\n",
       "      <td>944ec738-ee5e-40d6-8493-93c1eb8b403e</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Is it fair to judge an entire religious group ...</td>\n",
       "      <td>QUARC</td>\n",
       "      <td>b0e53c71-0567-4052-971c-d777b9fcdc1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>I must strongly denounce your offensive statem...</td>\n",
       "      <td>GPT3.5_ZS</td>\n",
       "      <td>b0449292-e5b5-4e0a-b36e-8eaabc0d3915</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Generalizing about Muslims based on the action...</td>\n",
       "      <td>GPT3.5_FS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Stereotyping Muslims based on the actions of a...</td>\n",
       "      <td>dialoGPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>All Muslims should be deported.</td>\n",
       "      <td>Informative</td>\n",
       "      <td>Islam does not pose a security risk to this co...</td>\n",
       "      <td>Actually, muslims have made significant contri...</td>\n",
       "      <td>dialoGPT</td>\n",
       "      <td>1b6f2c1c-e29d-4939-8f93-f22e3285abaa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>All Muslims should be deported.</td>\n",
       "      <td>Informative</td>\n",
       "      <td>Islam does not pose a security risk to this co...</td>\n",
       "      <td>This statement is not supported by factual inf...</td>\n",
       "      <td>QUARC</td>\n",
       "      <td>5076747c-d132-41bf-988c-05655d259fbd</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>All Muslims should be deported.</td>\n",
       "      <td>Informative</td>\n",
       "      <td>Islam does not pose a security risk to this co...</td>\n",
       "      <td>The statement that All Muslims should be depor...</td>\n",
       "      <td>GPT3.5_ZS</td>\n",
       "      <td>485bf5cf-789a-48bc-bf21-7ed68ef426cd</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>All Muslims should be deported.</td>\n",
       "      <td>Informative</td>\n",
       "      <td>Islam does not pose a security risk to this co...</td>\n",
       "      <td>please not rid of oppressing muslims. muslims ...</td>\n",
       "      <td>GPS</td>\n",
       "      <td>b3acb94b-9019-45a7-9c4d-725b3184e684</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>All Muslims should be deported.</td>\n",
       "      <td>Informative</td>\n",
       "      <td>Islam does not pose a security risk to this co...</td>\n",
       "      <td>I understand that you may have concerns about ...</td>\n",
       "      <td>GPT3.5_FS</td>\n",
       "      <td>9cb2d8a6-6548-4adf-a4c2-e2eb1ff1e335</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                  hatespeech       csType  \\\n",
       "0      0  Above all Islam is a religion of conquest.   Denouncing   \n",
       "1      1  Above all Islam is a religion of conquest.   Denouncing   \n",
       "2      2  Above all Islam is a religion of conquest.   Denouncing   \n",
       "3      3  Above all Islam is a religion of conquest.   Denouncing   \n",
       "4      4  Above all Islam is a religion of conquest.   Denouncing   \n",
       "5      5             All Muslims should be deported.  Informative   \n",
       "6      6             All Muslims should be deported.  Informative   \n",
       "7      7             All Muslims should be deported.  Informative   \n",
       "8      8             All Muslims should be deported.  Informative   \n",
       "9      9             All Muslims should be deported.  Informative   \n",
       "\n",
       "                                       counterspeech  \\\n",
       "0  No, islam is a religion of 1.6 billion people ...   \n",
       "1  No, islam is a religion of 1.6 billion people ...   \n",
       "2  No, islam is a religion of 1.6 billion people ...   \n",
       "3  No, islam is a religion of 1.6 billion people ...   \n",
       "4  No, islam is a religion of 1.6 billion people ...   \n",
       "5  Islam does not pose a security risk to this co...   \n",
       "6  Islam does not pose a security risk to this co...   \n",
       "7  Islam does not pose a security risk to this co...   \n",
       "8  Islam does not pose a security risk to this co...   \n",
       "9  Islam does not pose a security risk to this co...   \n",
       "\n",
       "                             predicted_counterspeech     source  \\\n",
       "0  islam only a religion of per just wrong. peace...        GPS   \n",
       "1  Is it fair to judge an entire religious group ...      QUARC   \n",
       "2  I must strongly denounce your offensive statem...  GPT3.5_ZS   \n",
       "3  Generalizing about Muslims based on the action...  GPT3.5_FS   \n",
       "4  Stereotyping Muslims based on the actions of a...   dialoGPT   \n",
       "5  Actually, muslims have made significant contri...   dialoGPT   \n",
       "6  This statement is not supported by factual inf...      QUARC   \n",
       "7  The statement that All Muslims should be depor...  GPT3.5_ZS   \n",
       "8  please not rid of oppressing muslims. muslims ...        GPS   \n",
       "9  I understand that you may have concerns about ...  GPT3.5_FS   \n",
       "\n",
       "                                   uuid  \\\n",
       "0  944ec738-ee5e-40d6-8493-93c1eb8b403e   \n",
       "1  b0e53c71-0567-4052-971c-d777b9fcdc1a   \n",
       "2  b0449292-e5b5-4e0a-b36e-8eaabc0d3915   \n",
       "3                                   NaN   \n",
       "4                                   NaN   \n",
       "5  1b6f2c1c-e29d-4939-8f93-f22e3285abaa   \n",
       "6  5076747c-d132-41bf-988c-05655d259fbd   \n",
       "7  485bf5cf-789a-48bc-bf21-7ed68ef426cd   \n",
       "8  b3acb94b-9019-45a7-9c4d-725b3184e684   \n",
       "9  9cb2d8a6-6548-4adf-a4c2-e2eb1ff1e335   \n",
       "\n",
       "   prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_relevance  \\\n",
       "0                                                2.0                  \n",
       "1                                                4.0                  \n",
       "2                                                5.0                  \n",
       "3                                                4.0                  \n",
       "4                                                4.0                  \n",
       "5                                                5.0                  \n",
       "6                                                5.0                  \n",
       "7                                                5.0                  \n",
       "8                                                4.0                  \n",
       "9                                                5.0                  \n",
       "\n",
       "   prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_coherence  \\\n",
       "0                                                2.0                  \n",
       "1                                                5.0                  \n",
       "2                                                5.0                  \n",
       "3                                                5.0                  \n",
       "4                                                4.0                  \n",
       "5                                                5.0                  \n",
       "6                                                4.0                  \n",
       "7                                                5.0                  \n",
       "8                                                2.0                  \n",
       "9                                                5.0                  \n",
       "\n",
       "   prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_suitableness  ...  \\\n",
       "0                                                1.0                    ...   \n",
       "1                                                3.0                    ...   \n",
       "2                                                3.0                    ...   \n",
       "3                                                3.0                    ...   \n",
       "4                                                3.0                    ...   \n",
       "5                                                3.0                    ...   \n",
       "6                                                3.0                    ...   \n",
       "7                                                3.0                    ...   \n",
       "8                                                2.0                    ...   \n",
       "9                                                3.0                    ...   \n",
       "\n",
       "   prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_relevance  \\\n",
       "0                                                2.0             \n",
       "1                                                4.0             \n",
       "2                                                5.0             \n",
       "3                                                4.0             \n",
       "4                                                4.0             \n",
       "5                                                5.0             \n",
       "6                                                4.0             \n",
       "7                                                5.0             \n",
       "8                                                1.0             \n",
       "9                                                5.0             \n",
       "\n",
       "   prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_coherence  \\\n",
       "0                                                2.0             \n",
       "1                                                4.0             \n",
       "2                                                4.0             \n",
       "3                                                4.0             \n",
       "4                                                3.0             \n",
       "5                                                4.0             \n",
       "6                                                3.0             \n",
       "7                                                4.0             \n",
       "8                                                1.0             \n",
       "9                                                4.0             \n",
       "\n",
       "   prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_suitableness  \\\n",
       "0                                                2.0                \n",
       "1                                                2.0                \n",
       "2                                                2.0                \n",
       "3                                                3.0                \n",
       "4                                                3.0                \n",
       "5                                                2.0                \n",
       "6                                                2.0                \n",
       "7                                                2.0                \n",
       "8                                               -1.0                \n",
       "9                                                2.0                \n",
       "\n",
       "   prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_aggressiveness  \\\n",
       "0                                                2.0                  \n",
       "1                                                1.0                  \n",
       "2                                                2.0                  \n",
       "3                                                1.0                  \n",
       "4                                                1.0                  \n",
       "5                                                1.0                  \n",
       "6                                                1.0                  \n",
       "7                                                2.0                  \n",
       "8                                                5.0                  \n",
       "9                                                2.0                  \n",
       "\n",
       "   prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_avg_score  \\\n",
       "0                                           0.500000             \n",
       "1                                           0.777778             \n",
       "2                                           0.777778             \n",
       "3                                           0.833333             \n",
       "4                                           0.777778             \n",
       "5                                           0.833333             \n",
       "6                                           0.722222             \n",
       "7                                           0.777778             \n",
       "8                                           0.055556             \n",
       "9                                           0.777778             \n",
       "\n",
       "   prediction_gpt-4o_zeroshot_relevance  \\\n",
       "0                                   2.0   \n",
       "1                                   5.0   \n",
       "2                                   5.0   \n",
       "3                                   5.0   \n",
       "4                                   5.0   \n",
       "5                                   5.0   \n",
       "6                                   5.0   \n",
       "7                                   5.0   \n",
       "8                                   1.0   \n",
       "9                                   5.0   \n",
       "\n",
       "   prediction_gpt-4o_zeroshot_aggressiveness  \\\n",
       "0                                        2.0   \n",
       "1                                        1.0   \n",
       "2                                        1.0   \n",
       "3                                        1.0   \n",
       "4                                        1.0   \n",
       "5                                        1.0   \n",
       "6                                        1.0   \n",
       "7                                        1.0   \n",
       "8                                        4.0   \n",
       "9                                        1.0   \n",
       "\n",
       "   prediction_gpt-4o_zeroshot_coherence  \\\n",
       "0                                   1.0   \n",
       "1                                   4.0   \n",
       "2                                   5.0   \n",
       "3                                   5.0   \n",
       "4                                   4.0   \n",
       "5                                   5.0   \n",
       "6                                   3.0   \n",
       "7                                   5.0   \n",
       "8                                   1.0   \n",
       "9                                   5.0   \n",
       "\n",
       "   prediction_gpt-4o_zeroshot_suitableness  \\\n",
       "0                                      2.0   \n",
       "1                                      2.0   \n",
       "2                                      3.0   \n",
       "3                                      3.0   \n",
       "4                                      3.0   \n",
       "5                                      3.0   \n",
       "6                                      3.0   \n",
       "7                                      3.0   \n",
       "8                                     -1.0   \n",
       "9                                      3.0   \n",
       "\n",
       "   prediction_gpt-4o_zeroshot_avg_score  \n",
       "0                              0.444444  \n",
       "1                              0.833333  \n",
       "2                              0.944444  \n",
       "3                              0.944444  \n",
       "4                              0.888889  \n",
       "5                              0.944444  \n",
       "6                              0.833333  \n",
       "7                              0.944444  \n",
       "8                              0.111111  \n",
       "9                              0.944444  \n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_dir = '/home/amey/depository/cs-eval/predictions/human_eval/*.csv'\n",
    "main_cols = ['hatespeech', 'csType', 'counterspeech', 'predicted_counterspeech', 'source', 'uuid']\n",
    "\n",
    "df_analysis = pd.DataFrame()\n",
    "\n",
    "for filename in glob.glob(predictions_dir):\n",
    "    model_name = filename.split('/')[-1].replace('.csv','')\n",
    "    print(model_name)\n",
    "    df_pred = pd.DataFrame()\n",
    "    df_pred = pd.read_csv(filename)\n",
    "    df_pred = df_pred.reset_index()\n",
    "    pred_cols = [x for x in df_pred.columns if 'prediction_' in x and '_cleaned' in x]\n",
    "    assert len(pred_cols) == 4\n",
    "    assert df_pred.shape[0] == 310\n",
    "\n",
    "    df_pred[f'prediction_{model_name}_avg_score'] = [0]*df_pred.shape[0]\n",
    "\n",
    "    for i in range(len(pred_cols)):\n",
    "        pred_col = pred_cols[i]\n",
    "        aspect_name = get_aspect_name(pred_col)\n",
    "        assert df_pred[pred_col].isna().sum() == 0\n",
    "        df_pred.rename(columns = {\n",
    "            pred_col: f\"prediction_{model_name}_{aspect_name}\"\n",
    "        }, inplace=True)\n",
    "        pred_cols[i] = f\"prediction_{model_name}_{aspect_name}\"\n",
    "        df_pred[f'prediction_{model_name}_avg_score'] += df_pred[f\"prediction_{model_name}_{aspect_name}\"] if aspect_name != 'aggressiveness' else (5 - df_pred[f\"prediction_{model_name}_{aspect_name}\"])\n",
    "    \n",
    "    # Compute avg scores\n",
    "    df_pred[f'prediction_{model_name}_avg_score'] = df_pred[f'prediction_{model_name}_avg_score'] / 18\n",
    "    df_pred = df_pred[main_cols + pred_cols + [f'prediction_{model_name}_avg_score']]\n",
    "\n",
    "    if df_analysis.shape[0] == 0:\n",
    "        df_analysis = df_pred\n",
    "    else:\n",
    "        df_pred = df_pred[pred_cols + [f'prediction_{model_name}_avg_score']]\n",
    "        df_analysis = pd.concat((df_analysis, df_pred), axis=1)\n",
    "        assert df_analysis.shape[0] == 310\n",
    "\n",
    "df_analysis = df_analysis.reset_index()\n",
    "print(df_analysis.shape)\n",
    "df_analysis.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_avg_score',\n",
       " 'prediction_gpt-4o_avg_score',\n",
       " 'prediction_meta-llama-Llama-3-8b-chat-hf_avg_score',\n",
       " 'prediction_mistralai-Mistral-7B-Instruct-v0.3_avg_score',\n",
       " 'prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_avg_score',\n",
       " 'prediction_gpt-4o_zeroshot_avg_score']"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggressiveness_cols = [x for x in df_analysis.columns if 'prediction_' in x and 'aggressiveness' in x]\n",
    "relevance_cols = [x for x in df_analysis.columns if 'prediction_' in x and 'relevance' in x]\n",
    "coherence_cols = [x for x in df_analysis.columns if 'prediction_' in x and 'coherence' in x]\n",
    "suitableness_cols = [x for x in df_analysis.columns if 'prediction_' in x and 'suitableness' in x]\n",
    "avg_scores_cols = [x for x in df_analysis.columns if 'prediction_' in x and 'avg' in x]\n",
    "\n",
    "avg_scores_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_avg_score</th>\n",
       "      <th>prediction_gpt-4o_avg_score</th>\n",
       "      <th>prediction_meta-llama-Llama-3-8b-chat-hf_avg_score</th>\n",
       "      <th>prediction_mistralai-Mistral-7B-Instruct-v0.3_avg_score</th>\n",
       "      <th>prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_avg_score</th>\n",
       "      <th>prediction_gpt-4o_zeroshot_avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_avg_score  \\\n",
       "0                                           0.388889                  \n",
       "\n",
       "   prediction_gpt-4o_avg_score  \\\n",
       "0                     0.388889   \n",
       "\n",
       "   prediction_meta-llama-Llama-3-8b-chat-hf_avg_score  \\\n",
       "0                                                0.5    \n",
       "\n",
       "   prediction_mistralai-Mistral-7B-Instruct-v0.3_avg_score  \\\n",
       "0                                           0.444444         \n",
       "\n",
       "   prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_avg_score  \\\n",
       "0                                                0.5             \n",
       "\n",
       "   prediction_gpt-4o_zeroshot_avg_score  \n",
       "0                              0.444444  "
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis[avg_scores_cols].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 38)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis = df_analysis.merge(df_human_annotation)\n",
    "df_analysis.shape\n",
    "# assert df_analysis.shape[0] == 310\n",
    "# df_analysis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 38)\n"
     ]
    }
   ],
   "source": [
    "# Remove flagged datapoint\n",
    "df_analysis = df_analysis[df_analysis['hatespeech'] != 'I wish I live in a country that does not tolerate gay marriage.']\n",
    "print(df_analysis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df_analysis.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>source</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_relevance</th>\n",
       "      <th>prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_coherence</th>\n",
       "      <th>...</th>\n",
       "      <th>prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_coherence</th>\n",
       "      <th>prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_suitableness</th>\n",
       "      <th>prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_aggressiveness</th>\n",
       "      <th>prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_avg_score</th>\n",
       "      <th>prediction_gpt-4o_zeroshot_relevance</th>\n",
       "      <th>prediction_gpt-4o_zeroshot_aggressiveness</th>\n",
       "      <th>prediction_gpt-4o_zeroshot_coherence</th>\n",
       "      <th>prediction_gpt-4o_zeroshot_suitableness</th>\n",
       "      <th>prediction_gpt-4o_zeroshot_avg_score</th>\n",
       "      <th>rank_human_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>islam only a religion of per just wrong. peace...</td>\n",
       "      <td>GPS</td>\n",
       "      <td>944ec738-ee5e-40d6-8493-93c1eb8b403e</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Is it fair to judge an entire religious group ...</td>\n",
       "      <td>QUARC</td>\n",
       "      <td>b0e53c71-0567-4052-971c-d777b9fcdc1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>I must strongly denounce your offensive statem...</td>\n",
       "      <td>GPT3.5_ZS</td>\n",
       "      <td>b0449292-e5b5-4e0a-b36e-8eaabc0d3915</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Generalizing about Muslims based on the action...</td>\n",
       "      <td>GPT3.5_FS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Stereotyping Muslims based on the actions of a...</td>\n",
       "      <td>dialoGPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                                  hatespeech      csType  \\\n",
       "0        0      0  Above all Islam is a religion of conquest.  Denouncing   \n",
       "1        1      1  Above all Islam is a religion of conquest.  Denouncing   \n",
       "2        2      2  Above all Islam is a religion of conquest.  Denouncing   \n",
       "3        3      3  Above all Islam is a religion of conquest.  Denouncing   \n",
       "4        4      4  Above all Islam is a religion of conquest.  Denouncing   \n",
       "\n",
       "                                       counterspeech  \\\n",
       "0  No, islam is a religion of 1.6 billion people ...   \n",
       "1  No, islam is a religion of 1.6 billion people ...   \n",
       "2  No, islam is a religion of 1.6 billion people ...   \n",
       "3  No, islam is a religion of 1.6 billion people ...   \n",
       "4  No, islam is a religion of 1.6 billion people ...   \n",
       "\n",
       "                             predicted_counterspeech     source  \\\n",
       "0  islam only a religion of per just wrong. peace...        GPS   \n",
       "1  Is it fair to judge an entire religious group ...      QUARC   \n",
       "2  I must strongly denounce your offensive statem...  GPT3.5_ZS   \n",
       "3  Generalizing about Muslims based on the action...  GPT3.5_FS   \n",
       "4  Stereotyping Muslims based on the actions of a...   dialoGPT   \n",
       "\n",
       "                                   uuid  \\\n",
       "0  944ec738-ee5e-40d6-8493-93c1eb8b403e   \n",
       "1  b0e53c71-0567-4052-971c-d777b9fcdc1a   \n",
       "2  b0449292-e5b5-4e0a-b36e-8eaabc0d3915   \n",
       "3                                   NaN   \n",
       "4                                   NaN   \n",
       "\n",
       "   prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_relevance  \\\n",
       "0                                                2.0                  \n",
       "1                                                4.0                  \n",
       "2                                                5.0                  \n",
       "3                                                4.0                  \n",
       "4                                                4.0                  \n",
       "\n",
       "   prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_coherence  ...  \\\n",
       "0                                                2.0                 ...   \n",
       "1                                                5.0                 ...   \n",
       "2                                                5.0                 ...   \n",
       "3                                                5.0                 ...   \n",
       "4                                                4.0                 ...   \n",
       "\n",
       "   prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_coherence  \\\n",
       "0                                                2.0             \n",
       "1                                                4.0             \n",
       "2                                                4.0             \n",
       "3                                                4.0             \n",
       "4                                                3.0             \n",
       "\n",
       "   prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_suitableness  \\\n",
       "0                                                2.0                \n",
       "1                                                2.0                \n",
       "2                                                2.0                \n",
       "3                                                3.0                \n",
       "4                                                3.0                \n",
       "\n",
       "   prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_aggressiveness  \\\n",
       "0                                                2.0                  \n",
       "1                                                1.0                  \n",
       "2                                                2.0                  \n",
       "3                                                1.0                  \n",
       "4                                                1.0                  \n",
       "\n",
       "   prediction_meta-llama-Llama-3-8b-chat-hf_zeroshot_avg_score  \\\n",
       "0                                           0.500000             \n",
       "1                                           0.777778             \n",
       "2                                           0.777778             \n",
       "3                                           0.833333             \n",
       "4                                           0.777778             \n",
       "\n",
       "   prediction_gpt-4o_zeroshot_relevance  \\\n",
       "0                                   2.0   \n",
       "1                                   5.0   \n",
       "2                                   5.0   \n",
       "3                                   5.0   \n",
       "4                                   5.0   \n",
       "\n",
       "   prediction_gpt-4o_zeroshot_aggressiveness  \\\n",
       "0                                        2.0   \n",
       "1                                        1.0   \n",
       "2                                        1.0   \n",
       "3                                        1.0   \n",
       "4                                        1.0   \n",
       "\n",
       "   prediction_gpt-4o_zeroshot_coherence  \\\n",
       "0                                   1.0   \n",
       "1                                   4.0   \n",
       "2                                   5.0   \n",
       "3                                   5.0   \n",
       "4                                   4.0   \n",
       "\n",
       "   prediction_gpt-4o_zeroshot_suitableness  \\\n",
       "0                                      2.0   \n",
       "1                                      2.0   \n",
       "2                                      3.0   \n",
       "3                                      3.0   \n",
       "4                                      3.0   \n",
       "\n",
       "   prediction_gpt-4o_zeroshot_avg_score  rank_human_annotation  \n",
       "0                              0.444444                    5.0  \n",
       "1                              0.833333                    2.0  \n",
       "2                              0.944444                    1.0  \n",
       "3                              0.944444                    4.0  \n",
       "4                              0.888889                    3.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Ranking by each automated metric for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_mappings = {\n",
    "    'gpt-4o_zeroshot': 'gpt-4o_zeroshot',\n",
    "    'gpt-4o': 'gpt-4o',\n",
    "    'meta-llama-Llama-3-8b-chat-hf_zeroshot': 'llama_zeroshot',\n",
    "    'meta-llama-Llama-3-8b-chat-hf': 'llama',\n",
    "    'mistralai-Mistral-7B-Instruct-v0.3': 'mistral',\n",
    "    'mistralai-Mistral-7B-Instruct-v0.3_zeroshot': 'mistral_zeroshot',\n",
    "}\n",
    "# df_analysis = df_analysis.drop(columns=['level_0'])\n",
    "df_analysis['uuid_ranking'] = df_analysis['csType'].apply(lambda x: str(uuid.uuid4()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rankings: (61, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o_zeroshot</th>\n",
       "      <th>gpt-4o</th>\n",
       "      <th>llama_zeroshot</th>\n",
       "      <th>llama</th>\n",
       "      <th>mistral</th>\n",
       "      <th>mistral_zeroshot</th>\n",
       "      <th>bleu_1_(pred_cs, cs)</th>\n",
       "      <th>bleu_2_(pred_cs, cs)</th>\n",
       "      <th>bleu_3_(pred_cs, cs)</th>\n",
       "      <th>bleu_4_(pred_cs, cs)</th>\n",
       "      <th>rouge_1_(pred_cs, cs)</th>\n",
       "      <th>rouge_2_(pred_cs, cs)</th>\n",
       "      <th>rouge_l_(pred_cs, cs)</th>\n",
       "      <th>meteor_score_(pred_cs, cs)</th>\n",
       "      <th>bert_score_(pred_cs, cs)</th>\n",
       "      <th>human_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6964ebf8-42e5-4818-b290-64382d4de00c, 152248d...</td>\n",
       "      <td>[d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...</td>\n",
       "      <td>[152248db-1137-4f4f-aaf6-ef788c6c2043, 6964ebf...</td>\n",
       "      <td>[6964ebf8-42e5-4818-b290-64382d4de00c, 152248d...</td>\n",
       "      <td>[d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...</td>\n",
       "      <td>[d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...</td>\n",
       "      <td>[2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...</td>\n",
       "      <td>[2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...</td>\n",
       "      <td>[2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...</td>\n",
       "      <td>[2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...</td>\n",
       "      <td>[2513b132-f5c6-4391-97a5-1f4157df97f5, 152248d...</td>\n",
       "      <td>[2513b132-f5c6-4391-97a5-1f4157df97f5, 6964ebf...</td>\n",
       "      <td>[2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...</td>\n",
       "      <td>[152248db-1137-4f4f-aaf6-ef788c6c2043, 2513b13...</td>\n",
       "      <td>[d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 74703f8...</td>\n",
       "      <td>[6964ebf8-42e5-4818-b290-64382d4de00c, d8a5dfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ce655b57-8a83-4e69-9efc-f8d2bc36ef62, c3ef8aa...</td>\n",
       "      <td>[c3ef8aa2-80d5-4972-9dd5-ffb7285b2025, 9c8d072...</td>\n",
       "      <td>[ce655b57-8a83-4e69-9efc-f8d2bc36ef62, c3ef8aa...</td>\n",
       "      <td>[ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 9c8d072...</td>\n",
       "      <td>[ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 144bb5e...</td>\n",
       "      <td>[ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 144bb5e...</td>\n",
       "      <td>[9c8d0726-4b8f-4fdd-ae5a-93d7eadca40b, ce655b5...</td>\n",
       "      <td>[3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...</td>\n",
       "      <td>[3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...</td>\n",
       "      <td>[3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...</td>\n",
       "      <td>[144bb5ed-e7cc-4ceb-a10f-9431649de51a, 3dccc11...</td>\n",
       "      <td>[ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 144bb5e...</td>\n",
       "      <td>[144bb5ed-e7cc-4ceb-a10f-9431649de51a, 3dccc11...</td>\n",
       "      <td>[9c8d0726-4b8f-4fdd-ae5a-93d7eadca40b, c3ef8aa...</td>\n",
       "      <td>[3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...</td>\n",
       "      <td>[9c8d0726-4b8f-4fdd-ae5a-93d7eadca40b, c3ef8aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...</td>\n",
       "      <td>[189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...</td>\n",
       "      <td>[7bfd1705-fc1b-4870-b90b-6889172511fc, 33ed5c6...</td>\n",
       "      <td>[189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...</td>\n",
       "      <td>[32c51b86-f2ae-45a6-8001-e0c851ec838f, 189a7b3...</td>\n",
       "      <td>[32c51b86-f2ae-45a6-8001-e0c851ec838f, 189a7b3...</td>\n",
       "      <td>[32c51b86-f2ae-45a6-8001-e0c851ec838f, 7bfd170...</td>\n",
       "      <td>[e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...</td>\n",
       "      <td>[e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...</td>\n",
       "      <td>[e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...</td>\n",
       "      <td>[e313f5fe-f47e-4b74-889f-092372f27727, 7bfd170...</td>\n",
       "      <td>[32c51b86-f2ae-45a6-8001-e0c851ec838f, 189a7b3...</td>\n",
       "      <td>[e313f5fe-f47e-4b74-889f-092372f27727, 7bfd170...</td>\n",
       "      <td>[189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...</td>\n",
       "      <td>[e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...</td>\n",
       "      <td>[189a7b36-e646-4e25-9fba-eacdb916ea2d, 33ed5c6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     gpt-4o_zeroshot  \\\n",
       "0  [6964ebf8-42e5-4818-b290-64382d4de00c, 152248d...   \n",
       "0  [ce655b57-8a83-4e69-9efc-f8d2bc36ef62, c3ef8aa...   \n",
       "0  [189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...   \n",
       "\n",
       "                                              gpt-4o  \\\n",
       "0  [d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...   \n",
       "0  [c3ef8aa2-80d5-4972-9dd5-ffb7285b2025, 9c8d072...   \n",
       "0  [189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...   \n",
       "\n",
       "                                      llama_zeroshot  \\\n",
       "0  [152248db-1137-4f4f-aaf6-ef788c6c2043, 6964ebf...   \n",
       "0  [ce655b57-8a83-4e69-9efc-f8d2bc36ef62, c3ef8aa...   \n",
       "0  [7bfd1705-fc1b-4870-b90b-6889172511fc, 33ed5c6...   \n",
       "\n",
       "                                               llama  \\\n",
       "0  [6964ebf8-42e5-4818-b290-64382d4de00c, 152248d...   \n",
       "0  [ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 9c8d072...   \n",
       "0  [189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...   \n",
       "\n",
       "                                             mistral  \\\n",
       "0  [d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...   \n",
       "0  [ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 144bb5e...   \n",
       "0  [32c51b86-f2ae-45a6-8001-e0c851ec838f, 189a7b3...   \n",
       "\n",
       "                                    mistral_zeroshot  \\\n",
       "0  [d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...   \n",
       "0  [ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 144bb5e...   \n",
       "0  [32c51b86-f2ae-45a6-8001-e0c851ec838f, 189a7b3...   \n",
       "\n",
       "                                bleu_1_(pred_cs, cs)  \\\n",
       "0  [2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...   \n",
       "0  [9c8d0726-4b8f-4fdd-ae5a-93d7eadca40b, ce655b5...   \n",
       "0  [32c51b86-f2ae-45a6-8001-e0c851ec838f, 7bfd170...   \n",
       "\n",
       "                                bleu_2_(pred_cs, cs)  \\\n",
       "0  [2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...   \n",
       "0  [3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...   \n",
       "0  [e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...   \n",
       "\n",
       "                                bleu_3_(pred_cs, cs)  \\\n",
       "0  [2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...   \n",
       "0  [3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...   \n",
       "0  [e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...   \n",
       "\n",
       "                                bleu_4_(pred_cs, cs)  \\\n",
       "0  [2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...   \n",
       "0  [3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...   \n",
       "0  [e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...   \n",
       "\n",
       "                               rouge_1_(pred_cs, cs)  \\\n",
       "0  [2513b132-f5c6-4391-97a5-1f4157df97f5, 152248d...   \n",
       "0  [144bb5ed-e7cc-4ceb-a10f-9431649de51a, 3dccc11...   \n",
       "0  [e313f5fe-f47e-4b74-889f-092372f27727, 7bfd170...   \n",
       "\n",
       "                               rouge_2_(pred_cs, cs)  \\\n",
       "0  [2513b132-f5c6-4391-97a5-1f4157df97f5, 6964ebf...   \n",
       "0  [ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 144bb5e...   \n",
       "0  [32c51b86-f2ae-45a6-8001-e0c851ec838f, 189a7b3...   \n",
       "\n",
       "                               rouge_l_(pred_cs, cs)  \\\n",
       "0  [2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...   \n",
       "0  [144bb5ed-e7cc-4ceb-a10f-9431649de51a, 3dccc11...   \n",
       "0  [e313f5fe-f47e-4b74-889f-092372f27727, 7bfd170...   \n",
       "\n",
       "                          meteor_score_(pred_cs, cs)  \\\n",
       "0  [152248db-1137-4f4f-aaf6-ef788c6c2043, 2513b13...   \n",
       "0  [9c8d0726-4b8f-4fdd-ae5a-93d7eadca40b, c3ef8aa...   \n",
       "0  [189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...   \n",
       "\n",
       "                            bert_score_(pred_cs, cs)  \\\n",
       "0  [d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 74703f8...   \n",
       "0  [3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...   \n",
       "0  [e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...   \n",
       "\n",
       "                                    human_annotation  \n",
       "0  [6964ebf8-42e5-4818-b290-64382d4de00c, d8a5dfe...  \n",
       "0  [9c8d0726-4b8f-4fdd-ae5a-93d7eadca40b, c3ef8aa...  \n",
       "0  [189a7b36-e646-4e25-9fba-eacdb916ea2d, 33ed5c6...  "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = df_analysis.groupby(['hatespeech','csType'])\n",
    "df_ranking = pd.DataFrame()\n",
    "cols = [x for x in df_analysis.columns if 'prediction_' in x and 'avg' in x]\n",
    "\n",
    "for group_key, group_df in df_grouped:\n",
    "    # add prediction rankings\n",
    "    ranking_dict = {}\n",
    "    for model in model_name_mappings:\n",
    "        rank_col = [x for x in cols if model in x][0]\n",
    "        df_sorted = group_df.sort_values(by=rank_col, ascending=False)\n",
    "        ranks = df_sorted['uuid_ranking'].values.tolist()\n",
    "        if model_name_mappings[model] in ranking_dict:\n",
    "            ranking_dict[model_name_mappings[model]].append(ranks)\n",
    "        else:\n",
    "            ranking_dict[model_name_mappings[model]] = [ranks]\n",
    "    \n",
    "    \n",
    "    for col in traditional_metrics:\n",
    "        rank_col = col\n",
    "        df_sorted = group_df.sort_values(by=rank_col, ascending=False)\n",
    "        ranks = df_sorted['uuid_ranking'].values.tolist()\n",
    "        ranking_dict[col] = [ranks]\n",
    "\n",
    "    # add groundtruth rankings\n",
    "    df_sorted = group_df.sort_values(by='rank_human_annotation', ascending=True)\n",
    "    ranks = df_sorted['uuid_ranking'].values.tolist()\n",
    "    ranking_dict['human_annotation'] = [ranks]\n",
    "\n",
    "    df_ranking = pd.concat((df_ranking,pd.DataFrame.from_dict(ranking_dict)))\n",
    "\n",
    "print(f\"Total rankings: {df_ranking.shape}\")\n",
    "df_ranking.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG score: 0.9736200056866403\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "df_ranking = df_ranking\n",
    "\n",
    "def convert_rankings_to_relevance_scores(ranking1, ranking2):\n",
    "    # relevance_y_true = [(len(ranking1)-i) for i, _ in enumerate(ranking1)]\n",
    "    # relevance_y_pred = [(len(ranking2) - ranking2.index(id)) for id in ranking1]\n",
    "    relevance_y_true = [i+1 for i, _ in enumerate(ranking1)]\n",
    "    relevance_y_pred = [ranking2.index(id) + 1 for id in ranking1]\n",
    "    return relevance_y_true, relevance_y_pred\n",
    "\n",
    "true_col = 'human_annotation'\n",
    "pred_col = 'gpt-4o_zeroshot'\n",
    "\n",
    "y_true = df_ranking[true_col].values.tolist()\n",
    "y_pred = df_ranking[pred_col].values.tolist()\n",
    "y_true_rankings = [convert_rankings_to_relevance_scores(ranking1, ranking2)[0] for ranking1, ranking2 in zip(y_true, y_pred)]\n",
    "y_pred_rankings = [convert_rankings_to_relevance_scores(ranking1, ranking2)[1] for ranking1, ranking2 in zip(y_true, y_pred)]\n",
    "\n",
    "ndcg_score_list = [ndcg_score([y_true_ranking], [y_pred_ranking]) for y_true_ranking, y_pred_ranking in zip(y_true_rankings, y_pred_rankings)]\n",
    "avg_ndcg = ndcg_score(y_true_rankings, y_pred_rankings)\n",
    "print(f\"Average NDCG score: {avg_ndcg:}\")\n",
    "\n",
    "df_ranking[f'ndcg_({true_col},{pred_col})'] = ndcg_score_list\n",
    "# df_ranking.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o_zeroshot,0.9736200056866403\n",
      "gpt-4o,0.9655075104336339\n",
      "llama_zeroshot,0.9381903637159505\n",
      "llama,0.9551361268120805\n",
      "mistral,0.9508248402840414\n",
      "mistral_zeroshot,0.9508248402840414\n",
      "bleu_1_(pred_cs, cs),0.8854666055254281\n",
      "bleu_2_(pred_cs, cs),0.7871137146880147\n",
      "bleu_3_(pred_cs, cs),0.7884591439575401\n",
      "bleu_4_(pred_cs, cs),0.7884591439575401\n",
      "rouge_1_(pred_cs, cs),0.8696017548632476\n",
      "rouge_2_(pred_cs, cs),0.8773631428241773\n",
      "rouge_l_(pred_cs, cs),0.8688092160896259\n",
      "meteor_score_(pred_cs, cs),0.919623199358571\n",
      "bert_score_(pred_cs, cs),0.8541347549042574\n"
     ]
    }
   ],
   "source": [
    "cols_list = [\n",
    "    'gpt-4o_zeroshot', 'gpt-4o', 'llama_zeroshot', 'llama', 'mistral',\n",
    "       'mistral_zeroshot', 'bleu_1_(pred_cs, cs)', 'bleu_2_(pred_cs, cs)',\n",
    "       'bleu_3_(pred_cs, cs)', 'bleu_4_(pred_cs, cs)', 'rouge_1_(pred_cs, cs)',\n",
    "       'rouge_2_(pred_cs, cs)', 'rouge_l_(pred_cs, cs)',\n",
    "       'meteor_score_(pred_cs, cs)', 'bert_score_(pred_cs, cs)'\n",
    "]\n",
    "for pred_col in cols_list:\n",
    "\n",
    "    true_col = 'human_annotation'\n",
    "\n",
    "    y_true = df_ranking[true_col].values.tolist()\n",
    "    y_pred = df_ranking[pred_col].values.tolist()\n",
    "    y_true_rankings = [convert_rankings_to_relevance_scores(ranking1, ranking2)[0] for ranking1, ranking2 in zip(y_true, y_pred)]\n",
    "    y_pred_rankings = [convert_rankings_to_relevance_scores(ranking1, ranking2)[1] for ranking1, ranking2 in zip(y_true, y_pred)]\n",
    "\n",
    "    ndcg_score_list = [ndcg_score([y_true_ranking], [y_pred_ranking]) for y_true_ranking, y_pred_ranking in zip(y_true_rankings, y_pred_rankings)]\n",
    "    avg_ndcg = ndcg_score(y_true_rankings, y_pred_rankings)\n",
    "    # print(f\"Average NDCG score: {avg_ndcg:}\")\n",
    "    print(f\"{pred_col},{avg_ndcg:}\")\n",
    "\n",
    "    # print(f\"avg ndcg score: \")\n",
    "\n",
    "    df_ranking[f'ndcg_({true_col},{pred_col})'] = ndcg_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o_zeroshot</th>\n",
       "      <th>gpt-4o</th>\n",
       "      <th>llama_zeroshot</th>\n",
       "      <th>llama</th>\n",
       "      <th>mistral</th>\n",
       "      <th>mistral_zeroshot</th>\n",
       "      <th>bleu_1_(pred_cs, cs)</th>\n",
       "      <th>bleu_2_(pred_cs, cs)</th>\n",
       "      <th>bleu_3_(pred_cs, cs)</th>\n",
       "      <th>bleu_4_(pred_cs, cs)</th>\n",
       "      <th>...</th>\n",
       "      <th>ndcg_(human_annotation,mistral_zeroshot)</th>\n",
       "      <th>ndcg_(human_annotation,bleu_1_(pred_cs, cs))</th>\n",
       "      <th>ndcg_(human_annotation,bleu_2_(pred_cs, cs))</th>\n",
       "      <th>ndcg_(human_annotation,bleu_3_(pred_cs, cs))</th>\n",
       "      <th>ndcg_(human_annotation,bleu_4_(pred_cs, cs))</th>\n",
       "      <th>ndcg_(human_annotation,rouge_1_(pred_cs, cs))</th>\n",
       "      <th>ndcg_(human_annotation,rouge_2_(pred_cs, cs))</th>\n",
       "      <th>ndcg_(human_annotation,rouge_l_(pred_cs, cs))</th>\n",
       "      <th>ndcg_(human_annotation,meteor_score_(pred_cs, cs))</th>\n",
       "      <th>ndcg_(human_annotation,bert_score_(pred_cs, cs))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6964ebf8-42e5-4818-b290-64382d4de00c, 152248d...</td>\n",
       "      <td>[d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...</td>\n",
       "      <td>[152248db-1137-4f4f-aaf6-ef788c6c2043, 6964ebf...</td>\n",
       "      <td>[6964ebf8-42e5-4818-b290-64382d4de00c, 152248d...</td>\n",
       "      <td>[d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...</td>\n",
       "      <td>[d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...</td>\n",
       "      <td>[2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...</td>\n",
       "      <td>[2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...</td>\n",
       "      <td>[2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...</td>\n",
       "      <td>[2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962741</td>\n",
       "      <td>0.748487</td>\n",
       "      <td>0.748487</td>\n",
       "      <td>0.748487</td>\n",
       "      <td>0.748487</td>\n",
       "      <td>0.722243</td>\n",
       "      <td>0.865335</td>\n",
       "      <td>0.748487</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.800277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ce655b57-8a83-4e69-9efc-f8d2bc36ef62, c3ef8aa...</td>\n",
       "      <td>[c3ef8aa2-80d5-4972-9dd5-ffb7285b2025, 9c8d072...</td>\n",
       "      <td>[ce655b57-8a83-4e69-9efc-f8d2bc36ef62, c3ef8aa...</td>\n",
       "      <td>[ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 9c8d072...</td>\n",
       "      <td>[ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 144bb5e...</td>\n",
       "      <td>[ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 144bb5e...</td>\n",
       "      <td>[9c8d0726-4b8f-4fdd-ae5a-93d7eadca40b, ce655b5...</td>\n",
       "      <td>[3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...</td>\n",
       "      <td>[3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...</td>\n",
       "      <td>[3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926233</td>\n",
       "      <td>0.993251</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.782513</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.987254</td>\n",
       "      <td>0.758173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...</td>\n",
       "      <td>[189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...</td>\n",
       "      <td>[7bfd1705-fc1b-4870-b90b-6889172511fc, 33ed5c6...</td>\n",
       "      <td>[189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...</td>\n",
       "      <td>[32c51b86-f2ae-45a6-8001-e0c851ec838f, 189a7b3...</td>\n",
       "      <td>[32c51b86-f2ae-45a6-8001-e0c851ec838f, 189a7b3...</td>\n",
       "      <td>[32c51b86-f2ae-45a6-8001-e0c851ec838f, 7bfd170...</td>\n",
       "      <td>[e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...</td>\n",
       "      <td>[e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...</td>\n",
       "      <td>[e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960957</td>\n",
       "      <td>0.921966</td>\n",
       "      <td>0.722243</td>\n",
       "      <td>0.722243</td>\n",
       "      <td>0.722243</td>\n",
       "      <td>0.875021</td>\n",
       "      <td>0.960957</td>\n",
       "      <td>0.875021</td>\n",
       "      <td>0.957321</td>\n",
       "      <td>0.722243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cccb62aa-d0a1-4290-bd8f-d3f2b9fa0f13, 0f37e3b...</td>\n",
       "      <td>[447df4d1-0454-4d4c-8862-298981e75dc8, cccb62a...</td>\n",
       "      <td>[0f37e3b4-cf8a-4f12-93d3-d8f1d1ad83c8, cccb62a...</td>\n",
       "      <td>[cccb62aa-d0a1-4290-bd8f-d3f2b9fa0f13, 0f37e3b...</td>\n",
       "      <td>[cccb62aa-d0a1-4290-bd8f-d3f2b9fa0f13, 447df4d...</td>\n",
       "      <td>[cccb62aa-d0a1-4290-bd8f-d3f2b9fa0f13, 447df4d...</td>\n",
       "      <td>[0f37e3b4-cf8a-4f12-93d3-d8f1d1ad83c8, cccb62a...</td>\n",
       "      <td>[88ce5d18-dbf8-464e-a4e6-93cb2f5ff24d, 99511e6...</td>\n",
       "      <td>[88ce5d18-dbf8-464e-a4e6-93cb2f5ff24d, 99511e6...</td>\n",
       "      <td>[88ce5d18-dbf8-464e-a4e6-93cb2f5ff24d, 99511e6...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943997</td>\n",
       "      <td>0.938577</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.964070</td>\n",
       "      <td>0.938577</td>\n",
       "      <td>0.964070</td>\n",
       "      <td>0.959804</td>\n",
       "      <td>0.728992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[9e858255-4ef5-4048-bfc9-e00c48cde2c2, 1217f59...</td>\n",
       "      <td>[9e858255-4ef5-4048-bfc9-e00c48cde2c2, 1217f59...</td>\n",
       "      <td>[43a01ad2-ca3a-4851-b98d-974a07a0e95f, 9e85825...</td>\n",
       "      <td>[43a01ad2-ca3a-4851-b98d-974a07a0e95f, 9e85825...</td>\n",
       "      <td>[9e858255-4ef5-4048-bfc9-e00c48cde2c2, 1217f59...</td>\n",
       "      <td>[9e858255-4ef5-4048-bfc9-e00c48cde2c2, 1217f59...</td>\n",
       "      <td>[43a01ad2-ca3a-4851-b98d-974a07a0e95f, 9942515...</td>\n",
       "      <td>[4a97a00a-ea40-41bb-be82-49ef94cf6065, 9942515...</td>\n",
       "      <td>[4a97a00a-ea40-41bb-be82-49ef94cf6065, 9942515...</td>\n",
       "      <td>[4a97a00a-ea40-41bb-be82-49ef94cf6065, 9942515...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995734</td>\n",
       "      <td>0.926233</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.959804</td>\n",
       "      <td>0.959804</td>\n",
       "      <td>0.959804</td>\n",
       "      <td>0.959804</td>\n",
       "      <td>0.758173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[292d3df3-3302-4b51-b3fd-a14826c11832, f4a4d84...</td>\n",
       "      <td>[f4a4d84e-c4ae-41cd-a11e-d7e684839191, 2aebbb0...</td>\n",
       "      <td>[292d3df3-3302-4b51-b3fd-a14826c11832, 2aebbb0...</td>\n",
       "      <td>[f4a4d84e-c4ae-41cd-a11e-d7e684839191, 2aebbb0...</td>\n",
       "      <td>[14b1c188-4a93-44e9-9c26-d851e3b2316d, 2aebbb0...</td>\n",
       "      <td>[14b1c188-4a93-44e9-9c26-d851e3b2316d, 2aebbb0...</td>\n",
       "      <td>[d451c7e1-e267-4f4e-8357-b9fd162a7bb8, 14b1c18...</td>\n",
       "      <td>[2aebbb06-c938-4d85-b394-e31165129b52, f4a4d84...</td>\n",
       "      <td>[2aebbb06-c938-4d85-b394-e31165129b52, f4a4d84...</td>\n",
       "      <td>[2aebbb06-c938-4d85-b394-e31165129b52, f4a4d84...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938979</td>\n",
       "      <td>0.993251</td>\n",
       "      <td>0.759503</td>\n",
       "      <td>0.759503</td>\n",
       "      <td>0.759503</td>\n",
       "      <td>0.957321</td>\n",
       "      <td>0.993251</td>\n",
       "      <td>0.967758</td>\n",
       "      <td>0.957321</td>\n",
       "      <td>0.847222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[9934aa51-e195-4786-92d1-7e1829b3914b, de66cb0...</td>\n",
       "      <td>[9934aa51-e195-4786-92d1-7e1829b3914b, de66cb0...</td>\n",
       "      <td>[60e1caca-408c-48fc-9f54-61a8e2d9e6eb, 9934aa5...</td>\n",
       "      <td>[de66cb02-3027-47ad-93e3-505af3dcf559, 9934aa5...</td>\n",
       "      <td>[9934aa51-e195-4786-92d1-7e1829b3914b, de66cb0...</td>\n",
       "      <td>[9934aa51-e195-4786-92d1-7e1829b3914b, de66cb0...</td>\n",
       "      <td>[7c6e6127-0780-486b-b032-555356f78810, 60e1cac...</td>\n",
       "      <td>[3108c254-0932-4248-a269-1b82ed1f802b, 7c6e612...</td>\n",
       "      <td>[3108c254-0932-4248-a269-1b82ed1f802b, 7c6e612...</td>\n",
       "      <td>[3108c254-0932-4248-a269-1b82ed1f802b, 7c6e612...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982236</td>\n",
       "      <td>0.901265</td>\n",
       "      <td>0.823862</td>\n",
       "      <td>0.787932</td>\n",
       "      <td>0.787932</td>\n",
       "      <td>0.982236</td>\n",
       "      <td>0.939731</td>\n",
       "      <td>0.982236</td>\n",
       "      <td>0.977970</td>\n",
       "      <td>0.977970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7e20ecb8-a76e-42f2-8dc7-caaf72b2dcc2, f16cadf...</td>\n",
       "      <td>[f16cadf5-387c-4050-982d-d422e667789e, 5f74ff6...</td>\n",
       "      <td>[7e20ecb8-a76e-42f2-8dc7-caaf72b2dcc2, 5f74ff6...</td>\n",
       "      <td>[7e20ecb8-a76e-42f2-8dc7-caaf72b2dcc2, f16cadf...</td>\n",
       "      <td>[7e20ecb8-a76e-42f2-8dc7-caaf72b2dcc2, f16cadf...</td>\n",
       "      <td>[7e20ecb8-a76e-42f2-8dc7-caaf72b2dcc2, f16cadf...</td>\n",
       "      <td>[f16cadf5-387c-4050-982d-d422e667789e, 5f74ff6...</td>\n",
       "      <td>[625502e8-55f9-4f21-b578-180d61823381, 295d72a...</td>\n",
       "      <td>[625502e8-55f9-4f21-b578-180d61823381, 295d72a...</td>\n",
       "      <td>[625502e8-55f9-4f21-b578-180d61823381, 295d72a...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987254</td>\n",
       "      <td>0.787531</td>\n",
       "      <td>0.819596</td>\n",
       "      <td>0.819596</td>\n",
       "      <td>0.819596</td>\n",
       "      <td>0.734990</td>\n",
       "      <td>0.782513</td>\n",
       "      <td>0.754485</td>\n",
       "      <td>0.977970</td>\n",
       "      <td>0.833146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[caf0226a-72b4-403f-b41e-18904f178a3d, 1d27c7c...</td>\n",
       "      <td>[1d27c7ca-93c5-4531-b729-b833ede8ed15, caf0226...</td>\n",
       "      <td>[caf0226a-72b4-403f-b41e-18904f178a3d, 711749e...</td>\n",
       "      <td>[caf0226a-72b4-403f-b41e-18904f178a3d, 711749e...</td>\n",
       "      <td>[a5c32e23-524c-4e60-9a0d-665e5be67241, caf0226...</td>\n",
       "      <td>[a5c32e23-524c-4e60-9a0d-665e5be67241, caf0226...</td>\n",
       "      <td>[711749e9-88f9-433f-9757-75440be8966e, caf0226...</td>\n",
       "      <td>[1d27c7ca-93c5-4531-b729-b833ede8ed15, a5c32e2...</td>\n",
       "      <td>[1d27c7ca-93c5-4531-b729-b833ede8ed15, a5c32e2...</td>\n",
       "      <td>[1d27c7ca-93c5-4531-b729-b833ede8ed15, a5c32e2...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921966</td>\n",
       "      <td>0.993251</td>\n",
       "      <td>0.839895</td>\n",
       "      <td>0.839895</td>\n",
       "      <td>0.839895</td>\n",
       "      <td>0.948211</td>\n",
       "      <td>0.977970</td>\n",
       "      <td>0.796011</td>\n",
       "      <td>0.984718</td>\n",
       "      <td>0.937248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[9ff400dc-c05d-4b5c-a987-2a9ef771c43c, 3ce7ffa...</td>\n",
       "      <td>[9ff400dc-c05d-4b5c-a987-2a9ef771c43c, 3ce7ffa...</td>\n",
       "      <td>[9ff400dc-c05d-4b5c-a987-2a9ef771c43c, ee2acf2...</td>\n",
       "      <td>[9ff400dc-c05d-4b5c-a987-2a9ef771c43c, 3ce7ffa...</td>\n",
       "      <td>[9ff400dc-c05d-4b5c-a987-2a9ef771c43c, 3ce7ffa...</td>\n",
       "      <td>[9ff400dc-c05d-4b5c-a987-2a9ef771c43c, 3ce7ffa...</td>\n",
       "      <td>[fe8add53-ae09-40f1-9449-5500934473c7, cca2161...</td>\n",
       "      <td>[fe8add53-ae09-40f1-9449-5500934473c7, cca2161...</td>\n",
       "      <td>[fe8add53-ae09-40f1-9449-5500934473c7, cca2161...</td>\n",
       "      <td>[fe8add53-ae09-40f1-9449-5500934473c7, cca2161...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934311</td>\n",
       "      <td>0.806850</td>\n",
       "      <td>0.806850</td>\n",
       "      <td>0.806850</td>\n",
       "      <td>0.806850</td>\n",
       "      <td>0.948211</td>\n",
       "      <td>0.948211</td>\n",
       "      <td>0.948211</td>\n",
       "      <td>0.948211</td>\n",
       "      <td>0.823862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      gpt-4o_zeroshot  \\\n",
       "0   [6964ebf8-42e5-4818-b290-64382d4de00c, 152248d...   \n",
       "0   [ce655b57-8a83-4e69-9efc-f8d2bc36ef62, c3ef8aa...   \n",
       "0   [189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...   \n",
       "0   [cccb62aa-d0a1-4290-bd8f-d3f2b9fa0f13, 0f37e3b...   \n",
       "0   [9e858255-4ef5-4048-bfc9-e00c48cde2c2, 1217f59...   \n",
       "..                                                ...   \n",
       "0   [292d3df3-3302-4b51-b3fd-a14826c11832, f4a4d84...   \n",
       "0   [9934aa51-e195-4786-92d1-7e1829b3914b, de66cb0...   \n",
       "0   [7e20ecb8-a76e-42f2-8dc7-caaf72b2dcc2, f16cadf...   \n",
       "0   [caf0226a-72b4-403f-b41e-18904f178a3d, 1d27c7c...   \n",
       "0   [9ff400dc-c05d-4b5c-a987-2a9ef771c43c, 3ce7ffa...   \n",
       "\n",
       "                                               gpt-4o  \\\n",
       "0   [d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...   \n",
       "0   [c3ef8aa2-80d5-4972-9dd5-ffb7285b2025, 9c8d072...   \n",
       "0   [189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...   \n",
       "0   [447df4d1-0454-4d4c-8862-298981e75dc8, cccb62a...   \n",
       "0   [9e858255-4ef5-4048-bfc9-e00c48cde2c2, 1217f59...   \n",
       "..                                                ...   \n",
       "0   [f4a4d84e-c4ae-41cd-a11e-d7e684839191, 2aebbb0...   \n",
       "0   [9934aa51-e195-4786-92d1-7e1829b3914b, de66cb0...   \n",
       "0   [f16cadf5-387c-4050-982d-d422e667789e, 5f74ff6...   \n",
       "0   [1d27c7ca-93c5-4531-b729-b833ede8ed15, caf0226...   \n",
       "0   [9ff400dc-c05d-4b5c-a987-2a9ef771c43c, 3ce7ffa...   \n",
       "\n",
       "                                       llama_zeroshot  \\\n",
       "0   [152248db-1137-4f4f-aaf6-ef788c6c2043, 6964ebf...   \n",
       "0   [ce655b57-8a83-4e69-9efc-f8d2bc36ef62, c3ef8aa...   \n",
       "0   [7bfd1705-fc1b-4870-b90b-6889172511fc, 33ed5c6...   \n",
       "0   [0f37e3b4-cf8a-4f12-93d3-d8f1d1ad83c8, cccb62a...   \n",
       "0   [43a01ad2-ca3a-4851-b98d-974a07a0e95f, 9e85825...   \n",
       "..                                                ...   \n",
       "0   [292d3df3-3302-4b51-b3fd-a14826c11832, 2aebbb0...   \n",
       "0   [60e1caca-408c-48fc-9f54-61a8e2d9e6eb, 9934aa5...   \n",
       "0   [7e20ecb8-a76e-42f2-8dc7-caaf72b2dcc2, 5f74ff6...   \n",
       "0   [caf0226a-72b4-403f-b41e-18904f178a3d, 711749e...   \n",
       "0   [9ff400dc-c05d-4b5c-a987-2a9ef771c43c, ee2acf2...   \n",
       "\n",
       "                                                llama  \\\n",
       "0   [6964ebf8-42e5-4818-b290-64382d4de00c, 152248d...   \n",
       "0   [ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 9c8d072...   \n",
       "0   [189a7b36-e646-4e25-9fba-eacdb916ea2d, 7bfd170...   \n",
       "0   [cccb62aa-d0a1-4290-bd8f-d3f2b9fa0f13, 0f37e3b...   \n",
       "0   [43a01ad2-ca3a-4851-b98d-974a07a0e95f, 9e85825...   \n",
       "..                                                ...   \n",
       "0   [f4a4d84e-c4ae-41cd-a11e-d7e684839191, 2aebbb0...   \n",
       "0   [de66cb02-3027-47ad-93e3-505af3dcf559, 9934aa5...   \n",
       "0   [7e20ecb8-a76e-42f2-8dc7-caaf72b2dcc2, f16cadf...   \n",
       "0   [caf0226a-72b4-403f-b41e-18904f178a3d, 711749e...   \n",
       "0   [9ff400dc-c05d-4b5c-a987-2a9ef771c43c, 3ce7ffa...   \n",
       "\n",
       "                                              mistral  \\\n",
       "0   [d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...   \n",
       "0   [ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 144bb5e...   \n",
       "0   [32c51b86-f2ae-45a6-8001-e0c851ec838f, 189a7b3...   \n",
       "0   [cccb62aa-d0a1-4290-bd8f-d3f2b9fa0f13, 447df4d...   \n",
       "0   [9e858255-4ef5-4048-bfc9-e00c48cde2c2, 1217f59...   \n",
       "..                                                ...   \n",
       "0   [14b1c188-4a93-44e9-9c26-d851e3b2316d, 2aebbb0...   \n",
       "0   [9934aa51-e195-4786-92d1-7e1829b3914b, de66cb0...   \n",
       "0   [7e20ecb8-a76e-42f2-8dc7-caaf72b2dcc2, f16cadf...   \n",
       "0   [a5c32e23-524c-4e60-9a0d-665e5be67241, caf0226...   \n",
       "0   [9ff400dc-c05d-4b5c-a987-2a9ef771c43c, 3ce7ffa...   \n",
       "\n",
       "                                     mistral_zeroshot  \\\n",
       "0   [d8a5dfe2-f3a8-4086-a69d-8d27597ed48a, 152248d...   \n",
       "0   [ce655b57-8a83-4e69-9efc-f8d2bc36ef62, 144bb5e...   \n",
       "0   [32c51b86-f2ae-45a6-8001-e0c851ec838f, 189a7b3...   \n",
       "0   [cccb62aa-d0a1-4290-bd8f-d3f2b9fa0f13, 447df4d...   \n",
       "0   [9e858255-4ef5-4048-bfc9-e00c48cde2c2, 1217f59...   \n",
       "..                                                ...   \n",
       "0   [14b1c188-4a93-44e9-9c26-d851e3b2316d, 2aebbb0...   \n",
       "0   [9934aa51-e195-4786-92d1-7e1829b3914b, de66cb0...   \n",
       "0   [7e20ecb8-a76e-42f2-8dc7-caaf72b2dcc2, f16cadf...   \n",
       "0   [a5c32e23-524c-4e60-9a0d-665e5be67241, caf0226...   \n",
       "0   [9ff400dc-c05d-4b5c-a987-2a9ef771c43c, 3ce7ffa...   \n",
       "\n",
       "                                 bleu_1_(pred_cs, cs)  \\\n",
       "0   [2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...   \n",
       "0   [9c8d0726-4b8f-4fdd-ae5a-93d7eadca40b, ce655b5...   \n",
       "0   [32c51b86-f2ae-45a6-8001-e0c851ec838f, 7bfd170...   \n",
       "0   [0f37e3b4-cf8a-4f12-93d3-d8f1d1ad83c8, cccb62a...   \n",
       "0   [43a01ad2-ca3a-4851-b98d-974a07a0e95f, 9942515...   \n",
       "..                                                ...   \n",
       "0   [d451c7e1-e267-4f4e-8357-b9fd162a7bb8, 14b1c18...   \n",
       "0   [7c6e6127-0780-486b-b032-555356f78810, 60e1cac...   \n",
       "0   [f16cadf5-387c-4050-982d-d422e667789e, 5f74ff6...   \n",
       "0   [711749e9-88f9-433f-9757-75440be8966e, caf0226...   \n",
       "0   [fe8add53-ae09-40f1-9449-5500934473c7, cca2161...   \n",
       "\n",
       "                                 bleu_2_(pred_cs, cs)  \\\n",
       "0   [2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...   \n",
       "0   [3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...   \n",
       "0   [e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...   \n",
       "0   [88ce5d18-dbf8-464e-a4e6-93cb2f5ff24d, 99511e6...   \n",
       "0   [4a97a00a-ea40-41bb-be82-49ef94cf6065, 9942515...   \n",
       "..                                                ...   \n",
       "0   [2aebbb06-c938-4d85-b394-e31165129b52, f4a4d84...   \n",
       "0   [3108c254-0932-4248-a269-1b82ed1f802b, 7c6e612...   \n",
       "0   [625502e8-55f9-4f21-b578-180d61823381, 295d72a...   \n",
       "0   [1d27c7ca-93c5-4531-b729-b833ede8ed15, a5c32e2...   \n",
       "0   [fe8add53-ae09-40f1-9449-5500934473c7, cca2161...   \n",
       "\n",
       "                                 bleu_3_(pred_cs, cs)  \\\n",
       "0   [2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...   \n",
       "0   [3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...   \n",
       "0   [e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...   \n",
       "0   [88ce5d18-dbf8-464e-a4e6-93cb2f5ff24d, 99511e6...   \n",
       "0   [4a97a00a-ea40-41bb-be82-49ef94cf6065, 9942515...   \n",
       "..                                                ...   \n",
       "0   [2aebbb06-c938-4d85-b394-e31165129b52, f4a4d84...   \n",
       "0   [3108c254-0932-4248-a269-1b82ed1f802b, 7c6e612...   \n",
       "0   [625502e8-55f9-4f21-b578-180d61823381, 295d72a...   \n",
       "0   [1d27c7ca-93c5-4531-b729-b833ede8ed15, a5c32e2...   \n",
       "0   [fe8add53-ae09-40f1-9449-5500934473c7, cca2161...   \n",
       "\n",
       "                                 bleu_4_(pred_cs, cs)  ...  \\\n",
       "0   [2513b132-f5c6-4391-97a5-1f4157df97f5, d8a5dfe...  ...   \n",
       "0   [3dccc11d-2d4d-404d-9f65-48c8470a2233, 144bb5e...  ...   \n",
       "0   [e313f5fe-f47e-4b74-889f-092372f27727, 32c51b8...  ...   \n",
       "0   [88ce5d18-dbf8-464e-a4e6-93cb2f5ff24d, 99511e6...  ...   \n",
       "0   [4a97a00a-ea40-41bb-be82-49ef94cf6065, 9942515...  ...   \n",
       "..                                                ...  ...   \n",
       "0   [2aebbb06-c938-4d85-b394-e31165129b52, f4a4d84...  ...   \n",
       "0   [3108c254-0932-4248-a269-1b82ed1f802b, 7c6e612...  ...   \n",
       "0   [625502e8-55f9-4f21-b578-180d61823381, 295d72a...  ...   \n",
       "0   [1d27c7ca-93c5-4531-b729-b833ede8ed15, a5c32e2...  ...   \n",
       "0   [fe8add53-ae09-40f1-9449-5500934473c7, cca2161...  ...   \n",
       "\n",
       "   ndcg_(human_annotation,mistral_zeroshot)  \\\n",
       "0                                  0.962741   \n",
       "0                                  0.926233   \n",
       "0                                  0.960957   \n",
       "0                                  0.943997   \n",
       "0                                  0.995734   \n",
       "..                                      ...   \n",
       "0                                  0.938979   \n",
       "0                                  0.982236   \n",
       "0                                  0.987254   \n",
       "0                                  0.921966   \n",
       "0                                  0.934311   \n",
       "\n",
       "   ndcg_(human_annotation,bleu_1_(pred_cs, cs))  \\\n",
       "0                                      0.748487   \n",
       "0                                      0.993251   \n",
       "0                                      0.921966   \n",
       "0                                      0.938577   \n",
       "0                                      0.926233   \n",
       "..                                          ...   \n",
       "0                                      0.993251   \n",
       "0                                      0.901265   \n",
       "0                                      0.787531   \n",
       "0                                      0.993251   \n",
       "0                                      0.806850   \n",
       "\n",
       "   ndcg_(human_annotation,bleu_2_(pred_cs, cs))  \\\n",
       "0                                      0.748487   \n",
       "0                                      0.758173   \n",
       "0                                      0.722243   \n",
       "0                                      0.758173   \n",
       "0                                      0.758173   \n",
       "..                                          ...   \n",
       "0                                      0.759503   \n",
       "0                                      0.823862   \n",
       "0                                      0.819596   \n",
       "0                                      0.839895   \n",
       "0                                      0.806850   \n",
       "\n",
       "   ndcg_(human_annotation,bleu_3_(pred_cs, cs))  \\\n",
       "0                                      0.748487   \n",
       "0                                      0.758173   \n",
       "0                                      0.722243   \n",
       "0                                      0.758173   \n",
       "0                                      0.758173   \n",
       "..                                          ...   \n",
       "0                                      0.759503   \n",
       "0                                      0.787932   \n",
       "0                                      0.819596   \n",
       "0                                      0.839895   \n",
       "0                                      0.806850   \n",
       "\n",
       "   ndcg_(human_annotation,bleu_4_(pred_cs, cs))  \\\n",
       "0                                      0.748487   \n",
       "0                                      0.758173   \n",
       "0                                      0.722243   \n",
       "0                                      0.758173   \n",
       "0                                      0.758173   \n",
       "..                                          ...   \n",
       "0                                      0.759503   \n",
       "0                                      0.787932   \n",
       "0                                      0.819596   \n",
       "0                                      0.839895   \n",
       "0                                      0.806850   \n",
       "\n",
       "   ndcg_(human_annotation,rouge_1_(pred_cs, cs))  \\\n",
       "0                                       0.722243   \n",
       "0                                       0.762440   \n",
       "0                                       0.875021   \n",
       "0                                       0.964070   \n",
       "0                                       0.959804   \n",
       "..                                           ...   \n",
       "0                                       0.957321   \n",
       "0                                       0.982236   \n",
       "0                                       0.734990   \n",
       "0                                       0.948211   \n",
       "0                                       0.948211   \n",
       "\n",
       "    ndcg_(human_annotation,rouge_2_(pred_cs, cs))  \\\n",
       "0                                        0.865335   \n",
       "0                                        0.782513   \n",
       "0                                        0.960957   \n",
       "0                                        0.938577   \n",
       "0                                        0.959804   \n",
       "..                                            ...   \n",
       "0                                        0.993251   \n",
       "0                                        0.939731   \n",
       "0                                        0.782513   \n",
       "0                                        0.977970   \n",
       "0                                        0.948211   \n",
       "\n",
       "    ndcg_(human_annotation,rouge_l_(pred_cs, cs))  \\\n",
       "0                                        0.748487   \n",
       "0                                        0.811116   \n",
       "0                                        0.875021   \n",
       "0                                        0.964070   \n",
       "0                                        0.959804   \n",
       "..                                            ...   \n",
       "0                                        0.967758   \n",
       "0                                        0.982236   \n",
       "0                                        0.754485   \n",
       "0                                        0.796011   \n",
       "0                                        0.948211   \n",
       "\n",
       "    ndcg_(human_annotation,meteor_score_(pred_cs, cs))  \\\n",
       "0                                            0.762440    \n",
       "0                                            0.987254    \n",
       "0                                            0.957321    \n",
       "0                                            0.959804    \n",
       "0                                            0.959804    \n",
       "..                                                ...    \n",
       "0                                            0.957321    \n",
       "0                                            0.977970    \n",
       "0                                            0.977970    \n",
       "0                                            0.984718    \n",
       "0                                            0.948211    \n",
       "\n",
       "    ndcg_(human_annotation,bert_score_(pred_cs, cs))  \n",
       "0                                           0.800277  \n",
       "0                                           0.758173  \n",
       "0                                           0.722243  \n",
       "0                                           0.728992  \n",
       "0                                           0.758173  \n",
       "..                                               ...  \n",
       "0                                           0.847222  \n",
       "0                                           0.977970  \n",
       "0                                           0.833146  \n",
       "0                                           0.937248  \n",
       "0                                           0.823862  \n",
       "\n",
       "[61 rows x 31 columns]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ranking['rank_gpt-o'] = y_pred_rankings\n",
    "# x = df_ranking[['gpt-4o', 'rank_gpt-o']].explode(['gpt-4o','rank_gpt-o'])\n",
    "# x = x.rename(columns={'gpt-4o': 'uuid_ranking'})\n",
    "# y = df_analysis[['hatespeech', 'csType', 'uuid_ranking']].merge(x, on=['uuid_ranking'])\n",
    "# assert y.shape[0] == df_analysis.shape[0]\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.to_csv('/home/amey/temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_analysis.to_csv('/home/amey/depository/cs-eval/data/annotations/dataset_analysis_human_annotations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8632793397934301"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ndcg_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4e2db7d9-3560-4a83-bb7e-d756bede1130', 'c02a1ffc-e059-47a4-9140-4947d74c199e', 'feaaf02f-6bd1-44f2-a67a-3ec7354814ca', 'f4843a02-b80b-435c-8108-b23a8981e345', 'af361a88-2cbc-4d83-903d-e05c1014d02f']\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "['f4843a02-b80b-435c-8108-b23a8981e345', 'c02a1ffc-e059-47a4-9140-4947d74c199e', '4e2db7d9-3560-4a83-bb7e-d756bede1130', 'af361a88-2cbc-4d83-903d-e05c1014d02f', 'feaaf02f-6bd1-44f2-a67a-3ec7354814ca']\n",
      "NDCG score: 0.5965134711864127\n"
     ]
    }
   ],
   "source": [
    "def ndcg_score(y_true, y_pred, k=None):\n",
    "    \"\"\"\n",
    "    Compute the Normalized Discounted Cumulative Gain (NDCG) score.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (list): A list of strings representing the true ranking of items.\n",
    "    y_pred (list): A list of strings representing the predicted ranking of items.\n",
    "    k (int, optional): The number of top-ranked items to consider. If None, all items are considered.\n",
    "    \n",
    "    Returns:\n",
    "    float: The NDCG score.\n",
    "    \"\"\"\n",
    "    from math import log2\n",
    "    \n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(\"y_true and y_pred must have the same length.\")\n",
    "    \n",
    "    # Create a dictionary to store the relevance scores\n",
    "    relevance = {item: i+1 for i, item in enumerate(y_true)}\n",
    "    \n",
    "    # Compute the Discounted Cumulative Gain (DCG)\n",
    "    dcg = 0\n",
    "    for i, item in enumerate(y_pred):\n",
    "        if item in relevance:\n",
    "            rank = i + 1\n",
    "            dcg += (relevance[item] - 1) / log2(rank + 1)\n",
    "        if k is not None and rank >= k:\n",
    "            break\n",
    "    \n",
    "    # Compute the Ideal Discounted Cumulative Gain (IDCG)\n",
    "    idcg = sum(v / log2(i+2) for i, v in enumerate(range(len(y_true), 0, -1)))\n",
    "    \n",
    "    # Compute the NDCG score\n",
    "    ndcg = dcg / idcg\n",
    "    \n",
    "    return ndcg\n",
    "\n",
    "ranking1 = df_ranking.iloc[0]['human_annotation']\n",
    "ranking2 = df_ranking.iloc[0]['gpt-4o_zeroshot']\n",
    "\n",
    "print(ranking1)\n",
    "print(dashed_line)\n",
    "print(ranking2)\n",
    "\n",
    "score = ndcg_score(ranking1, ranking2)\n",
    "print(f\"NDCG score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 4, 1, 5, 2]] [[5, 4, 3, 2, 1]]\n",
      "NDCG score: 0.84\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Ground-truth relevance of some answers to a query\n",
    "true_relevance = np.asarray([[1, 2, 3, 4, 5]])\n",
    "\n",
    "# Predicted scores (relevance) for the answers\n",
    "scores = np.asarray([[5, 5, 5, 5, 5]])\n",
    "\n",
    "# Calculate NDCG score\n",
    "# ndcg = ndcg_score(true_relevance, scores)\n",
    "# print(f\"NDCG score: {ndcg:.2f}\")\n",
    "\n",
    "\n",
    "relevance_y_true = [[(len(ranking1)-i) for i, _ in enumerate(ranking1)]]\n",
    "relevance_y_pred = [[(len(ranking2) - ranking2.index(id)) for id in ranking1]]\n",
    "\n",
    "print(relevance_y_pred, relevance_y_true)\n",
    "ndcg = ndcg_score(relevance_y_true, relevance_y_pred)\n",
    "print(f\"NDCG score: {ndcg:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [x for x in df_analysis.columns if 'prediction_' in x and 'avg' in x]\n",
    "# cols\n",
    "# model_specific_rankings = {}\n",
    "# for model in model_name_mappings:\n",
    "#     rank_col = [x for x in cols if model in x][0]\n",
    "#     df_sorted = sample_df.sort_values(by=col, ascending=False)\n",
    "#     ranks = df_sorted['uuid_ranking'].values.tolist()\n",
    "#     if model_name_mappings[model] in model_specific_rankings:\n",
    "#         model_specific_rankings[model_name_mappings[model]].append(ranks)\n",
    "#     else:\n",
    "#         model_specific_rankings[model_name_mappings[model]] = [ranks]\n",
    "\n",
    "# df_ranking = pd.concat((df_ranking,pd.DataFrame.from_dict(model_specific_rankings)))\n",
    "# df_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human Eval table - Just finish for Gods Sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traditional_metrics = [\n",
    "'bleu_1_(pred_cs, cs)',\n",
    " 'bleu_2_(pred_cs, cs)',\n",
    " 'bleu_3_(pred_cs, cs)',\n",
    " 'bleu_4_(pred_cs, cs)',\n",
    " 'rouge_1_(pred_cs, cs)',\n",
    " 'rouge_2_(pred_cs, cs)',\n",
    " 'rouge_l_(pred_cs, cs)',\n",
    " 'meteor_score_(pred_cs, cs)',\n",
    "#  'bert_score_(hs, pred_cs)',\n",
    " 'bert_score_(pred_cs, cs)',\n",
    "#  'bart_score_(hs, pred_cs)',\n",
    "#  'bart_score_(cs, pred_cs)',\n",
    "#  'bart_score_(hs, pred_cs)',\n",
    "#  'pc_score_(hs, pred_cs)',\n",
    "#  'aq_score_(pred_cs)',\n",
    "#  'cd_score_(hs, pred_cs)',\n",
    "#  'pd_score(hs, pred_cs)',\n",
    "#  'negative_pc_score_(hs, pred_cs)',\n",
    "#  'toxicity_(pred_cs)',\n",
    "#  'obscenity_(pred_cs)',\n",
    "#  'identity_attack_(pred_cs)',\n",
    "#  'insult_(pred_cs)'\n",
    "#  'bart_score_(pred_cs, cs)',\n",
    "]\n",
    "\n",
    "unieval_cols = [\n",
    "    'aggressiveness_UniEval',\n",
    " 'coherence_UniEval',\n",
    " 'relevance_UniEval',\n",
    " 'suitableness_UniEval',\n",
    "]\n",
    "\n",
    "prediction_cols = [\n",
    " 'gpt-4-zs_relevance_score',\n",
    " 'gpt-4-zs_coherence_score',\n",
    " 'gpt-4-zs_aggressiveness_score',\n",
    " 'gpt-4-zs_suitableness_score',\n",
    " 'zs_Llama-3-8b-chat-hf_relevance_score',\n",
    " 'zs_Llama-3-8b-chat-hf_coherence_score',\n",
    " 'zs_Llama-3-8b-chat-hf_suitableness_score',\n",
    " 'zs_Llama-3-8b-chat-hf_aggressiveness_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_relevance_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_coherence_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_suitableness_score',\n",
    " 'zs_Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    " 'GEVAL_gpt-4_aggressiveness_score',\n",
    "  'GEVAL_gpt-4_coherence_score',\n",
    "  'GEVAL_gpt-4_relevance_score',\n",
    "  'GEVAL_gpt-4_suitableness_score',\n",
    " 'GEVAL_Llama-3-8b-chat-hf_aggressiveness_score',\n",
    " 'GEVAL_Llama-3-8b-chat-hf_coherence_score',\n",
    " 'GEVAL_Llama-3-8b-chat-hf_relevance_score',\n",
    " 'GEVAL_Llama-3-8b-chat-hf_suitableness_score',\n",
    " 'GEVAL_Mistral-7B-Instruct-v03_coherence_score',\n",
    " 'GEVAL_Mistral-7B-Instruct-v03_relevance_score',\n",
    " 'GEVAL_Mistral-7B-Instruct-v03_suitableness_score',\n",
    " 'GEVAL_Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    " 'Llama-3-8b-chat-hf_relevance_score',\n",
    " 'Llama-3-8b-chat-hf_coherence_score',\n",
    " 'Llama-3-8b-chat-hf_suitableness_score',\n",
    " 'Llama-3-8b-chat-hf_aggressiveness_score',\n",
    " 'Mistral-7B-Instruct-v03_relevance_score',\n",
    " 'Mistral-7B-Instruct-v03_coherence_score',\n",
    " 'Mistral-7B-Instruct-v03_suitableness_score',\n",
    " 'Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    " 'gpt-4_relevance_score',\n",
    " 'gpt-4_aggressiveness_score',\n",
    " 'gpt-4_coherence_score',\n",
    " 'gpt-4_suitableness_score'\n",
    " ]\n",
    "\n",
    "human_ratings = ['relevance_score', 'aggressiveness_score', 'coherence_score', 'suitableness_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>source</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_relevance</th>\n",
       "      <th>prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_coherence</th>\n",
       "      <th>...</th>\n",
       "      <th>rouge_2_(pred_cs, cs)</th>\n",
       "      <th>meteor_score_(pred_cs, cs)</th>\n",
       "      <th>bert_score_(hs, pred_cs)</th>\n",
       "      <th>toxicity_(pred_cs)</th>\n",
       "      <th>pc_score_(hs, pred_cs)</th>\n",
       "      <th>negative_pc_score_(hs, pred_cs)</th>\n",
       "      <th>cd_score_(hs, pred_cs)</th>\n",
       "      <th>aq_score_(pred_cs)</th>\n",
       "      <th>pd_score(hs, pred_csv)</th>\n",
       "      <th>bert_score_(pred_cs, cs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>islam only a religion of per just wrong. peace...</td>\n",
       "      <td>GPS</td>\n",
       "      <td>944ec738-ee5e-40d6-8493-93c1eb8b403e</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.871862</td>\n",
       "      <td>0.457112</td>\n",
       "      <td>0.723042</td>\n",
       "      <td>-0.723042</td>\n",
       "      <td>0.35685</td>\n",
       "      <td>0.492228</td>\n",
       "      <td>-0.366192</td>\n",
       "      <td>0.8534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                                  hatespeech      csType  \\\n",
       "0        0      0  Above all Islam is a religion of conquest.  Denouncing   \n",
       "\n",
       "                                       counterspeech  \\\n",
       "0  No, islam is a religion of 1.6 billion people ...   \n",
       "\n",
       "                             predicted_counterspeech source  \\\n",
       "0  islam only a religion of per just wrong. peace...    GPS   \n",
       "\n",
       "                                   uuid  \\\n",
       "0  944ec738-ee5e-40d6-8493-93c1eb8b403e   \n",
       "\n",
       "   prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_relevance  \\\n",
       "0                                                2.0                  \n",
       "\n",
       "   prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_coherence  ...  \\\n",
       "0                                                2.0                 ...   \n",
       "\n",
       "   rouge_2_(pred_cs, cs)  meteor_score_(pred_cs, cs)  \\\n",
       "0               0.137931                    0.154321   \n",
       "\n",
       "   bert_score_(hs, pred_cs)  toxicity_(pred_cs)  pc_score_(hs, pred_cs)  \\\n",
       "0                  0.871862            0.457112                0.723042   \n",
       "\n",
       "   negative_pc_score_(hs, pred_cs)  cd_score_(hs, pred_cs)  \\\n",
       "0                        -0.723042                 0.35685   \n",
       "\n",
       "   aq_score_(pred_cs)  pd_score(hs, pred_csv)  bert_score_(pred_cs, cs)  \n",
       "0            0.492228               -0.366192                    0.8534  \n",
       "\n",
       "[1 rows x 59 columns]"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anal = pd.read_csv('/home/amey/depository/cs-eval/data/annotations/df_analysis_human_annotation_metrics_calculated.csv')\n",
    "print(df_anal.shape)\n",
    "df_anal.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>bleu_1_(pred_cs, cs)</th>\n",
       "      <th>bleu_2_(pred_cs, cs)</th>\n",
       "      <th>bleu_3_(pred_cs, cs)</th>\n",
       "      <th>bleu_4_(pred_cs, cs)</th>\n",
       "      <th>rouge_1_(pred_cs, cs)</th>\n",
       "      <th>rouge_2_(pred_cs, cs)</th>\n",
       "      <th>rouge_l_(pred_cs, cs)</th>\n",
       "      <th>meteor_score_(pred_cs, cs)</th>\n",
       "      <th>bert_score_(pred_cs, cs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.031888</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.028614</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.856686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.131926</td>\n",
       "      <td>0.830768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.018386</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.853999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.018174</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.854176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  bleu_1_(pred_cs, cs)  bleu_2_(pred_cs, cs)  bleu_3_(pred_cs, cs)  \\\n",
       "0      0              0.062500              0.031888              0.002702   \n",
       "1      1              0.058824              0.028614              0.002603   \n",
       "2      2              0.013889              0.002453              0.000247   \n",
       "3      3              0.041667              0.018386              0.001648   \n",
       "4      4              0.041667              0.018174              0.001631   \n",
       "\n",
       "   bleu_4_(pred_cs, cs)  rouge_1_(pred_cs, cs)  rouge_2_(pred_cs, cs)  \\\n",
       "0              0.001368               0.275862               0.137931   \n",
       "1              0.001317               0.193548               0.000000   \n",
       "2              0.000124               0.081633               0.037037   \n",
       "3              0.000830               0.270270               0.000000   \n",
       "4              0.000821               0.216216               0.000000   \n",
       "\n",
       "   rouge_l_(pred_cs, cs)  meteor_score_(pred_cs, cs)  bert_score_(pred_cs, cs)  \n",
       "0               0.275862                    0.154321                  0.853400  \n",
       "1               0.129032                    0.092593                  0.856686  \n",
       "2               0.081633                    0.131926                  0.830768  \n",
       "3               0.108108                    0.176471                  0.853999  \n",
       "4               0.108108                    0.147059                  0.854176  "
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anal = df_anal[traditional_metrics]\n",
    "df_anal = df_anal.reset_index()\n",
    "print(df_anal.shape)\n",
    "df_anal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in traditional_metrics:\n",
    "#     if col in df_analysis.columns:\n",
    "#         df_analysis = df_analysis.drop(columns=col)\n",
    "#     df_analysis.drop(columns='uuid', inplace=True)\n",
    "\n",
    "df_analysis = pd.concat([df_analysis, df_anal], axis=1)\n",
    "# pd.concat([df_analysis, df_anal], axis=1).shape\n",
    "# assert df_analysis.shape[0] == 305\n",
    "# df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>source</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_relevance</th>\n",
       "      <th>prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_coherence</th>\n",
       "      <th>...</th>\n",
       "      <th>index</th>\n",
       "      <th>bleu_1_(pred_cs, cs)</th>\n",
       "      <th>bleu_2_(pred_cs, cs)</th>\n",
       "      <th>bleu_3_(pred_cs, cs)</th>\n",
       "      <th>bleu_4_(pred_cs, cs)</th>\n",
       "      <th>rouge_1_(pred_cs, cs)</th>\n",
       "      <th>rouge_2_(pred_cs, cs)</th>\n",
       "      <th>rouge_l_(pred_cs, cs)</th>\n",
       "      <th>meteor_score_(pred_cs, cs)</th>\n",
       "      <th>bert_score_(pred_cs, cs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>islam only a religion of per just wrong. peace...</td>\n",
       "      <td>GPS</td>\n",
       "      <td>944ec738-ee5e-40d6-8493-93c1eb8b403e</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.031888</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Is it fair to judge an entire religious group ...</td>\n",
       "      <td>QUARC</td>\n",
       "      <td>b0e53c71-0567-4052-971c-d777b9fcdc1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.028614</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.856686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>I must strongly denounce your offensive statem...</td>\n",
       "      <td>GPT3.5_ZS</td>\n",
       "      <td>b0449292-e5b5-4e0a-b36e-8eaabc0d3915</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.131926</td>\n",
       "      <td>0.830768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Generalizing about Muslims based on the action...</td>\n",
       "      <td>GPT3.5_FS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.018386</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.853999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Above all Islam is a religion of conquest.</td>\n",
       "      <td>Denouncing</td>\n",
       "      <td>No, islam is a religion of 1.6 billion people ...</td>\n",
       "      <td>Stereotyping Muslims based on the actions of a...</td>\n",
       "      <td>dialoGPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.018174</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.854176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                                  hatespeech      csType  \\\n",
       "0        0      0  Above all Islam is a religion of conquest.  Denouncing   \n",
       "1        1      1  Above all Islam is a religion of conquest.  Denouncing   \n",
       "2        2      2  Above all Islam is a religion of conquest.  Denouncing   \n",
       "3        3      3  Above all Islam is a religion of conquest.  Denouncing   \n",
       "4        4      4  Above all Islam is a religion of conquest.  Denouncing   \n",
       "\n",
       "                                       counterspeech  \\\n",
       "0  No, islam is a religion of 1.6 billion people ...   \n",
       "1  No, islam is a religion of 1.6 billion people ...   \n",
       "2  No, islam is a religion of 1.6 billion people ...   \n",
       "3  No, islam is a religion of 1.6 billion people ...   \n",
       "4  No, islam is a religion of 1.6 billion people ...   \n",
       "\n",
       "                             predicted_counterspeech     source  \\\n",
       "0  islam only a religion of per just wrong. peace...        GPS   \n",
       "1  Is it fair to judge an entire religious group ...      QUARC   \n",
       "2  I must strongly denounce your offensive statem...  GPT3.5_ZS   \n",
       "3  Generalizing about Muslims based on the action...  GPT3.5_FS   \n",
       "4  Stereotyping Muslims based on the actions of a...   dialoGPT   \n",
       "\n",
       "                                   uuid  \\\n",
       "0  944ec738-ee5e-40d6-8493-93c1eb8b403e   \n",
       "1  b0e53c71-0567-4052-971c-d777b9fcdc1a   \n",
       "2  b0449292-e5b5-4e0a-b36e-8eaabc0d3915   \n",
       "3                                   NaN   \n",
       "4                                   NaN   \n",
       "\n",
       "   prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_relevance  \\\n",
       "0                                                2.0                  \n",
       "1                                                4.0                  \n",
       "2                                                5.0                  \n",
       "3                                                4.0                  \n",
       "4                                                4.0                  \n",
       "\n",
       "   prediction_mistralai-Mistral-7B-Instruct-v0.3_zeroshot_coherence  ...  \\\n",
       "0                                                2.0                 ...   \n",
       "1                                                5.0                 ...   \n",
       "2                                                5.0                 ...   \n",
       "3                                                5.0                 ...   \n",
       "4                                                4.0                 ...   \n",
       "\n",
       "   index  bleu_1_(pred_cs, cs)  bleu_2_(pred_cs, cs)  bleu_3_(pred_cs, cs)  \\\n",
       "0      0              0.062500              0.031888              0.002702   \n",
       "1      1              0.058824              0.028614              0.002603   \n",
       "2      2              0.013889              0.002453              0.000247   \n",
       "3      3              0.041667              0.018386              0.001648   \n",
       "4      4              0.041667              0.018174              0.001631   \n",
       "\n",
       "   bleu_4_(pred_cs, cs)  rouge_1_(pred_cs, cs)  rouge_2_(pred_cs, cs)  \\\n",
       "0              0.001368               0.275862               0.137931   \n",
       "1              0.001317               0.193548               0.000000   \n",
       "2              0.000124               0.081633               0.037037   \n",
       "3              0.000830               0.270270               0.000000   \n",
       "4              0.000821               0.216216               0.000000   \n",
       "\n",
       "   rouge_l_(pred_cs, cs)  meteor_score_(pred_cs, cs)  bert_score_(pred_cs, cs)  \n",
       "0               0.275862                    0.154321                  0.853400  \n",
       "1               0.129032                    0.092593                  0.856686  \n",
       "2               0.081633                    0.131926                  0.830768  \n",
       "3               0.108108                    0.176471                  0.853999  \n",
       "4               0.108108                    0.147059                  0.854176  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat = pd.concat([df_analysis, df_anal], axis=1)\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_analysis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ranking.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for Model A: 0.33173591402082847\n",
      "p-value for Model B: 0.014306057386159976\n",
      "p-value for Model C: 0.02856527352376914\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Example t-statistics\n",
    "t_A = 1.155\n",
    "t_B = 5.135\n",
    "t_C = 3.970\n",
    "df = 3  # degrees of freedom\n",
    "\n",
    "# Calculate p-values (two-tailed)\n",
    "p_A = 2 * (1 - stats.t.cdf(abs(t_A), df))\n",
    "p_B = 2 * (1 - stats.t.cdf(abs(t_B), df))\n",
    "p_C = 2 * (1 - stats.t.cdf(abs(t_C), df))\n",
    "\n",
    "print(f\"p-value for Model A: {p_A}\")\n",
    "print(f\"p-value for Model B: {p_B}\")\n",
    "print(f\"p-value for Model C: {p_C}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model  Spearman Correlation (ρ)  t-statistic   p-value\n",
      "0  Model A                  0.800000     2.309401  0.104088\n",
      "1  Model B                  0.974679     7.549834  0.004818\n",
      "2  Model C                  0.900000     3.576237  0.037386\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, t\n",
    "\n",
    "# Sample data: Ground truth ratings and model ratings\n",
    "data = {\n",
    "    'Ground Truth': [4, 3, 5, 2, 1],\n",
    "    'Model A': [5, 3, 4, 1, 2],\n",
    "    'Model B': [4, 2, 5, 2, 1],\n",
    "    'Model C': [3, 4, 5, 2, 1]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to compute Spearman correlation, t-statistic, and p-value\n",
    "def compute_statistics(df, model_col):\n",
    "    # Calculate Spearman correlation\n",
    "    rho, _ = spearmanr(df['Ground Truth'], df[model_col])\n",
    "    \n",
    "    # Number of observations\n",
    "    n = len(df)\n",
    "    \n",
    "    # Calculate t-statistic\n",
    "    t_statistic = (rho * np.sqrt(n - 2)) / np.sqrt(1 - rho**2)\n",
    "    \n",
    "    # Degrees of freedom\n",
    "    df = n - 2\n",
    "    \n",
    "    # Calculate p-value (two-tailed)\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(t_statistic), df))\n",
    "    \n",
    "    return rho, t_statistic, p_value\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "# Compute statistics for each model\n",
    "for model in df.columns[1:]:\n",
    "    rho, t_stat, p_val = compute_statistics(df, model)\n",
    "    results.append({\n",
    "        'Model': model,\n",
    "        'Spearman Correlation (ρ)': rho,\n",
    "        't-statistic': t_stat,\n",
    "        'p-value': p_val\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Model A</th>\n",
       "      <th>Model B</th>\n",
       "      <th>Model C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ground Truth  Model A  Model B  Model C\n",
       "0             4        5        4        3\n",
       "1             3        3        2        4\n",
       "2             5        4        5        5\n",
       "3             2        1        2        2\n",
       "4             1        2        1        1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>suitableness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>aggressiveness_score</th>\n",
       "      <th>annotator</th>\n",
       "      <th>...</th>\n",
       "      <th>GEVAL_Llama-3-8b-chat-hf_aggressiveness_score</th>\n",
       "      <th>GEVAL_gpt-4_coherence_score</th>\n",
       "      <th>GEVAL_Llama-3-8b-chat-hf_coherence_score</th>\n",
       "      <th>GEVAL_Mistral-7B-Instruct-v03_coherence_score</th>\n",
       "      <th>GEVAL_gpt-4_relevance_score</th>\n",
       "      <th>GEVAL_Llama-3-8b-chat-hf_relevance_score</th>\n",
       "      <th>GEVAL_Mistral-7B-Instruct-v03_relevance_score</th>\n",
       "      <th>GEVAL_gpt-4_suitableness_score</th>\n",
       "      <th>GEVAL_Mistral-7B-Instruct-v03_suitableness_score</th>\n",
       "      <th>GEVAL_Llama-3-8b-chat-hf_suitableness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Islam is a destructive force in the world.</td>\n",
       "      <td>Can we generalize about an entire religion? is...</td>\n",
       "      <td>How can you generalize an entire religion base...</td>\n",
       "      <td>Questioning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                  hatespeech  \\\n",
       "1540    NaN  Islam is a destructive force in the world.   \n",
       "\n",
       "                                          counterspeech  \\\n",
       "1540  Can we generalize about an entire religion? is...   \n",
       "\n",
       "                                predicted_counterspeech       csType  \\\n",
       "1540  How can you generalize an entire religion base...  Questioning   \n",
       "\n",
       "      suitableness_score  relevance_score  coherence_score  \\\n",
       "1540                 2.0              5.0              3.0   \n",
       "\n",
       "      aggressiveness_score annotator  ...  \\\n",
       "1540                   1.0       NaN  ...   \n",
       "\n",
       "     GEVAL_Llama-3-8b-chat-hf_aggressiveness_score  \\\n",
       "1540                                           1.0   \n",
       "\n",
       "     GEVAL_gpt-4_coherence_score  GEVAL_Llama-3-8b-chat-hf_coherence_score  \\\n",
       "1540                         2.0                                       2.0   \n",
       "\n",
       "      GEVAL_Mistral-7B-Instruct-v03_coherence_score  \\\n",
       "1540                                            4.0   \n",
       "\n",
       "      GEVAL_gpt-4_relevance_score  GEVAL_Llama-3-8b-chat-hf_relevance_score  \\\n",
       "1540                          5.0                                       4.0   \n",
       "\n",
       "      GEVAL_Mistral-7B-Instruct-v03_relevance_score  \\\n",
       "1540                                            5.0   \n",
       "\n",
       "      GEVAL_gpt-4_suitableness_score  \\\n",
       "1540                             2.0   \n",
       "\n",
       "      GEVAL_Mistral-7B-Instruct-v03_suitableness_score  \\\n",
       "1540                                               3.0   \n",
       "\n",
       "      GEVAL_Llama-3-8b-chat-hf_suitableness_score  \n",
       "1540                                          2.0  \n",
       "\n",
       "[1 rows x 81 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.read_csv('/home/amey/depository/cs-eval/emnlp_2024_analysis/analysis_metrics_computed_renamed_cols.csv')\n",
    "df_results = df_results.sample(5000)\n",
    "df_results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "hatespeech\n",
      "counterspeech\n",
      "predicted_counterspeech\n",
      "csType\n",
      "suitableness_score\n",
      "relevance_score\n",
      "coherence_score\n",
      "aggressiveness_score\n",
      "annotator\n",
      "source\n",
      "uuid\n",
      "id\n",
      "bart_score_(cs, pred_cs)\n",
      "bart_score_(hs, pred_cs)\n",
      "bart_score_(pred_cs, cs)\n",
      "coherence_UniEval\n",
      "relevance_UniEval\n",
      "aggressiveness_UniEval\n",
      "suitableness_UniEval\n",
      "bm25_score_(pred_cs, cs)\n",
      "bm25_score_(hs, pred_cs)\n",
      "mauve_score_(hs, pred_cs)\n",
      "mauve_score_(pred_cs, cs)\n",
      "bleu_1_(pred_cs, cs)\n",
      "bleu_2_(pred_cs, cs)\n",
      "bleu_3_(pred_cs, cs)\n",
      "bleu_4_(pred_cs, cs)\n",
      "rouge_1_(pred_cs, cs)\n",
      "rouge_2_(pred_cs, cs)\n",
      "rouge_l_(pred_cs, cs)\n",
      "meteor_score_(pred_cs, cs)\n",
      "bert_score_(hs, pred_cs)\n",
      "bert_score_(pred_cs, cs)\n",
      "pc_score_(hs, pred_cs)\n",
      "aq_score_(pred_cs)\n",
      "cd_score_(hs, pred_cs)\n",
      "pd_score(hs, pred_cs)\n",
      "negative_pc_score_(hs, pred_cs)\n",
      "toxicity_(pred_cs)\n",
      "obscenity_(pred_cs)\n",
      "identity_attack_(pred_cs)\n",
      "insult_(pred_cs)\n",
      "gpt-4_relevance_score\n",
      "gpt-4_aggressiveness_score\n",
      "gpt-4_coherence_score\n",
      "gpt-4_suitableness_score\n",
      "gpt-4_suitablness_score\n",
      "gpt-4-zs_relevance_score\n",
      "gpt-4-zs_coherence_score\n",
      "gpt-4-zs_aggressiveness_score\n",
      "gpt-4-zs_suitableness_score\n",
      "gpt-4-zs_relevance_score\"\n",
      "Llama-3-8b-chat-hf_relevance_score\n",
      "Llama-3-8b-chat-hf_coherence_score\n",
      "Llama-3-8b-chat-hf_suitableness_score\n",
      "Llama-3-8b-chat-hf_aggressiveness_score\n",
      "zs_Llama-3-8b-chat-hf_relevance_score\n",
      "zs_Llama-3-8b-chat-hf_coherence_score\n",
      "zs_Llama-3-8b-chat-hf_suitableness_score\n",
      "zs_Llama-3-8b-chat-hf_aggressiveness_score\n",
      "Mistral-7B-Instruct-v03_relevance_score\n",
      "Mistral-7B-Instruct-v03_coherence_score\n",
      "Mistral-7B-Instruct-v03_suitableness_score\n",
      "Mistral-7B-Instruct-v03_aggressiveness_score\n",
      "zs_Mistral-7B-Instruct-v03_relevance_score\n",
      "zs_Mistral-7B-Instruct-v03_coherence_score\n",
      "zs_Mistral-7B-Instruct-v03_suitableness_score\n",
      "zs_Mistral-7B-Instruct-v03_aggressiveness_score\n",
      "GEVAL_gpt-4_aggressiveness_score\n",
      "GEVAL_Mistral-7B-Instruct-v03_aggressiveness_score\n",
      "GEVAL_Llama-3-8b-chat-hf_aggressiveness_score\n",
      "GEVAL_gpt-4_coherence_score\n",
      "GEVAL_Llama-3-8b-chat-hf_coherence_score\n",
      "GEVAL_Mistral-7B-Instruct-v03_coherence_score\n",
      "GEVAL_gpt-4_relevance_score\n",
      "GEVAL_Llama-3-8b-chat-hf_relevance_score\n",
      "GEVAL_Mistral-7B-Instruct-v03_relevance_score\n",
      "GEVAL_gpt-4_suitableness_score\n",
      "GEVAL_Mistral-7B-Instruct-v03_suitableness_score\n",
      "GEVAL_Llama-3-8b-chat-hf_suitableness_score\n"
     ]
    }
   ],
   "source": [
    "for col in df_results.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "traditional_metrics = [\n",
    "'bleu_1_(pred_cs, cs)',\n",
    "'bleu_2_(pred_cs, cs)',\n",
    "'bleu_3_(pred_cs, cs)',\n",
    "'bleu_4_(pred_cs, cs)',\n",
    "'rouge_1_(pred_cs, cs)',\n",
    "'rouge_2_(pred_cs, cs)',\n",
    "'rouge_l_(pred_cs, cs)',\n",
    "'meteor_score_(pred_cs, cs)',\n",
    "'bert_score_(pred_cs, cs)',\n",
    "'pc_score_(hs, pred_cs)',\n",
    "'aq_score_(pred_cs)',\n",
    "'pd_score(hs, pred_cs)',\n",
    "'negative_pc_score_(hs, pred_cs)',\n",
    "'toxicity_(pred_cs)',\n",
    "'bart_score_(pred_cs, cs)',\n",
    "]\n",
    "\n",
    "unieval_cols = [\n",
    "'aggressiveness_UniEval',\n",
    "'coherence_UniEval',\n",
    "'relevance_UniEval',\n",
    "'suitableness_UniEval',\n",
    "]\n",
    "\n",
    "prediction_cols = [\n",
    "'gpt-4-zs_relevance_score',\n",
    "'gpt-4-zs_coherence_score',\n",
    "'gpt-4-zs_aggressiveness_score',\n",
    "'gpt-4-zs_suitableness_score',\n",
    "'zs_Llama-3-8b-chat-hf_relevance_score',\n",
    "'zs_Llama-3-8b-chat-hf_coherence_score',\n",
    "'zs_Llama-3-8b-chat-hf_suitableness_score',\n",
    "'zs_Llama-3-8b-chat-hf_aggressiveness_score',\n",
    "'zs_Mistral-7B-Instruct-v03_relevance_score',\n",
    "'zs_Mistral-7B-Instruct-v03_coherence_score',\n",
    "'zs_Mistral-7B-Instruct-v03_suitableness_score',\n",
    "'zs_Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    "'GEVAL_gpt-4_aggressiveness_score',\n",
    "'GEVAL_gpt-4_coherence_score',\n",
    "'GEVAL_gpt-4_relevance_score',\n",
    "'GEVAL_gpt-4_suitableness_score',\n",
    "'GEVAL_Llama-3-8b-chat-hf_aggressiveness_score',\n",
    "'GEVAL_Llama-3-8b-chat-hf_coherence_score',\n",
    "'GEVAL_Llama-3-8b-chat-hf_relevance_score',\n",
    "'GEVAL_Llama-3-8b-chat-hf_suitableness_score',\n",
    "'GEVAL_Mistral-7B-Instruct-v03_coherence_score',\n",
    "'GEVAL_Mistral-7B-Instruct-v03_relevance_score',\n",
    "'GEVAL_Mistral-7B-Instruct-v03_suitableness_score',\n",
    "'GEVAL_Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    "'Llama-3-8b-chat-hf_relevance_score',\n",
    "'Llama-3-8b-chat-hf_coherence_score',\n",
    "'Llama-3-8b-chat-hf_suitableness_score',\n",
    "'Llama-3-8b-chat-hf_aggressiveness_score',\n",
    "'Mistral-7B-Instruct-v03_relevance_score',\n",
    "'Mistral-7B-Instruct-v03_coherence_score',\n",
    "'Mistral-7B-Instruct-v03_suitableness_score',\n",
    "'Mistral-7B-Instruct-v03_aggressiveness_score',\n",
    "'gpt-4_relevance_score',\n",
    "'gpt-4_aggressiveness_score',\n",
    "'gpt-4_coherence_score',\n",
    "'gpt-4_suitableness_score'\n",
    "]\n",
    "\n",
    "human_ratings = ['relevance_score', 'aggressiveness_score', 'coherence_score', 'suitableness_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coherence_score',\n",
       " 'gpt-4-zs_coherence_score',\n",
       " 'zs_Llama-3-8b-chat-hf_coherence_score',\n",
       " 'zs_Mistral-7B-Instruct-v03_coherence_score',\n",
       " 'GEVAL_gpt-4_coherence_score',\n",
       " 'GEVAL_Llama-3-8b-chat-hf_coherence_score',\n",
       " 'GEVAL_Mistral-7B-Instruct-v03_coherence_score',\n",
       " 'Llama-3-8b-chat-hf_coherence_score',\n",
       " 'Mistral-7B-Instruct-v03_coherence_score',\n",
       " 'gpt-4_coherence_score',\n",
       " 'coherence_UniEval',\n",
       " 'bleu_1_(pred_cs, cs)',\n",
       " 'bleu_2_(pred_cs, cs)',\n",
       " 'bleu_3_(pred_cs, cs)',\n",
       " 'bleu_4_(pred_cs, cs)',\n",
       " 'rouge_1_(pred_cs, cs)',\n",
       " 'rouge_2_(pred_cs, cs)',\n",
       " 'rouge_l_(pred_cs, cs)',\n",
       " 'meteor_score_(pred_cs, cs)',\n",
       " 'bert_score_(pred_cs, cs)',\n",
       " 'pc_score_(hs, pred_cs)',\n",
       " 'aq_score_(pred_cs)',\n",
       " 'pd_score(hs, pred_cs)',\n",
       " 'negative_pc_score_(hs, pred_cs)',\n",
       " 'toxicity_(pred_cs)',\n",
       " 'bart_score_(pred_cs, cs)']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute SS for Relevance\n",
    "aspect_name = 'coherence_score'\n",
    "y_pred_cols = [col for col in prediction_cols if aspect_name in col or f'{aspect_name}_UniEval' in col] + ['coherence_UniEval']\n",
    "y_pred_cols += traditional_metrics\n",
    "y_true_cols = [col for col in human_ratings if aspect_name in col]\n",
    "total_cols = y_true_cols + y_pred_cols\n",
    "total_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>gpt-4-zs_coherence_score</th>\n",
       "      <th>zs_Llama-3-8b-chat-hf_coherence_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_coherence_score</th>\n",
       "      <th>GEVAL_gpt-4_coherence_score</th>\n",
       "      <th>GEVAL_Llama-3-8b-chat-hf_coherence_score</th>\n",
       "      <th>GEVAL_Mistral-7B-Instruct-v03_coherence_score</th>\n",
       "      <th>Llama-3-8b-chat-hf_coherence_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_coherence_score</th>\n",
       "      <th>gpt-4_coherence_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rouge_2_(pred_cs, cs)</th>\n",
       "      <th>rouge_l_(pred_cs, cs)</th>\n",
       "      <th>meteor_score_(pred_cs, cs)</th>\n",
       "      <th>bert_score_(pred_cs, cs)</th>\n",
       "      <th>pc_score_(hs, pred_cs)</th>\n",
       "      <th>aq_score_(pred_cs)</th>\n",
       "      <th>pd_score(hs, pred_cs)</th>\n",
       "      <th>negative_pc_score_(hs, pred_cs)</th>\n",
       "      <th>toxicity_(pred_cs)</th>\n",
       "      <th>bart_score_(pred_cs, cs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.279243</td>\n",
       "      <td>0.894743</td>\n",
       "      <td>-0.816182</td>\n",
       "      <td>0.766144</td>\n",
       "      <td>1.755184</td>\n",
       "      <td>0.816182</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>-3.339529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>0.259558</td>\n",
       "      <td>0.855028</td>\n",
       "      <td>0.999399</td>\n",
       "      <td>0.924829</td>\n",
       "      <td>-0.003144</td>\n",
       "      <td>-0.999399</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>-3.288932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.070755</td>\n",
       "      <td>0.858426</td>\n",
       "      <td>0.998735</td>\n",
       "      <td>0.717073</td>\n",
       "      <td>-0.065075</td>\n",
       "      <td>-0.998735</td>\n",
       "      <td>0.120347</td>\n",
       "      <td>-3.895826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.108303</td>\n",
       "      <td>0.842483</td>\n",
       "      <td>0.998498</td>\n",
       "      <td>0.812375</td>\n",
       "      <td>-0.875203</td>\n",
       "      <td>-0.998498</td>\n",
       "      <td>0.011965</td>\n",
       "      <td>-3.423391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.844502</td>\n",
       "      <td>-0.921634</td>\n",
       "      <td>0.856986</td>\n",
       "      <td>1.532287</td>\n",
       "      <td>0.921634</td>\n",
       "      <td>0.089539</td>\n",
       "      <td>-2.931246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coherence_score  gpt-4-zs_coherence_score  \\\n",
       "1540              3.0                       3.0   \n",
       "2806              3.0                       5.0   \n",
       "4464              3.0                       4.0   \n",
       "4783              1.0                       1.0   \n",
       "3492              3.0                       3.0   \n",
       "\n",
       "      zs_Llama-3-8b-chat-hf_coherence_score  \\\n",
       "1540                                    3.0   \n",
       "2806                                    4.0   \n",
       "4464                                    4.0   \n",
       "4783                                    2.0   \n",
       "3492                                    3.0   \n",
       "\n",
       "      zs_Mistral-7B-Instruct-v03_coherence_score  GEVAL_gpt-4_coherence_score  \\\n",
       "1540                                         4.0                          2.0   \n",
       "2806                                         4.0                          2.0   \n",
       "4464                                         4.0                          2.0   \n",
       "4783                                         2.0                          2.0   \n",
       "3492                                         4.0                          4.0   \n",
       "\n",
       "      GEVAL_Llama-3-8b-chat-hf_coherence_score  \\\n",
       "1540                                       2.0   \n",
       "2806                                       4.0   \n",
       "4464                                       2.0   \n",
       "4783                                       2.0   \n",
       "3492                                       3.0   \n",
       "\n",
       "      GEVAL_Mistral-7B-Instruct-v03_coherence_score  \\\n",
       "1540                                            4.0   \n",
       "2806                                            4.0   \n",
       "4464                                            4.0   \n",
       "4783                                            3.0   \n",
       "3492                                            5.0   \n",
       "\n",
       "      Llama-3-8b-chat-hf_coherence_score  \\\n",
       "1540                                 2.0   \n",
       "2806                                 4.0   \n",
       "4464                                 2.0   \n",
       "4783                                 2.0   \n",
       "3492                                 3.0   \n",
       "\n",
       "      Mistral-7B-Instruct-v03_coherence_score  gpt-4_coherence_score  ...  \\\n",
       "1540                                      4.0                    2.0  ...   \n",
       "2806                                      4.0                    2.0  ...   \n",
       "4464                                      4.0                    2.0  ...   \n",
       "4783                                      3.0                    1.0  ...   \n",
       "3492                                      5.0                    3.0  ...   \n",
       "\n",
       "      rouge_2_(pred_cs, cs)  rouge_l_(pred_cs, cs)  \\\n",
       "1540               0.062500               0.294118   \n",
       "2806               0.051502               0.178344   \n",
       "4464               0.000000               0.058824   \n",
       "4783               0.000000               0.181818   \n",
       "3492               0.025974               0.173913   \n",
       "\n",
       "      meteor_score_(pred_cs, cs)  bert_score_(pred_cs, cs)  \\\n",
       "1540                    0.279243                  0.894743   \n",
       "2806                    0.259558                  0.855028   \n",
       "4464                    0.070755                  0.858426   \n",
       "4783                    0.108303                  0.842483   \n",
       "3492                    0.096875                  0.844502   \n",
       "\n",
       "      pc_score_(hs, pred_cs)  aq_score_(pred_cs)  pd_score(hs, pred_cs)  \\\n",
       "1540               -0.816182            0.766144               1.755184   \n",
       "2806                0.999399            0.924829              -0.003144   \n",
       "4464                0.998735            0.717073              -0.065075   \n",
       "4783                0.998498            0.812375              -0.875203   \n",
       "3492               -0.921634            0.856986               1.532287   \n",
       "\n",
       "      negative_pc_score_(hs, pred_cs)  toxicity_(pred_cs)  \\\n",
       "1540                         0.816182            0.000664   \n",
       "2806                        -0.999399            0.004222   \n",
       "4464                        -0.998735            0.120347   \n",
       "4783                        -0.998498            0.011965   \n",
       "3492                         0.921634            0.089539   \n",
       "\n",
       "      bart_score_(pred_cs, cs)  \n",
       "1540                 -3.339529  \n",
       "2806                 -3.288932  \n",
       "4464                 -3.895826  \n",
       "4783                 -3.423391  \n",
       "3492                 -2.931246  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_view = df_results[total_cols]\n",
    "df_view.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Spearman Correlation (ρ)</th>\n",
       "      <th>t-statistic</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-zs_coherence_score</td>\n",
       "      <td>0.439583</td>\n",
       "      <td>34.599106</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zs_Llama-3-8b-chat-hf_coherence_score</td>\n",
       "      <td>0.336586</td>\n",
       "      <td>25.269910</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zs_Mistral-7B-Instruct-v03_coherence_score</td>\n",
       "      <td>0.377003</td>\n",
       "      <td>28.776113</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GEVAL_gpt-4_coherence_score</td>\n",
       "      <td>0.583905</td>\n",
       "      <td>50.848662</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEVAL_Llama-3-8b-chat-hf_coherence_score</td>\n",
       "      <td>0.322556</td>\n",
       "      <td>24.091236</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GEVAL_Mistral-7B-Instruct-v03_coherence_score</td>\n",
       "      <td>0.346971</td>\n",
       "      <td>26.154451</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3-8b-chat-hf_coherence_score</td>\n",
       "      <td>0.330840</td>\n",
       "      <td>24.784963</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mistral-7B-Instruct-v03_coherence_score</td>\n",
       "      <td>0.355565</td>\n",
       "      <td>26.894710</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-4_coherence_score</td>\n",
       "      <td>0.601487</td>\n",
       "      <td>53.228117</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coherence_UniEval</td>\n",
       "      <td>0.169098</td>\n",
       "      <td>12.129294</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bleu_1_(pred_cs, cs)</td>\n",
       "      <td>0.102512</td>\n",
       "      <td>7.285658</td>\n",
       "      <td>3.701484e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bleu_2_(pred_cs, cs)</td>\n",
       "      <td>-0.232870</td>\n",
       "      <td>-16.928471</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bleu_3_(pred_cs, cs)</td>\n",
       "      <td>-0.252561</td>\n",
       "      <td>-18.453403</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bleu_4_(pred_cs, cs)</td>\n",
       "      <td>-0.252561</td>\n",
       "      <td>-18.453403</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rouge_1_(pred_cs, cs)</td>\n",
       "      <td>0.342799</td>\n",
       "      <td>25.797783</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rouge_2_(pred_cs, cs)</td>\n",
       "      <td>0.357343</td>\n",
       "      <td>27.048856</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rouge_l_(pred_cs, cs)</td>\n",
       "      <td>0.349490</td>\n",
       "      <td>26.370648</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>meteor_score_(pred_cs, cs)</td>\n",
       "      <td>0.354015</td>\n",
       "      <td>26.760687</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bert_score_(pred_cs, cs)</td>\n",
       "      <td>0.342531</td>\n",
       "      <td>25.774948</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pc_score_(hs, pred_cs)</td>\n",
       "      <td>-0.110515</td>\n",
       "      <td>-7.861213</td>\n",
       "      <td>4.662937e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aq_score_(pred_cs)</td>\n",
       "      <td>0.044943</td>\n",
       "      <td>3.180507</td>\n",
       "      <td>1.479162e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pd_score(hs, pred_cs)</td>\n",
       "      <td>0.133675</td>\n",
       "      <td>9.535941</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>negative_pc_score_(hs, pred_cs)</td>\n",
       "      <td>0.110515</td>\n",
       "      <td>7.861213</td>\n",
       "      <td>4.662937e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>toxicity_(pred_cs)</td>\n",
       "      <td>-0.195623</td>\n",
       "      <td>-14.102360</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bart_score_(pred_cs, cs)</td>\n",
       "      <td>0.383519</td>\n",
       "      <td>29.358405</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Model  Spearman Correlation (ρ)  \\\n",
       "0                        gpt-4-zs_coherence_score                  0.439583   \n",
       "1           zs_Llama-3-8b-chat-hf_coherence_score                  0.336586   \n",
       "2      zs_Mistral-7B-Instruct-v03_coherence_score                  0.377003   \n",
       "3                     GEVAL_gpt-4_coherence_score                  0.583905   \n",
       "4        GEVAL_Llama-3-8b-chat-hf_coherence_score                  0.322556   \n",
       "5   GEVAL_Mistral-7B-Instruct-v03_coherence_score                  0.346971   \n",
       "6              Llama-3-8b-chat-hf_coherence_score                  0.330840   \n",
       "7         Mistral-7B-Instruct-v03_coherence_score                  0.355565   \n",
       "8                           gpt-4_coherence_score                  0.601487   \n",
       "9                               coherence_UniEval                  0.169098   \n",
       "10                           bleu_1_(pred_cs, cs)                  0.102512   \n",
       "11                           bleu_2_(pred_cs, cs)                 -0.232870   \n",
       "12                           bleu_3_(pred_cs, cs)                 -0.252561   \n",
       "13                           bleu_4_(pred_cs, cs)                 -0.252561   \n",
       "14                          rouge_1_(pred_cs, cs)                  0.342799   \n",
       "15                          rouge_2_(pred_cs, cs)                  0.357343   \n",
       "16                          rouge_l_(pred_cs, cs)                  0.349490   \n",
       "17                     meteor_score_(pred_cs, cs)                  0.354015   \n",
       "18                       bert_score_(pred_cs, cs)                  0.342531   \n",
       "19                         pc_score_(hs, pred_cs)                 -0.110515   \n",
       "20                             aq_score_(pred_cs)                  0.044943   \n",
       "21                          pd_score(hs, pred_cs)                  0.133675   \n",
       "22                negative_pc_score_(hs, pred_cs)                  0.110515   \n",
       "23                             toxicity_(pred_cs)                 -0.195623   \n",
       "24                       bart_score_(pred_cs, cs)                  0.383519   \n",
       "\n",
       "    t-statistic       p-value  \n",
       "0     34.599106  0.000000e+00  \n",
       "1     25.269910  0.000000e+00  \n",
       "2     28.776113  0.000000e+00  \n",
       "3     50.848662  0.000000e+00  \n",
       "4     24.091236  0.000000e+00  \n",
       "5     26.154451  0.000000e+00  \n",
       "6     24.784963  0.000000e+00  \n",
       "7     26.894710  0.000000e+00  \n",
       "8     53.228117  0.000000e+00  \n",
       "9     12.129294  0.000000e+00  \n",
       "10     7.285658  3.701484e-13  \n",
       "11   -16.928471  0.000000e+00  \n",
       "12   -18.453403  0.000000e+00  \n",
       "13   -18.453403  0.000000e+00  \n",
       "14    25.797783  0.000000e+00  \n",
       "15    27.048856  0.000000e+00  \n",
       "16    26.370648  0.000000e+00  \n",
       "17    26.760687  0.000000e+00  \n",
       "18    25.774948  0.000000e+00  \n",
       "19    -7.861213  4.662937e-15  \n",
       "20     3.180507  1.479162e-03  \n",
       "21     9.535941  0.000000e+00  \n",
       "22     7.861213  4.662937e-15  \n",
       "23   -14.102360  0.000000e+00  \n",
       "24    29.358405  0.000000e+00  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to compute Spearman correlation, t-statistic, and p-value\n",
    "def compute_statistics(df, model_col, y_true_col):\n",
    "    # Calculate Spearman correlation\n",
    "    rho, _ = spearmanr(df[y_true_col], df[model_col])\n",
    "    \n",
    "    # Number of observations\n",
    "    n = len(df)\n",
    "    \n",
    "    # Calculate t-statistic\n",
    "    t_statistic = (rho * np.sqrt(n - 2)) / np.sqrt(1 - rho**2)\n",
    "    \n",
    "    # Degrees of freedom\n",
    "    df = n - 2\n",
    "    \n",
    "    # Calculate p-value (two-tailed)\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(t_statistic), df))\n",
    "    \n",
    "    return rho, t_statistic, p_value\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "# Compute statistics for each model\n",
    "for model in df_view.columns[1:]:\n",
    "    rho, t_stat, p_val = compute_statistics(df_view, model, y_true_col=\"coherence_score\")\n",
    "    results.append({\n",
    "        'Model': model,\n",
    "        'Spearman Correlation (ρ)': rho,\n",
    "        't-statistic': t_stat,\n",
    "        'p-value': p_val\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "statistical_test_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "# print(statistical_test_df)\n",
    "statistical_test_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.000000\n",
       "1     0.000000\n",
       "2     0.000000\n",
       "3     0.000000\n",
       "4     0.000000\n",
       "5     0.000000\n",
       "6     0.000000\n",
       "7     0.000000\n",
       "8     0.000000\n",
       "9     0.000000\n",
       "10    0.000000\n",
       "11    0.000000\n",
       "12    0.000000\n",
       "13    0.000000\n",
       "14    0.000000\n",
       "15    0.000000\n",
       "16    0.000000\n",
       "17    0.000000\n",
       "18    0.000000\n",
       "19    0.000000\n",
       "20    0.001479\n",
       "21    0.000000\n",
       "22    0.000000\n",
       "23    0.000000\n",
       "24    0.000000\n",
       "Name: p-value, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_test_df['p-value'].round(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Spearman Correlation (ρ)</th>\n",
       "      <th>t-statistic</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEVAL_Llama-3-8b-chat-hf_coherence_score</td>\n",
       "      <td>0.322556</td>\n",
       "      <td>24.091236</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GEVAL_Mistral-7B-Instruct-v03_coherence_score</td>\n",
       "      <td>0.346971</td>\n",
       "      <td>26.154451</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GEVAL_gpt-4_coherence_score</td>\n",
       "      <td>0.583905</td>\n",
       "      <td>50.848662</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3-8b-chat-hf_coherence_score</td>\n",
       "      <td>0.330840</td>\n",
       "      <td>24.784963</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mistral-7B-Instruct-v03_coherence_score</td>\n",
       "      <td>0.355565</td>\n",
       "      <td>26.894710</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aq_score_(pred_cs)</td>\n",
       "      <td>0.044943</td>\n",
       "      <td>3.180507</td>\n",
       "      <td>1.479162e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bart_score_(pred_cs, cs)</td>\n",
       "      <td>0.383519</td>\n",
       "      <td>29.358405</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bert_score_(pred_cs, cs)</td>\n",
       "      <td>0.342531</td>\n",
       "      <td>25.774948</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bleu_1_(pred_cs, cs)</td>\n",
       "      <td>0.102512</td>\n",
       "      <td>7.285658</td>\n",
       "      <td>3.701484e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bleu_2_(pred_cs, cs)</td>\n",
       "      <td>-0.232870</td>\n",
       "      <td>-16.928471</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bleu_3_(pred_cs, cs)</td>\n",
       "      <td>-0.252561</td>\n",
       "      <td>-18.453403</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bleu_4_(pred_cs, cs)</td>\n",
       "      <td>-0.252561</td>\n",
       "      <td>-18.453403</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coherence_UniEval</td>\n",
       "      <td>0.169098</td>\n",
       "      <td>12.129294</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-zs_coherence_score</td>\n",
       "      <td>0.439583</td>\n",
       "      <td>34.599106</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-4_coherence_score</td>\n",
       "      <td>0.601487</td>\n",
       "      <td>53.228117</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>meteor_score_(pred_cs, cs)</td>\n",
       "      <td>0.354015</td>\n",
       "      <td>26.760687</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>negative_pc_score_(hs, pred_cs)</td>\n",
       "      <td>0.110515</td>\n",
       "      <td>7.861213</td>\n",
       "      <td>4.662937e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pc_score_(hs, pred_cs)</td>\n",
       "      <td>-0.110515</td>\n",
       "      <td>-7.861213</td>\n",
       "      <td>4.662937e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pd_score(hs, pred_cs)</td>\n",
       "      <td>0.133675</td>\n",
       "      <td>9.535941</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rouge_1_(pred_cs, cs)</td>\n",
       "      <td>0.342799</td>\n",
       "      <td>25.797783</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rouge_2_(pred_cs, cs)</td>\n",
       "      <td>0.357343</td>\n",
       "      <td>27.048856</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rouge_l_(pred_cs, cs)</td>\n",
       "      <td>0.349490</td>\n",
       "      <td>26.370648</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>toxicity_(pred_cs)</td>\n",
       "      <td>-0.195623</td>\n",
       "      <td>-14.102360</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zs_Llama-3-8b-chat-hf_coherence_score</td>\n",
       "      <td>0.336586</td>\n",
       "      <td>25.269910</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zs_Mistral-7B-Instruct-v03_coherence_score</td>\n",
       "      <td>0.377003</td>\n",
       "      <td>28.776113</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Model  Spearman Correlation (ρ)  \\\n",
       "4        GEVAL_Llama-3-8b-chat-hf_coherence_score                  0.322556   \n",
       "5   GEVAL_Mistral-7B-Instruct-v03_coherence_score                  0.346971   \n",
       "3                     GEVAL_gpt-4_coherence_score                  0.583905   \n",
       "6              Llama-3-8b-chat-hf_coherence_score                  0.330840   \n",
       "7         Mistral-7B-Instruct-v03_coherence_score                  0.355565   \n",
       "20                             aq_score_(pred_cs)                  0.044943   \n",
       "24                       bart_score_(pred_cs, cs)                  0.383519   \n",
       "18                       bert_score_(pred_cs, cs)                  0.342531   \n",
       "10                           bleu_1_(pred_cs, cs)                  0.102512   \n",
       "11                           bleu_2_(pred_cs, cs)                 -0.232870   \n",
       "12                           bleu_3_(pred_cs, cs)                 -0.252561   \n",
       "13                           bleu_4_(pred_cs, cs)                 -0.252561   \n",
       "9                               coherence_UniEval                  0.169098   \n",
       "0                        gpt-4-zs_coherence_score                  0.439583   \n",
       "8                           gpt-4_coherence_score                  0.601487   \n",
       "17                     meteor_score_(pred_cs, cs)                  0.354015   \n",
       "22                negative_pc_score_(hs, pred_cs)                  0.110515   \n",
       "19                         pc_score_(hs, pred_cs)                 -0.110515   \n",
       "21                          pd_score(hs, pred_cs)                  0.133675   \n",
       "14                          rouge_1_(pred_cs, cs)                  0.342799   \n",
       "15                          rouge_2_(pred_cs, cs)                  0.357343   \n",
       "16                          rouge_l_(pred_cs, cs)                  0.349490   \n",
       "23                             toxicity_(pred_cs)                 -0.195623   \n",
       "1           zs_Llama-3-8b-chat-hf_coherence_score                  0.336586   \n",
       "2      zs_Mistral-7B-Instruct-v03_coherence_score                  0.377003   \n",
       "\n",
       "    t-statistic       p-value  \n",
       "4     24.091236  0.000000e+00  \n",
       "5     26.154451  0.000000e+00  \n",
       "3     50.848662  0.000000e+00  \n",
       "6     24.784963  0.000000e+00  \n",
       "7     26.894710  0.000000e+00  \n",
       "20     3.180507  1.479162e-03  \n",
       "24    29.358405  0.000000e+00  \n",
       "18    25.774948  0.000000e+00  \n",
       "10     7.285658  3.701484e-13  \n",
       "11   -16.928471  0.000000e+00  \n",
       "12   -18.453403  0.000000e+00  \n",
       "13   -18.453403  0.000000e+00  \n",
       "9     12.129294  0.000000e+00  \n",
       "0     34.599106  0.000000e+00  \n",
       "8     53.228117  0.000000e+00  \n",
       "17    26.760687  0.000000e+00  \n",
       "22     7.861213  4.662937e-15  \n",
       "19    -7.861213  4.662937e-15  \n",
       "21     9.535941  0.000000e+00  \n",
       "14    25.797783  0.000000e+00  \n",
       "15    27.048856  0.000000e+00  \n",
       "16    26.370648  0.000000e+00  \n",
       "23   -14.102360  0.000000e+00  \n",
       "1     25.269910  0.000000e+00  \n",
       "2     28.776113  0.000000e+00  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_test_df.head()\n",
    "statistical_test_df = statistical_test_df.sort_values(by='Model')\n",
    "statistical_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_test_df.to_csv('/home/amey/depository/cs-eval/statistical_tests/coherence_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict = {}\n",
    "\n",
    "results_dict['coherence'] = statistical_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Spearman Correlation (ρ)_coherence</th>\n",
       "      <th>t-statistic_coherence</th>\n",
       "      <th>p-value_coherence</th>\n",
       "      <th>Spearman Correlation (ρ)_coherence</th>\n",
       "      <th>t-statistic_coherence</th>\n",
       "      <th>p-value_coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aq_score_(pred_cs)</td>\n",
       "      <td>0.273408</td>\n",
       "      <td>8.979414</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.169892</td>\n",
       "      <td>5.446264</td>\n",
       "      <td>6.477786e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart_score_(pred_cs, cs)</td>\n",
       "      <td>0.253230</td>\n",
       "      <td>8.269349</td>\n",
       "      <td>4.440892e-16</td>\n",
       "      <td>0.259169</td>\n",
       "      <td>8.477075</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert_score_(pred_cs, cs)</td>\n",
       "      <td>0.075047</td>\n",
       "      <td>2.377528</td>\n",
       "      <td>1.761669e-02</td>\n",
       "      <td>0.066599</td>\n",
       "      <td>2.108631</td>\n",
       "      <td>3.522511e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bleu_1_(pred_cs, cs)</td>\n",
       "      <td>0.022391</td>\n",
       "      <td>0.707539</td>\n",
       "      <td>4.793966e-01</td>\n",
       "      <td>-0.014509</td>\n",
       "      <td>-0.458419</td>\n",
       "      <td>6.467514e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bleu_2_(pred_cs, cs)</td>\n",
       "      <td>-0.316866</td>\n",
       "      <td>-10.553986</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.437443</td>\n",
       "      <td>-15.367679</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bleu_3_(pred_cs, cs)</td>\n",
       "      <td>-0.322465</td>\n",
       "      <td>-10.761921</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.447044</td>\n",
       "      <td>-15.788084</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bleu_4_(pred_cs, cs)</td>\n",
       "      <td>-0.322465</td>\n",
       "      <td>-10.761921</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.447044</td>\n",
       "      <td>-15.788084</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meteor_score_(pred_cs, cs)</td>\n",
       "      <td>0.257354</td>\n",
       "      <td>8.413506</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.285534</td>\n",
       "      <td>9.412179</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>negative_pc_score_(hs, pred_cs)</td>\n",
       "      <td>0.155645</td>\n",
       "      <td>4.977654</td>\n",
       "      <td>7.578055e-07</td>\n",
       "      <td>0.096535</td>\n",
       "      <td>3.063976</td>\n",
       "      <td>2.242796e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pc_score_(hs, pred_cs)</td>\n",
       "      <td>-0.155645</td>\n",
       "      <td>-4.977654</td>\n",
       "      <td>7.578055e-07</td>\n",
       "      <td>-0.096535</td>\n",
       "      <td>-3.063976</td>\n",
       "      <td>2.242796e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pd_score(hs, pred_cs)</td>\n",
       "      <td>0.303376</td>\n",
       "      <td>10.058010</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.197373</td>\n",
       "      <td>6.360369</td>\n",
       "      <td>3.059777e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rouge_1_(pred_cs, cs)</td>\n",
       "      <td>0.139018</td>\n",
       "      <td>4.434803</td>\n",
       "      <td>1.023818e-05</td>\n",
       "      <td>0.114565</td>\n",
       "      <td>3.643215</td>\n",
       "      <td>2.831142e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rouge_2_(pred_cs, cs)</td>\n",
       "      <td>0.176280</td>\n",
       "      <td>5.657481</td>\n",
       "      <td>2.005923e-08</td>\n",
       "      <td>0.164640</td>\n",
       "      <td>5.273112</td>\n",
       "      <td>1.644337e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rouge_l_(pred_cs, cs)</td>\n",
       "      <td>0.172653</td>\n",
       "      <td>5.537466</td>\n",
       "      <td>3.923695e-08</td>\n",
       "      <td>0.162735</td>\n",
       "      <td>5.210448</td>\n",
       "      <td>2.288504e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>toxicity_(pred_cs)</td>\n",
       "      <td>0.046166</td>\n",
       "      <td>1.459996</td>\n",
       "      <td>1.446060e-01</td>\n",
       "      <td>-0.137822</td>\n",
       "      <td>-4.395896</td>\n",
       "      <td>1.221341e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Spearman Correlation (ρ)_coherence  \\\n",
       "0                aq_score_(pred_cs)                            0.273408   \n",
       "1          bart_score_(pred_cs, cs)                            0.253230   \n",
       "2          bert_score_(pred_cs, cs)                            0.075047   \n",
       "3              bleu_1_(pred_cs, cs)                            0.022391   \n",
       "4              bleu_2_(pred_cs, cs)                           -0.316866   \n",
       "5              bleu_3_(pred_cs, cs)                           -0.322465   \n",
       "6              bleu_4_(pred_cs, cs)                           -0.322465   \n",
       "7        meteor_score_(pred_cs, cs)                            0.257354   \n",
       "8   negative_pc_score_(hs, pred_cs)                            0.155645   \n",
       "9            pc_score_(hs, pred_cs)                           -0.155645   \n",
       "10            pd_score(hs, pred_cs)                            0.303376   \n",
       "11            rouge_1_(pred_cs, cs)                            0.139018   \n",
       "12            rouge_2_(pred_cs, cs)                            0.176280   \n",
       "13            rouge_l_(pred_cs, cs)                            0.172653   \n",
       "14               toxicity_(pred_cs)                            0.046166   \n",
       "\n",
       "    t-statistic_coherence  p-value_coherence  \\\n",
       "0                8.979414       0.000000e+00   \n",
       "1                8.269349       4.440892e-16   \n",
       "2                2.377528       1.761669e-02   \n",
       "3                0.707539       4.793966e-01   \n",
       "4              -10.553986       0.000000e+00   \n",
       "5              -10.761921       0.000000e+00   \n",
       "6              -10.761921       0.000000e+00   \n",
       "7                8.413506       0.000000e+00   \n",
       "8                4.977654       7.578055e-07   \n",
       "9               -4.977654       7.578055e-07   \n",
       "10              10.058010       0.000000e+00   \n",
       "11               4.434803       1.023818e-05   \n",
       "12               5.657481       2.005923e-08   \n",
       "13               5.537466       3.923695e-08   \n",
       "14               1.459996       1.446060e-01   \n",
       "\n",
       "    Spearman Correlation (ρ)_coherence  t-statistic_coherence  \\\n",
       "0                             0.169892               5.446264   \n",
       "1                             0.259169               8.477075   \n",
       "2                             0.066599               2.108631   \n",
       "3                            -0.014509              -0.458419   \n",
       "4                            -0.437443             -15.367679   \n",
       "5                            -0.447044             -15.788084   \n",
       "6                            -0.447044             -15.788084   \n",
       "7                             0.285534               9.412179   \n",
       "8                             0.096535               3.063976   \n",
       "9                            -0.096535              -3.063976   \n",
       "10                            0.197373               6.360369   \n",
       "11                            0.114565               3.643215   \n",
       "12                            0.164640               5.273112   \n",
       "13                            0.162735               5.210448   \n",
       "14                           -0.137822              -4.395896   \n",
       "\n",
       "    p-value_coherence  \n",
       "0        6.477786e-08  \n",
       "1        0.000000e+00  \n",
       "2        3.522511e-02  \n",
       "3        6.467514e-01  \n",
       "4        0.000000e+00  \n",
       "5        0.000000e+00  \n",
       "6        0.000000e+00  \n",
       "7        0.000000e+00  \n",
       "8        2.242796e-03  \n",
       "9        2.242796e-03  \n",
       "10       3.059777e-10  \n",
       "11       2.831142e-04  \n",
       "12       1.644337e-07  \n",
       "13       2.288504e-07  \n",
       "14       1.221341e-05  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_aggregted = pd.DataFrame()\n",
    "\n",
    "for key in results_dict:\n",
    "    df = results_dict[key]\n",
    "    if result_aggregted.shape[0] == 0:\n",
    "        result_aggregted = result_aggregted.merge(df)\n",
    "    else:\n",
    "        result_aggregted = result_aggregted.merge(df, on=[\"Model\"],suffixes=[f'_{key}',f'_{key}'])\n",
    "\n",
    "result_aggregted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Spearman Correlation (ρ)_aggressiveness</th>\n",
       "      <th>t-statistic_aggressiveness</th>\n",
       "      <th>p-value_aggressiveness</th>\n",
       "      <th>Spearman Correlation (ρ)_aggressiveness</th>\n",
       "      <th>t-statistic_aggressiveness</th>\n",
       "      <th>p-value_aggressiveness</th>\n",
       "      <th>Spearman Correlation (ρ)_suitableness</th>\n",
       "      <th>t-statistic_suitableness</th>\n",
       "      <th>p-value_suitableness</th>\n",
       "      <th>Spearman Correlation (ρ)_suitableness</th>\n",
       "      <th>t-statistic_suitableness</th>\n",
       "      <th>p-value_suitableness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aq_score_(pred_cs)</td>\n",
       "      <td>0.139648</td>\n",
       "      <td>11.391146</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.014866</td>\n",
       "      <td>1.200861</td>\n",
       "      <td>2.298489e-01</td>\n",
       "      <td>0.051013</td>\n",
       "      <td>4.125790</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.051901</td>\n",
       "      <td>4.197743</td>\n",
       "      <td>2.731700e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart_score_(pred_cs, cs)</td>\n",
       "      <td>0.276174</td>\n",
       "      <td>23.209640</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.196778</td>\n",
       "      <td>-16.210928</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.388745</td>\n",
       "      <td>34.079955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255486</td>\n",
       "      <td>21.344271</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert_score_(pred_cs, cs)</td>\n",
       "      <td>0.222516</td>\n",
       "      <td>18.435056</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.074823</td>\n",
       "      <td>-6.060545</td>\n",
       "      <td>1.432281e-09</td>\n",
       "      <td>0.347490</td>\n",
       "      <td>29.932473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250449</td>\n",
       "      <td>20.894989</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bleu_1_(pred_cs, cs)</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.134975</td>\n",
       "      <td>8.926358e-01</td>\n",
       "      <td>-0.137347</td>\n",
       "      <td>-11.199802</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.104392</td>\n",
       "      <td>8.478206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009767</td>\n",
       "      <td>0.788954</td>\n",
       "      <td>4.301674e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bleu_2_(pred_cs, cs)</td>\n",
       "      <td>-0.075129</td>\n",
       "      <td>-6.085463</td>\n",
       "      <td>1.227414e-09</td>\n",
       "      <td>0.155197</td>\n",
       "      <td>12.689240</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.230571</td>\n",
       "      <td>-19.139197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.097109</td>\n",
       "      <td>-7.880858</td>\n",
       "      <td>3.774758e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bleu_3_(pred_cs, cs)</td>\n",
       "      <td>-0.090728</td>\n",
       "      <td>-7.358526</td>\n",
       "      <td>2.087219e-13</td>\n",
       "      <td>0.159741</td>\n",
       "      <td>13.070286</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.251044</td>\n",
       "      <td>-20.947949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.114336</td>\n",
       "      <td>-9.296003</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bleu_4_(pred_cs, cs)</td>\n",
       "      <td>-0.090728</td>\n",
       "      <td>-7.358526</td>\n",
       "      <td>2.087219e-13</td>\n",
       "      <td>0.159741</td>\n",
       "      <td>13.070286</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.251044</td>\n",
       "      <td>-20.947949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.114336</td>\n",
       "      <td>-9.296003</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meteor_score_(pred_cs, cs)</td>\n",
       "      <td>0.171473</td>\n",
       "      <td>14.058355</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.204731</td>\n",
       "      <td>-16.894225</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.352934</td>\n",
       "      <td>30.467594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166009</td>\n",
       "      <td>13.597465</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>negative_pc_score_(hs, pred_cs)</td>\n",
       "      <td>-0.018940</td>\n",
       "      <td>-1.530103</td>\n",
       "      <td>1.260397e-01</td>\n",
       "      <td>-0.221548</td>\n",
       "      <td>-18.350705</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.105847</td>\n",
       "      <td>8.597737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.379971</td>\n",
       "      <td>7.039791e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pc_score_(hs, pred_cs)</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>1.530103</td>\n",
       "      <td>1.260397e-01</td>\n",
       "      <td>0.221548</td>\n",
       "      <td>18.350705</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.105847</td>\n",
       "      <td>-8.597737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004704</td>\n",
       "      <td>-0.379971</td>\n",
       "      <td>7.039791e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pd_score(hs, pred_cs)</td>\n",
       "      <td>0.116384</td>\n",
       "      <td>9.464844</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.137078</td>\n",
       "      <td>-11.177486</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.136305</td>\n",
       "      <td>11.113224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084349</td>\n",
       "      <td>6.837341</td>\n",
       "      <td>8.799850e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rouge_1_(pred_cs, cs)</td>\n",
       "      <td>0.200069</td>\n",
       "      <td>16.493269</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.166764</td>\n",
       "      <td>-13.661071</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.343821</td>\n",
       "      <td>29.573817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193223</td>\n",
       "      <td>15.906627</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rouge_2_(pred_cs, cs)</td>\n",
       "      <td>0.199803</td>\n",
       "      <td>16.470450</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.211784</td>\n",
       "      <td>-17.503126</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.359001</td>\n",
       "      <td>31.068095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.221370</td>\n",
       "      <td>18.335249</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rouge_l_(pred_cs, cs)</td>\n",
       "      <td>0.201989</td>\n",
       "      <td>16.658283</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.162727</td>\n",
       "      <td>-13.321206</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.351699</td>\n",
       "      <td>30.345847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.199067</td>\n",
       "      <td>16.407273</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>toxicity_(pred_cs)</td>\n",
       "      <td>-0.022423</td>\n",
       "      <td>-1.811574</td>\n",
       "      <td>7.009803e-02</td>\n",
       "      <td>0.282617</td>\n",
       "      <td>23.797512</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.191298</td>\n",
       "      <td>-15.742088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.109086</td>\n",
       "      <td>-8.863894</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Spearman Correlation (ρ)_aggressiveness  \\\n",
       "0                aq_score_(pred_cs)                                 0.139648   \n",
       "1          bart_score_(pred_cs, cs)                                 0.276174   \n",
       "2          bert_score_(pred_cs, cs)                                 0.222516   \n",
       "3              bleu_1_(pred_cs, cs)                                 0.001671   \n",
       "4              bleu_2_(pred_cs, cs)                                -0.075129   \n",
       "5              bleu_3_(pred_cs, cs)                                -0.090728   \n",
       "6              bleu_4_(pred_cs, cs)                                -0.090728   \n",
       "7        meteor_score_(pred_cs, cs)                                 0.171473   \n",
       "8   negative_pc_score_(hs, pred_cs)                                -0.018940   \n",
       "9            pc_score_(hs, pred_cs)                                 0.018940   \n",
       "10            pd_score(hs, pred_cs)                                 0.116384   \n",
       "11            rouge_1_(pred_cs, cs)                                 0.200069   \n",
       "12            rouge_2_(pred_cs, cs)                                 0.199803   \n",
       "13            rouge_l_(pred_cs, cs)                                 0.201989   \n",
       "14               toxicity_(pred_cs)                                -0.022423   \n",
       "\n",
       "    t-statistic_aggressiveness  p-value_aggressiveness  \\\n",
       "0                    11.391146            0.000000e+00   \n",
       "1                    23.209640            0.000000e+00   \n",
       "2                    18.435056            0.000000e+00   \n",
       "3                     0.134975            8.926358e-01   \n",
       "4                    -6.085463            1.227414e-09   \n",
       "5                    -7.358526            2.087219e-13   \n",
       "6                    -7.358526            2.087219e-13   \n",
       "7                    14.058355            0.000000e+00   \n",
       "8                    -1.530103            1.260397e-01   \n",
       "9                     1.530103            1.260397e-01   \n",
       "10                    9.464844            0.000000e+00   \n",
       "11                   16.493269            0.000000e+00   \n",
       "12                   16.470450            0.000000e+00   \n",
       "13                   16.658283            0.000000e+00   \n",
       "14                   -1.811574            7.009803e-02   \n",
       "\n",
       "    Spearman Correlation (ρ)_aggressiveness  t-statistic_aggressiveness  \\\n",
       "0                                  0.014866                    1.200861   \n",
       "1                                 -0.196778                  -16.210928   \n",
       "2                                 -0.074823                   -6.060545   \n",
       "3                                 -0.137347                  -11.199802   \n",
       "4                                  0.155197                   12.689240   \n",
       "5                                  0.159741                   13.070286   \n",
       "6                                  0.159741                   13.070286   \n",
       "7                                 -0.204731                  -16.894225   \n",
       "8                                 -0.221548                  -18.350705   \n",
       "9                                  0.221548                   18.350705   \n",
       "10                                -0.137078                  -11.177486   \n",
       "11                                -0.166764                  -13.661071   \n",
       "12                                -0.211784                  -17.503126   \n",
       "13                                -0.162727                  -13.321206   \n",
       "14                                 0.282617                   23.797512   \n",
       "\n",
       "    p-value_aggressiveness  Spearman Correlation (ρ)_suitableness  \\\n",
       "0             2.298489e-01                               0.051013   \n",
       "1             0.000000e+00                               0.388745   \n",
       "2             1.432281e-09                               0.347490   \n",
       "3             0.000000e+00                               0.104392   \n",
       "4             0.000000e+00                              -0.230571   \n",
       "5             0.000000e+00                              -0.251044   \n",
       "6             0.000000e+00                              -0.251044   \n",
       "7             0.000000e+00                               0.352934   \n",
       "8             0.000000e+00                               0.105847   \n",
       "9             0.000000e+00                              -0.105847   \n",
       "10            0.000000e+00                               0.136305   \n",
       "11            0.000000e+00                               0.343821   \n",
       "12            0.000000e+00                               0.359001   \n",
       "13            0.000000e+00                               0.351699   \n",
       "14            0.000000e+00                              -0.191298   \n",
       "\n",
       "    t-statistic_suitableness  p-value_suitableness  \\\n",
       "0                   4.125790              0.000037   \n",
       "1                  34.079955              0.000000   \n",
       "2                  29.932473              0.000000   \n",
       "3                   8.478206              0.000000   \n",
       "4                 -19.139197              0.000000   \n",
       "5                 -20.947949              0.000000   \n",
       "6                 -20.947949              0.000000   \n",
       "7                  30.467594              0.000000   \n",
       "8                   8.597737              0.000000   \n",
       "9                  -8.597737              0.000000   \n",
       "10                 11.113224              0.000000   \n",
       "11                 29.573817              0.000000   \n",
       "12                 31.068095              0.000000   \n",
       "13                 30.345847              0.000000   \n",
       "14                -15.742088              0.000000   \n",
       "\n",
       "    Spearman Correlation (ρ)_suitableness  t-statistic_suitableness  \\\n",
       "0                                0.051901                  4.197743   \n",
       "1                                0.255486                 21.344271   \n",
       "2                                0.250449                 20.894989   \n",
       "3                                0.009767                  0.788954   \n",
       "4                               -0.097109                 -7.880858   \n",
       "5                               -0.114336                 -9.296003   \n",
       "6                               -0.114336                 -9.296003   \n",
       "7                                0.166009                 13.597465   \n",
       "8                                0.004704                  0.379971   \n",
       "9                               -0.004704                 -0.379971   \n",
       "10                               0.084349                  6.837341   \n",
       "11                               0.193223                 15.906627   \n",
       "12                               0.221370                 18.335249   \n",
       "13                               0.199067                 16.407273   \n",
       "14                              -0.109086                 -8.863894   \n",
       "\n",
       "    p-value_suitableness  \n",
       "0           2.731700e-05  \n",
       "1           0.000000e+00  \n",
       "2           0.000000e+00  \n",
       "3           4.301674e-01  \n",
       "4           3.774758e-15  \n",
       "5           0.000000e+00  \n",
       "6           0.000000e+00  \n",
       "7           0.000000e+00  \n",
       "8           7.039791e-01  \n",
       "9           7.039791e-01  \n",
       "10          8.799850e-12  \n",
       "11          0.000000e+00  \n",
       "12          0.000000e+00  \n",
       "13          0.000000e+00  \n",
       "14          0.000000e+00  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_cols = [\"Model\"] + [col for col in result_aggregted.columns if 'p-' in col]\n",
    "result_aggregted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_aggregted.to_csv('/home/amey/depository/cs-eval/statistical_tests/top_100_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Model</th>\n",
       "      <th>Spearman Correlation (ρ)_aggressiveness</th>\n",
       "      <th>t-statistic_aggressiveness</th>\n",
       "      <th>p-value_aggressiveness</th>\n",
       "      <th>Spearman Correlation (ρ)_aggressiveness.1</th>\n",
       "      <th>t-statistic_aggressiveness.1</th>\n",
       "      <th>p-value_aggressiveness.1</th>\n",
       "      <th>Spearman Correlation (ρ)_suitableness</th>\n",
       "      <th>t-statistic_suitableness</th>\n",
       "      <th>p-value_suitableness</th>\n",
       "      <th>Spearman Correlation (ρ)_suitableness.1</th>\n",
       "      <th>t-statistic_suitableness.1</th>\n",
       "      <th>p-value_suitableness.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aq_score_(pred_cs)</td>\n",
       "      <td>0.139648</td>\n",
       "      <td>11.391146</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.014866</td>\n",
       "      <td>1.200861</td>\n",
       "      <td>2.298489e-01</td>\n",
       "      <td>0.051013</td>\n",
       "      <td>4.125790</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.051901</td>\n",
       "      <td>4.197743</td>\n",
       "      <td>2.731700e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bart_score_(pred_cs, cs)</td>\n",
       "      <td>0.276174</td>\n",
       "      <td>23.209640</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.196778</td>\n",
       "      <td>-16.210928</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.388745</td>\n",
       "      <td>34.079955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255486</td>\n",
       "      <td>21.344271</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bert_score_(pred_cs, cs)</td>\n",
       "      <td>0.222516</td>\n",
       "      <td>18.435056</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.074823</td>\n",
       "      <td>-6.060545</td>\n",
       "      <td>1.432281e-09</td>\n",
       "      <td>0.347490</td>\n",
       "      <td>29.932473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250449</td>\n",
       "      <td>20.894989</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bleu_1_(pred_cs, cs)</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.134975</td>\n",
       "      <td>8.926358e-01</td>\n",
       "      <td>-0.137347</td>\n",
       "      <td>-11.199802</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.104392</td>\n",
       "      <td>8.478206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009767</td>\n",
       "      <td>0.788954</td>\n",
       "      <td>4.301674e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bleu_2_(pred_cs, cs)</td>\n",
       "      <td>-0.075129</td>\n",
       "      <td>-6.085463</td>\n",
       "      <td>1.227414e-09</td>\n",
       "      <td>0.155197</td>\n",
       "      <td>12.689240</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.230571</td>\n",
       "      <td>-19.139197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.097109</td>\n",
       "      <td>-7.880858</td>\n",
       "      <td>3.774758e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     Model  \\\n",
       "0           0        aq_score_(pred_cs)   \n",
       "1           1  bart_score_(pred_cs, cs)   \n",
       "2           2  bert_score_(pred_cs, cs)   \n",
       "3           3      bleu_1_(pred_cs, cs)   \n",
       "4           4      bleu_2_(pred_cs, cs)   \n",
       "\n",
       "   Spearman Correlation (ρ)_aggressiveness  t-statistic_aggressiveness  \\\n",
       "0                                 0.139648                   11.391146   \n",
       "1                                 0.276174                   23.209640   \n",
       "2                                 0.222516                   18.435056   \n",
       "3                                 0.001671                    0.134975   \n",
       "4                                -0.075129                   -6.085463   \n",
       "\n",
       "   p-value_aggressiveness  Spearman Correlation (ρ)_aggressiveness.1  \\\n",
       "0            0.000000e+00                                   0.014866   \n",
       "1            0.000000e+00                                  -0.196778   \n",
       "2            0.000000e+00                                  -0.074823   \n",
       "3            8.926358e-01                                  -0.137347   \n",
       "4            1.227414e-09                                   0.155197   \n",
       "\n",
       "   t-statistic_aggressiveness.1  p-value_aggressiveness.1  \\\n",
       "0                      1.200861              2.298489e-01   \n",
       "1                    -16.210928              0.000000e+00   \n",
       "2                     -6.060545              1.432281e-09   \n",
       "3                    -11.199802              0.000000e+00   \n",
       "4                     12.689240              0.000000e+00   \n",
       "\n",
       "   Spearman Correlation (ρ)_suitableness  t-statistic_suitableness  \\\n",
       "0                               0.051013                  4.125790   \n",
       "1                               0.388745                 34.079955   \n",
       "2                               0.347490                 29.932473   \n",
       "3                               0.104392                  8.478206   \n",
       "4                              -0.230571                -19.139197   \n",
       "\n",
       "   p-value_suitableness  Spearman Correlation (ρ)_suitableness.1  \\\n",
       "0              0.000037                                 0.051901   \n",
       "1              0.000000                                 0.255486   \n",
       "2              0.000000                                 0.250449   \n",
       "3              0.000000                                 0.009767   \n",
       "4              0.000000                                -0.097109   \n",
       "\n",
       "   t-statistic_suitableness.1  p-value_suitableness.1  \n",
       "0                    4.197743            2.731700e-05  \n",
       "1                   21.344271            0.000000e+00  \n",
       "2                   20.894989            0.000000e+00  \n",
       "3                    0.788954            4.301674e-01  \n",
       "4                   -7.880858            3.774758e-15  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/amey/depository/cs-eval/statistical_tests/complete_results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### paired t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=25, step=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/amey/depository/cs-eval/statistical_tests/aggressiveness_complete.csv')\n",
    "df = df[['Model', 'Spearman Correlation (ρ)']]\n",
    "df = df.transpose()\n",
    "# df = df.reset_index(drop=True)\n",
    "df.head(5)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coherence_score results are not normally distributed (p=0.000)\n",
      "Model gpt-4-zs_coherence_score results are not normally distributed (p=0.000)\n",
      "Model zs_Llama-3-8b-chat-hf_coherence_score results are not normally distributed (p=0.000)\n",
      "Model zs_Mistral-7B-Instruct-v03_coherence_score results are not normally distributed (p=0.000)\n",
      "Model GEVAL_gpt-4_coherence_score results are not normally distributed (p=0.000)\n",
      "Model GEVAL_Llama-3-8b-chat-hf_coherence_score results are not normally distributed (p=0.000)\n",
      "Model GEVAL_Mistral-7B-Instruct-v03_coherence_score results are not normally distributed (p=0.000)\n",
      "Model Llama-3-8b-chat-hf_coherence_score results are not normally distributed (p=0.000)\n",
      "Model Mistral-7B-Instruct-v03_coherence_score results are not normally distributed (p=0.000)\n",
      "Model gpt-4_coherence_score results are not normally distributed (p=0.000)\n",
      "Model coherence_UniEval results are not normally distributed (p=0.000)\n",
      "Model bleu_1_(pred_cs, cs) results are not normally distributed (p=0.000)\n",
      "Model bleu_2_(pred_cs, cs) results are not normally distributed (p=0.000)\n",
      "Model bleu_3_(pred_cs, cs) results are not normally distributed (p=0.000)\n",
      "Model bleu_4_(pred_cs, cs) results are not normally distributed (p=0.000)\n",
      "Model rouge_1_(pred_cs, cs) results are not normally distributed (p=0.000)\n",
      "Model rouge_2_(pred_cs, cs) results are not normally distributed (p=0.000)\n",
      "Model rouge_l_(pred_cs, cs) results are not normally distributed (p=0.000)\n",
      "Model meteor_score_(pred_cs, cs) results are not normally distributed (p=0.000)\n",
      "Model bert_score_(pred_cs, cs) results are not normally distributed (p=0.000)\n",
      "Model pc_score_(hs, pred_cs) results are not normally distributed (p=0.000)\n",
      "Model aq_score_(pred_cs) results are not normally distributed (p=0.000)\n",
      "Model pd_score(hs, pred_cs) results are not normally distributed (p=0.000)\n",
      "Model negative_pc_score_(hs, pred_cs) results are not normally distributed (p=0.000)\n",
      "Model toxicity_(pred_cs) results are not normally distributed (p=0.000)\n",
      "Model bart_score_(pred_cs, cs) results are not normally distributed (p=0.000)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "columns = df.columns.tolist()\n",
    "for model in columns:\n",
    "    results = df_view[model]\n",
    "    _, p_value = shapiro(results)\n",
    "    if p_value < 0.05:\n",
    "        print(f\"Model {model} results are not normally distributed (p={p_value:.3f})\")\n",
    "    else:\n",
    "        print(f\"Model {model} results are normally distributed (p={p_value:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggressiveness_scorespearman</th>\n",
       "      <th>metric</th>\n",
       "      <th>aggressiveness_scorekendalltau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.137347</td>\n",
       "      <td>bleu_1_(pred_cs, cs)</td>\n",
       "      <td>-0.113858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155197</td>\n",
       "      <td>bleu_2_(pred_cs, cs)</td>\n",
       "      <td>0.119664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.159741</td>\n",
       "      <td>bleu_3_(pred_cs, cs)</td>\n",
       "      <td>0.123370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159741</td>\n",
       "      <td>bleu_4_(pred_cs, cs)</td>\n",
       "      <td>0.123370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.166764</td>\n",
       "      <td>rouge_1_(pred_cs, cs)</td>\n",
       "      <td>-0.130036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aggressiveness_scorespearman                 metric  \\\n",
       "0                     -0.137347   bleu_1_(pred_cs, cs)   \n",
       "1                      0.155197   bleu_2_(pred_cs, cs)   \n",
       "2                      0.159741   bleu_3_(pred_cs, cs)   \n",
       "3                      0.159741   bleu_4_(pred_cs, cs)   \n",
       "4                     -0.166764  rouge_1_(pred_cs, cs)   \n",
       "\n",
       "   aggressiveness_scorekendalltau  \n",
       "0                       -0.113858  \n",
       "1                        0.119664  \n",
       "2                        0.123370  \n",
       "3                        0.123370  \n",
       "4                       -0.130036  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('/home/amey/depository/cs-eval/results/spearman_aggressiveness_score.csv')\n",
    "df2 = pd.read_csv('/home/amey/depository/cs-eval/results/kendalltau_aggressiveness_score.csv')\n",
    "df = pd.merge(df1, df2, on='metric', suffixes=['spearman', 'kendalltau'])\n",
    "assert df.shape[0] == df1.shape[0] == df2.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_1_(pred_cs, cs) bleu_2_(pred_cs, cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model bleu_2_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) bleu_3_(pred_cs, cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model bleu_3_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) bleu_4_(pred_cs, cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model bleu_4_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) rouge_1_(pred_cs, cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model rouge_1_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) rouge_2_(pred_cs, cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model rouge_2_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) rouge_l_(pred_cs, cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model rouge_l_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) meteor_score_(pred_cs, cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model meteor_score_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) bert_score_(pred_cs, cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model bert_score_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) bart_score_(pred_cs, cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model bart_score_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) pc_score_(hs, pred_cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model pc_score_(hs, pred_cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) aq_score_(pred_cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model aq_score_(pred_cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) pd_score(hs, pred_cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model pd_score(hs, pred_cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) toxicity_(pred_cs)\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model toxicity_(pred_cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) gpt-4-zs_aggressiveness_score\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model gpt-4-zs_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) zs_Llama-3-8b-chat-hf_aggressiveness_score\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model zs_Llama-3-8b-chat-hf_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) zs_Mistral-7B-Instruct-v03_aggressiveness_score\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model zs_Mistral-7B-Instruct-v03_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) GEVAL_gpt-4_aggressiveness_score\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model GEVAL_gpt-4_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) GEVAL_Llama-3-8b-chat-hf_aggressiveness_score\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model GEVAL_Llama-3-8b-chat-hf_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) GEVAL_Mistral-7B-Instruct-v03_aggressiveness_score\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model GEVAL_Mistral-7B-Instruct-v03_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) Llama-3-8b-chat-hf_aggressiveness_score\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model Llama-3-8b-chat-hf_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) Mistral-7B-Instruct-v03_aggressiveness_score\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model Mistral-7B-Instruct-v03_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_1_(pred_cs, cs) gpt-4_aggressiveness_score\n",
      "Comparing Model bleu_1_(pred_cs, cs) and Model gpt-4_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) bleu_3_(pred_cs, cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model bleu_3_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) bleu_4_(pred_cs, cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model bleu_4_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) rouge_1_(pred_cs, cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model rouge_1_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) rouge_2_(pred_cs, cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model rouge_2_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) rouge_l_(pred_cs, cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model rouge_l_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) meteor_score_(pred_cs, cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model meteor_score_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) bert_score_(pred_cs, cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model bert_score_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) bart_score_(pred_cs, cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model bart_score_(pred_cs, cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) pc_score_(hs, pred_cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model pc_score_(hs, pred_cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) aq_score_(pred_cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model aq_score_(pred_cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) pd_score(hs, pred_cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model pd_score(hs, pred_cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) toxicity_(pred_cs)\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model toxicity_(pred_cs) using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) gpt-4-zs_aggressiveness_score\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model gpt-4-zs_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) zs_Llama-3-8b-chat-hf_aggressiveness_score\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model zs_Llama-3-8b-chat-hf_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) zs_Mistral-7B-Instruct-v03_aggressiveness_score\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model zs_Mistral-7B-Instruct-v03_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) GEVAL_gpt-4_aggressiveness_score\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model GEVAL_gpt-4_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) GEVAL_Llama-3-8b-chat-hf_aggressiveness_score\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model GEVAL_Llama-3-8b-chat-hf_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) GEVAL_Mistral-7B-Instruct-v03_aggressiveness_score\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model GEVAL_Mistral-7B-Instruct-v03_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) Llama-3-8b-chat-hf_aggressiveness_score\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model Llama-3-8b-chat-hf_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) Mistral-7B-Instruct-v03_aggressiveness_score\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model Mistral-7B-Instruct-v03_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_2_(pred_cs, cs) gpt-4_aggressiveness_score\n",
      "Comparing Model bleu_2_(pred_cs, cs) and Model gpt-4_aggressiveness_score using Aggressiveness_scorespearman correlation:\n",
      "t-statistic=0.000, p-value=1.000\n",
      "bleu_3_(pred_cs, cs) bleu_4_(pred_cs, cs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero_method 'wilcox' and 'pratt' do not work if x - y is zero for all elements.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model1_values \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m model1, metric]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      8\u001b[0m model2_values \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m model2, metric]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m----> 9\u001b[0m t_stat, p_value \u001b[38;5;241m=\u001b[39m \u001b[43mwilcoxon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel2_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComparing Model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and Model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m correlation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt-statistic=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_stat\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, p-value=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/socionet/lib/python3.9/site-packages/scipy/_lib/_util.py:794\u001b[0m, in \u001b[0;36m_rename_parameter.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(message)\n\u001b[1;32m    793\u001b[0m     kwargs[new_name] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old_name)\n\u001b[0;32m--> 794\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/socionet/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:531\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sentinel:\n\u001b[1;32m    530\u001b[0m     samples \u001b[38;5;241m=\u001b[39m _remove_sentinel(samples, paired, sentinel)\n\u001b[0;32m--> 531\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mhypotest_fun_out\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m res \u001b[38;5;241m=\u001b[39m result_to_tuple(res)\n\u001b[1;32m    533\u001b[0m res \u001b[38;5;241m=\u001b[39m _add_reduced_axes(res, reduced_axes, keepdims)\n",
      "File \u001b[0;32m~/miniconda3/envs/socionet/lib/python3.9/site-packages/scipy/stats/_morestats.py:4111\u001b[0m, in \u001b[0;36mwilcoxon\u001b[0;34m(x, y, zero_method, correction, alternative, method, axis)\u001b[0m\n\u001b[1;32m   3893\u001b[0m \u001b[38;5;129m@_rename_parameter\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;129m@_axis_nan_policy_factory\u001b[39m(\n\u001b[1;32m   3895\u001b[0m     wilcoxon_result_object, paired\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwilcoxon\u001b[39m(x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zero_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwilcox\u001b[39m\u001b[38;5;124m\"\u001b[39m, correction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3900\u001b[0m              alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo-sided\u001b[39m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate the Wilcoxon signed-rank test.\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \n\u001b[1;32m   3903\u001b[0m \u001b[38;5;124;03m    The Wilcoxon signed-rank test tests the null hypothesis that two\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4109\u001b[0m \n\u001b[1;32m   4110\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wilcoxon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wilcoxon_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malternative\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4112\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/socionet/lib/python3.9/site-packages/scipy/stats/_wilcoxon.py:198\u001b[0m, in \u001b[0;36m_wilcoxon_nd\u001b[0;34m(x, y, zero_method, correction, alternative, method, axis)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wilcoxon_nd\u001b[39m(x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zero_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwilcox\u001b[39m\u001b[38;5;124m'\u001b[39m, correction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    196\u001b[0m                  alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtwo-sided\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 198\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[43m_wilcoxon_iv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malternative\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     d, zero_method, correction, alternative, method, axis \u001b[38;5;241m=\u001b[39m temp\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/socionet/lib/python3.9/site-packages/scipy/stats/_wilcoxon.py:124\u001b[0m, in \u001b[0;36m_wilcoxon_iv\u001b[0;34m(x, y, zero_method, correction, alternative, method, axis)\u001b[0m\n\u001b[1;32m    118\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExact p-value calculation does not work if there are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros. Switching to normal approximation.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    120\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapprox\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m zero_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwilcox\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpratt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m n_zero \u001b[38;5;241m==\u001b[39m d\u001b[38;5;241m.\u001b[39msize \u001b[38;5;129;01mand\u001b[39;00m d\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m d\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero_method \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwilcox\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpratt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m do not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwork if x - y is zero for all elements.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m d\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapprox\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    128\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample size too small for normal approximation.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: zero_method 'wilcox' and 'pratt' do not work if x - y is zero for all elements."
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "from itertools import combinations\n",
    "model_names = df.metric.values.tolist()\n",
    "for metric in ['aggressiveness_scorespearman', 'aggressiveness_scorekendalltau']:\n",
    "    for model1, model2 in combinations(model_names, 2):\n",
    "        print(model1, model2)\n",
    "        model1_values = df.loc[df['metric'] == model1, metric].values\n",
    "        model2_values = df.loc[df['metric'] == model2, metric].values\n",
    "        t_stat, p_value = wilcoxon(model1_values, model2_values)\n",
    "        print(f\"Comparing Model {model1} and Model {model2} using {metric.capitalize()} correlation:\")\n",
    "        print(f\"t-statistic={t_stat:.3f}, p-value={p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical significance testing - across different temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_coherence_score</th>\n",
       "      <th>prediction_suitableness_score</th>\n",
       "      <th>prediction_aggressiveness_score</th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_coherence_score</th>\n",
       "      <th>prediction_suitableness_score</th>\n",
       "      <th>prediction_aggressiveness_score</th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_coherence_score</th>\n",
       "      <th>prediction_suitableness_score</th>\n",
       "      <th>prediction_aggressiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_relevance_score  prediction_coherence_score  \\\n",
       "0                         4.0                         3.0   \n",
       "1                         4.0                         4.0   \n",
       "2                         5.0                         5.0   \n",
       "3                         1.0                         1.0   \n",
       "4                         4.0                         2.0   \n",
       "\n",
       "   prediction_suitableness_score  prediction_aggressiveness_score  \\\n",
       "0                            3.0                              2.0   \n",
       "1                            3.0                              2.0   \n",
       "2                            3.0                              2.0   \n",
       "3                            1.0                              4.0   \n",
       "4                            2.0                              2.0   \n",
       "\n",
       "   prediction_relevance_score  prediction_coherence_score  \\\n",
       "0                         4.0                         3.0   \n",
       "1                         4.0                         4.0   \n",
       "2                         5.0                         5.0   \n",
       "3                         1.0                         1.0   \n",
       "4                         5.0                         2.0   \n",
       "\n",
       "   prediction_suitableness_score  prediction_aggressiveness_score  \\\n",
       "0                            3.0                              3.0   \n",
       "1                            3.0                              2.0   \n",
       "2                            3.0                              2.0   \n",
       "3                            1.0                              4.0   \n",
       "4                            2.0                              3.0   \n",
       "\n",
       "   prediction_relevance_score  prediction_coherence_score  \\\n",
       "0                         4.0                         2.0   \n",
       "1                         4.0                         4.0   \n",
       "2                         5.0                         5.0   \n",
       "3                         1.0                         1.0   \n",
       "4                         4.0                         2.0   \n",
       "\n",
       "   prediction_suitableness_score  prediction_aggressiveness_score  \n",
       "0                            3.0                              2.0  \n",
       "1                            3.0                              2.0  \n",
       "2                            3.0                              2.0  \n",
       "3                            1.0                              4.0  \n",
       "4                            2.0                              2.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from utils import postprocess_llm_response, extract_content_from_response\n",
    "\n",
    "df1 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/mistralai-Mistral-7B-Instruct-v0.3_temperature_0.0.pkl')\n",
    "df2 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/mistralai-Mistral-7B-Instruct-v0.3_temperature_0.5.pkl')\n",
    "df3 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/mistralai-Mistral-7B-Instruct-v0.3_temperature_1.pkl')\n",
    "\n",
    "prediction_cols = [col for col in df1.columns if 'prediction_' in col]\n",
    "\n",
    "for col in prediction_cols:\n",
    "    df1[col] = df1[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df1[col] = df1[col].apply(lambda x: extract_score(x))\n",
    "    df1 = df1.rename(columns={col: col.replace('mistralai/Mistral-7B-Instruct-v0.3_','')})\n",
    "\n",
    "    df2[col] = df2[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df2[col] = df2[col].apply(lambda x: extract_score(x))\n",
    "    df2 = df2.rename(columns={col: col.replace('mistralai/Mistral-7B-Instruct-v0.3_','')})\n",
    "\n",
    "    df3[col] = df3[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df3[col] = df3[col].apply(lambda x: extract_score(x))\n",
    "    df3 = df3.rename(columns={col: col.replace('mistralai/Mistral-7B-Instruct-v0.3_','')})\n",
    "\n",
    "prediction_cols = [col for col in df1.columns if 'prediction_' in col] \n",
    "# df_analysis = pd.concat([df1[prediction_cols], df2[prediction_cols], df3[prediction_cols]], axis=1)\n",
    "df_analysis = pd.concat([df1[prediction_cols], df2[prediction_cols], df3[prediction_cols]], axis=1)\n",
    "df_analysis = rename_similar_columns(df_analysis)\n",
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_coherence_score</th>\n",
       "      <th>prediction_suitableness_score</th>\n",
       "      <th>prediction_aggressiveness_score</th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_coherence_score</th>\n",
       "      <th>prediction_suitableness_score</th>\n",
       "      <th>prediction_aggressiveness_score</th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_coherence_score</th>\n",
       "      <th>prediction_suitableness_score</th>\n",
       "      <th>prediction_aggressiveness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>suitableness_score</th>\n",
       "      <th>aggressiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_relevance_score  prediction_coherence_score  \\\n",
       "0                         4.0                         3.0   \n",
       "1                         4.0                         4.0   \n",
       "2                         5.0                         5.0   \n",
       "3                         1.0                         1.0   \n",
       "4                         4.0                         2.0   \n",
       "\n",
       "   prediction_suitableness_score  prediction_aggressiveness_score  \\\n",
       "0                            3.0                              2.0   \n",
       "1                            3.0                              2.0   \n",
       "2                            3.0                              2.0   \n",
       "3                            1.0                              4.0   \n",
       "4                            2.0                              2.0   \n",
       "\n",
       "   prediction_relevance_score  prediction_coherence_score  \\\n",
       "0                         4.0                         3.0   \n",
       "1                         4.0                         4.0   \n",
       "2                         5.0                         5.0   \n",
       "3                         1.0                         1.0   \n",
       "4                         5.0                         2.0   \n",
       "\n",
       "   prediction_suitableness_score  prediction_aggressiveness_score  \\\n",
       "0                            3.0                              3.0   \n",
       "1                            3.0                              2.0   \n",
       "2                            3.0                              2.0   \n",
       "3                            1.0                              4.0   \n",
       "4                            2.0                              3.0   \n",
       "\n",
       "   prediction_relevance_score  prediction_coherence_score  \\\n",
       "0                         4.0                         2.0   \n",
       "1                         4.0                         4.0   \n",
       "2                         5.0                         5.0   \n",
       "3                         1.0                         1.0   \n",
       "4                         4.0                         2.0   \n",
       "\n",
       "   prediction_suitableness_score  prediction_aggressiveness_score  \\\n",
       "0                            3.0                              2.0   \n",
       "1                            3.0                              2.0   \n",
       "2                            3.0                              2.0   \n",
       "3                            1.0                              4.0   \n",
       "4                            2.0                              2.0   \n",
       "\n",
       "   relevance_score  coherence_score  suitableness_score  aggressiveness_score  \n",
       "0         3.333333         2.333333            1.666667              1.666667  \n",
       "1         3.666667         4.333333            2.333333              1.000000  \n",
       "2         3.333333         3.333333            2.666667              1.000000  \n",
       "3         3.000000         1.000000            1.000000              2.333333  \n",
       "4         2.333333         1.000000            1.000000              1.666667  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_gt = pd.read_csv('/home/amey/depository/cs-eval/data/annotations/dataset_analysis_metrics_calculated.csv')[:1300]\n",
    "true_cols = [col.replace('prediction_','') for col in prediction_cols]\n",
    "df_analysis = pd.concat([df_analysis, df_w_gt[true_cols]], axis=1)\n",
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction_relevance_score  prediction_relevance_score  \\\n",
       "0                            4.0                         4.0   \n",
       "1                            4.0                         4.0   \n",
       "2                            5.0                         5.0   \n",
       "3                            1.0                         1.0   \n",
       "4                            4.0                         5.0   \n",
       "...                          ...                         ...   \n",
       "1295                         5.0                         5.0   \n",
       "1296                         4.0                         4.0   \n",
       "1297                         5.0                         5.0   \n",
       "1298                         5.0                         5.0   \n",
       "1299                         2.0                         2.0   \n",
       "\n",
       "      prediction_relevance_score  \n",
       "0                            4.0  \n",
       "1                            4.0  \n",
       "2                            5.0  \n",
       "3                            1.0  \n",
       "4                            4.0  \n",
       "...                          ...  \n",
       "1295                         5.0  \n",
       "1296                         4.0  \n",
       "1297                         5.0  \n",
       "1298                         5.0  \n",
       "1299                         2.0  \n",
       "\n",
       "[1300 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis['prediction_relevance_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_relevance_score\n",
      "Standard deviation: 0.1288423089857736\n",
      "prediction_coherence_score\n",
      "Standard deviation: 0.1480647207294224\n",
      "prediction_suitableness_score\n",
      "Standard deviation: 0.034641016151377546\n",
      "prediction_aggressiveness_score\n",
      "Standard deviation: 0.11446282224041861\n",
      "prediction_relevance_score\n",
      "Kruskal-Wallis H-statistic: 1.1450653426398427, p-value: 0.5640949608699841\n",
      "prediction_coherence_score\n",
      "Kruskal-Wallis H-statistic: 0.08925124150100705, p-value: 0.9563554544574492\n",
      "prediction_suitableness_score\n",
      "Kruskal-Wallis H-statistic: 0.052638327644834566, p-value: 0.9740241667175431\n",
      "prediction_aggressiveness_score\n",
      "Kruskal-Wallis H-statistic: 2.8838521607090604, p-value: 0.2364718559742476\n"
     ]
    }
   ],
   "source": [
    "for col in prediction_cols:\n",
    "    print(col)\n",
    "    print(f\"Standard deviation: {df_analysis[col].std(axis=1).mean()}\")\n",
    "\n",
    "for col in prediction_cols:\n",
    "    print(col)\n",
    "    values = df_analysis[col].values.tolist()\n",
    "    values1 = [x[0] for x in values]\n",
    "    values2 = [x[1] for x in values]\n",
    "    values3 = [x[2] for x in values]\n",
    "\n",
    "    h_statistic, p_value = stats.kruskal(values1, values2, values3)\n",
    "    print(f\"Kruskal-Wallis H-statistic: {h_statistic}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_temp0_relevance_score</th>\n",
       "      <th>prediction_temp0_coherence_score</th>\n",
       "      <th>prediction_temp0_suitableness_score</th>\n",
       "      <th>prediction_temp0_aggressiveness_score</th>\n",
       "      <th>prediction_temp0.5_relevance_score</th>\n",
       "      <th>prediction_temp0.5_coherence_score</th>\n",
       "      <th>prediction_temp0.5_suitableness_score</th>\n",
       "      <th>prediction_temp0.5_aggressiveness_score</th>\n",
       "      <th>prediction_temp1_relevance_score</th>\n",
       "      <th>prediction_temp1_coherence_score</th>\n",
       "      <th>prediction_temp1_suitableness_score</th>\n",
       "      <th>prediction_temp1_aggressiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_temp0_relevance_score  prediction_temp0_coherence_score  \\\n",
       "0                               5.0                               4.0   \n",
       "1                               5.0                               4.0   \n",
       "2                               5.0                               4.0   \n",
       "3                               1.0                               1.0   \n",
       "4                               2.0                               1.0   \n",
       "\n",
       "   prediction_temp0_suitableness_score  prediction_temp0_aggressiveness_score  \\\n",
       "0                                  2.0                                    1.0   \n",
       "1                                  2.0                                    1.0   \n",
       "2                                  2.0                                    1.0   \n",
       "3                                  1.0                                    4.0   \n",
       "4                                  1.0                                    1.0   \n",
       "\n",
       "   prediction_temp0.5_relevance_score  prediction_temp0.5_coherence_score  \\\n",
       "0                                 5.0                                 5.0   \n",
       "1                                 4.0                                 4.0   \n",
       "2                                 5.0                                 4.0   \n",
       "3                                 1.0                                 1.0   \n",
       "4                                 1.0                                 1.0   \n",
       "\n",
       "   prediction_temp0.5_suitableness_score  \\\n",
       "0                                    2.0   \n",
       "1                                    2.0   \n",
       "2                                    2.0   \n",
       "3                                    1.0   \n",
       "4                                    1.0   \n",
       "\n",
       "   prediction_temp0.5_aggressiveness_score  prediction_temp1_relevance_score  \\\n",
       "0                                      1.0                               5.0   \n",
       "1                                      1.0                               5.0   \n",
       "2                                      1.0                               5.0   \n",
       "3                                      4.0                               1.0   \n",
       "4                                      1.0                               1.0   \n",
       "\n",
       "   prediction_temp1_coherence_score  prediction_temp1_suitableness_score  \\\n",
       "0                               5.0                                  2.0   \n",
       "1                               4.0                                  2.0   \n",
       "2                               4.0                                  2.0   \n",
       "3                               1.0                                  1.0   \n",
       "4                               2.0                                  1.0   \n",
       "\n",
       "   prediction_temp1_aggressiveness_score  \n",
       "0                                    1.0  \n",
       "1                                    2.0  \n",
       "2                                    1.0  \n",
       "3                                    5.0  \n",
       "4                                    1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from utils import postprocess_llm_response, extract_content_from_response\n",
    "\n",
    "df1 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/meta-llama-Llama-3-8b-chat-hf_temperature_0.pkl')\n",
    "df2 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/meta-llama-Llama-3-8b-chat-hf_temperature_0.5.pkl')\n",
    "df3 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/meta-llama-Llama-3-8b-chat-hf_temperature_1.pkl')\n",
    "\n",
    "prediction_cols = [col for col in df1.columns if 'prediction_' in col]\n",
    "\n",
    "for col in prediction_cols:\n",
    "    df1[col] = df1[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df1[col] = df1[col].apply(lambda x: extract_score(x))\n",
    "    df1 = df1.rename(columns={col: col.replace('meta-llama/Llama-3-8b-chat-hf_','temp0_')})\n",
    "\n",
    "    df2[col] = df2[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df2[col] = df2[col].apply(lambda x: extract_score(x))\n",
    "    df2 = df2.rename(columns={col: col.replace('meta-llama/Llama-3-8b-chat-hf_','temp0.5_')})\n",
    "\n",
    "    df3[col] = df3[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df3[col] = df3[col].apply(lambda x: extract_score(x))\n",
    "    df3 = df3.rename(columns={col: col.replace('meta-llama/Llama-3-8b-chat-hf_','temp1_')})\n",
    "\n",
    "df_analysis = pd.concat([df1[[col for col in df1.columns if 'prediction_' in col]], df2[[col for col in df2.columns if 'prediction_' in col]], df3[[col for col in df3.columns if 'prediction_' in col]]], axis=1)\n",
    "prediction_cols = [col for col in df_analysis.columns if 'prediction_' in col] \n",
    "df_analysis.head()\n",
    "\n",
    "# df_w_gt = pd.read_csv('/home/amey/depository/cs-eval/data/annotations/dataset_analysis_metrics_calculated.csv')[:1300]\n",
    "# true_cols = ['relevance_score', 'coherence_score', 'aggressiveness_score', 'suitableness_score']\n",
    "# df_analysis = pd.concat([df_analysis, df_w_gt[true_cols]], axis=1)\n",
    "# df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suitableness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction_temp0_suitableness_score</th>\n",
       "      <td>0.414468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_temp0.5_suitableness_score</th>\n",
       "      <td>0.373575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_temp1_suitableness_score</th>\n",
       "      <td>0.319541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       suitableness_score\n",
       "prediction_temp0_suitableness_score              0.414468\n",
       "prediction_temp0.5_suitableness_score            0.373575\n",
       "prediction_temp1_suitableness_score              0.319541"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_name = 'suitableness_score'\n",
    "y_pred_cols = [col for col in df_analysis.columns if aspect_name in col and 'prediction' in col]\n",
    "y_true_cols = [aspect_name]\n",
    "\n",
    "spearman_df, kendall_df = calculate_correlation_matrices(df_analysis, y_pred_cols, y_true_cols)\n",
    "spearman_df\n",
    "# spearman_df = spearman_df.rename_axis('metric')\n",
    "# spearman_df['metric'] = spearman_df.index\n",
    "# spearman_df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in prediction_cols:\n",
    "#     print(col)\n",
    "#     print(f\"Standard deviation: {df_analysis[col].std(axis=1).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from scipy.stats import ttest_rel\n",
    "\n",
    "# # Load your dataframe\n",
    "# df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# # Define the models\n",
    "# models = ['Model A', 'Model B', 'Model C']\n",
    "\n",
    "# # Create an empty list to store the results\n",
    "# results = []\n",
    "\n",
    "# # Perform paired t-test for each model\n",
    "# for model in models:\n",
    "#     t_stat, p_value = ttest_rel(df['y_true'], df[f\"{model}_pred\"])\n",
    "#     results.append({\n",
    "#         'Model': model,\n",
    "#         't-statistic': t_stat,\n",
    "#         'p-value': p_value,\n",
    "#         'Significant Difference': 'Yes' if p_value < 0.05 else 'No'\n",
    "#     })\n",
    "\n",
    "# # Create a dataframe from the results\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Display the results table\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction_relevance_score  prediction_relevance_score  \\\n",
       "0                            5.0                         5.0   \n",
       "1                            5.0                         4.0   \n",
       "2                            5.0                         5.0   \n",
       "3                            1.0                         1.0   \n",
       "4                            2.0                         1.0   \n",
       "...                          ...                         ...   \n",
       "1295                         5.0                         5.0   \n",
       "1296                         4.0                         5.0   \n",
       "1297                         5.0                         5.0   \n",
       "1298                         4.0                         4.0   \n",
       "1299                         1.0                         1.0   \n",
       "\n",
       "      prediction_relevance_score  \n",
       "0                            5.0  \n",
       "1                            5.0  \n",
       "2                            5.0  \n",
       "3                            1.0  \n",
       "4                            1.0  \n",
       "...                          ...  \n",
       "1295                         5.0  \n",
       "1296                         4.0  \n",
       "1297                         5.0  \n",
       "1298                         4.0  \n",
       "1299                         1.0  \n",
       "\n",
       "[1300 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis['prediction_relevance_score']\n",
    "# df_anal = df_analysis['prediction_relevance_score']\n",
    "# spearman_df, kendall_df = calculate_correlation_matrices(, unieval_cols, human_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction__relevance_score</th>\n",
       "      <th>prediction__coherence_score</th>\n",
       "      <th>prediction__suitableness_score</th>\n",
       "      <th>prediction__aggressiveness_score</th>\n",
       "      <th>prediction__relevance_score</th>\n",
       "      <th>prediction__coherence_score</th>\n",
       "      <th>prediction__suitableness_score</th>\n",
       "      <th>prediction__aggressiveness_score</th>\n",
       "      <th>prediction__relevance_score</th>\n",
       "      <th>prediction__coherence_score</th>\n",
       "      <th>prediction__suitableness_score</th>\n",
       "      <th>prediction__aggressiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction__relevance_score  prediction__coherence_score  \\\n",
       "0                          5.0                          4.0   \n",
       "1                          5.0                          4.0   \n",
       "2                          5.0                          4.0   \n",
       "3                          1.0                          1.0   \n",
       "4                          2.0                          2.0   \n",
       "\n",
       "   prediction__suitableness_score  prediction__aggressiveness_score  \\\n",
       "0                             2.0                               1.0   \n",
       "1                             2.0                               2.0   \n",
       "2                             2.0                               2.0   \n",
       "3                             1.0                               4.0   \n",
       "4                             1.0                               2.0   \n",
       "\n",
       "   prediction__relevance_score  prediction__coherence_score  \\\n",
       "0                          5.0                          4.0   \n",
       "1                          5.0                          4.0   \n",
       "2                          5.0                          4.0   \n",
       "3                          1.0                          1.0   \n",
       "4                          1.0                          2.0   \n",
       "\n",
       "   prediction__suitableness_score  prediction__aggressiveness_score  \\\n",
       "0                             2.0                               1.0   \n",
       "1                             2.0                               1.0   \n",
       "2                             2.0                               2.0   \n",
       "3                             2.0                               4.0   \n",
       "4                             1.0                               2.0   \n",
       "\n",
       "   prediction__relevance_score  prediction__coherence_score  \\\n",
       "0                          5.0                          4.0   \n",
       "1                          4.0                          4.0   \n",
       "2                          4.0                          4.0   \n",
       "3                          2.0                          1.0   \n",
       "4                          3.0                          2.0   \n",
       "\n",
       "   prediction__suitableness_score  prediction__aggressiveness_score  \n",
       "0                             2.0                               1.0  \n",
       "1                             2.0                               1.0  \n",
       "2                             2.0                               1.0  \n",
       "3                             2.0                               4.0  \n",
       "4                             2.0                               2.0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from utils import postprocess_llm_response, extract_content_from_response\n",
    "\n",
    "df1 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/meta-llama-Llama-3-8b-chat-hf_zeroshot_temperature_0.0.pkl')\n",
    "df2 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/meta-llama-Llama-3-8b-chat-hf_zeroshot_temperature_0.5.pkl')\n",
    "df3 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/meta-llama-Llama-3-8b-chat-hf_zeroshot_temperature_1.pkl')\n",
    "\n",
    "prediction_cols = [col for col in df1.columns if 'prediction_' in col]\n",
    "\n",
    "for col in prediction_cols:\n",
    "    df1 = df1[df1[col].notna()]\n",
    "    df1[col] = df1[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df1[col] = df1[col].apply(lambda x: extract_score(x))\n",
    "    df1 = df1.rename(columns={col: col.replace('meta-llama/Llama-3-8b-chat-hf','')})\n",
    "\n",
    "    df2 = df2[df2[col].notna()]\n",
    "    df2[col] = df2[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df2[col] = df2[col].apply(lambda x: extract_score(x))\n",
    "    df2 = df2.rename(columns={col: col.replace('meta-llama/Llama-3-8b-chat-hf','')})\n",
    "    \n",
    "    df3 = df3[df3[col].notna()]\n",
    "    df3[col] = df3[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df3[col] = df3[col].apply(lambda x: extract_score(x))\n",
    "    df3 = df3.rename(columns={col: col.replace('meta-llama/Llama-3-8b-chat-hf','')})\n",
    "\n",
    "prediction_cols = [col for col in df1.columns if 'prediction_' in col]\n",
    "# df_analysis = pd.concat([df1[prediction_cols], df2[prediction_cols], df3[prediction_cols]], axis=1)\n",
    "df_analysis = pd.concat([df1[prediction_cols], df2[prediction_cols], df3[prediction_cols]], axis=1)\n",
    "df_analysis = df_analysis[:1300]\n",
    "df_analysis = df_analysis.dropna()\n",
    "print(df_analysis.shape)\n",
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction__relevance_score\n",
      "Standard deviation: 0.22998096797735215\n",
      "prediction__coherence_score\n",
      "Standard deviation: 0.170563729426318\n",
      "prediction__suitableness_score\n",
      "Standard deviation: 0.2749732399823688\n",
      "prediction__aggressiveness_score\n",
      "Standard deviation: 0.2793979324154946\n"
     ]
    }
   ],
   "source": [
    "for col in prediction_cols:\n",
    "    print(col)\n",
    "    print(f\"Standard deviation: {df_analysis[col].std(axis=1).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_coherence_score</th>\n",
       "      <th>prediction_suitableness_score</th>\n",
       "      <th>prediction_aggressiveness_score</th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_coherence_score</th>\n",
       "      <th>prediction_suitableness_score</th>\n",
       "      <th>prediction_aggressiveness_score</th>\n",
       "      <th>prediction_relevance_score</th>\n",
       "      <th>prediction_coherence_score</th>\n",
       "      <th>prediction_suitableness_score</th>\n",
       "      <th>prediction_aggressiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_relevance_score  prediction_coherence_score  \\\n",
       "0                         5.0                         4.0   \n",
       "1                         5.0                         4.0   \n",
       "2                         5.0                         5.0   \n",
       "3                         1.0                         1.0   \n",
       "4                         5.0                         2.0   \n",
       "\n",
       "   prediction_suitableness_score  prediction_aggressiveness_score  \\\n",
       "0                            2.0                              2.0   \n",
       "1                            3.0                              2.0   \n",
       "2                            3.0                              2.0   \n",
       "3                            1.0                              4.0   \n",
       "4                            1.0                              1.0   \n",
       "\n",
       "   prediction_relevance_score  prediction_coherence_score  \\\n",
       "0                         5.0                         4.0   \n",
       "1                         5.0                         4.0   \n",
       "2                         5.0                         5.0   \n",
       "3                         1.0                         1.0   \n",
       "4                         5.0                         2.0   \n",
       "\n",
       "   prediction_suitableness_score  prediction_aggressiveness_score  \\\n",
       "0                            3.0                              1.0   \n",
       "1                            3.0                              1.0   \n",
       "2                            3.0                              2.0   \n",
       "3                            1.0                              4.0   \n",
       "4                            1.0                              1.0   \n",
       "\n",
       "   prediction_relevance_score  prediction_coherence_score  \\\n",
       "0                         5.0                         3.0   \n",
       "1                         5.0                         4.0   \n",
       "2                         5.0                         4.0   \n",
       "3                         2.0                         1.0   \n",
       "4                         5.0                         2.0   \n",
       "\n",
       "   prediction_suitableness_score  prediction_aggressiveness_score  \n",
       "0                            1.0                              1.0  \n",
       "1                            3.0                              1.0  \n",
       "2                            3.0                              2.0  \n",
       "3                            1.0                              4.0  \n",
       "4                            1.0                              1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from utils import postprocess_llm_response, extract_content_from_response\n",
    "\n",
    "df1 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/mistralai-Mistral-7B-Instruct-v0.3_zeroshot_temperature_0.0.pkl')\n",
    "df2 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/mistralai-Mistral-7B-Instruct-v0.3_zeroshot_temperature_0.5.pkl')\n",
    "df3 = pd.read_pickle('/home/amey/depository/cs-eval/predictions_rebuttal/mistralai-Mistral-7B-Instruct-v0.3_zeroshot_temperature_1.pkl')\n",
    "\n",
    "prediction_cols = [col for col in df1.columns if 'prediction_' in col]\n",
    "\n",
    "for col in prediction_cols:\n",
    "    df1 = df1[df1[col].notna()]\n",
    "    # print(df1.shape)\n",
    "    df1[col] = df1[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df1[col] = df1[col].apply(lambda x: extract_score(x))\n",
    "    df1 = df1.rename(columns={col: col.replace('mistralai/Mistral-7B-Instruct-v0.3_','')})\n",
    "\n",
    "    df2 = df2[df2[col].notna()]\n",
    "    # print(df2.shape)\n",
    "    df2[col] = df2[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df2[col] = df2[col].apply(lambda x: extract_score(x))\n",
    "    df2 = df2.rename(columns={col: col.replace('mistralai/Mistral-7B-Instruct-v0.3_','')})\n",
    "    \n",
    "    df3 = df3[df3[col].notna()]\n",
    "    # print(df3.shape)\n",
    "    df3[col] = df3[col].apply(lambda x: extract_content_from_response(x))\n",
    "    df3[col] = df3[col].apply(lambda x: extract_score(x))\n",
    "    df3 = df3.rename(columns={col: col.replace('mistralai/Mistral-7B-Instruct-v0.3_','')})\n",
    "\n",
    "prediction_cols = [col for col in df1.columns if 'prediction_' in col]\n",
    "# df_analysis = pd.concat([df1[prediction_cols], df2[prediction_cols], df3[prediction_cols]], axis=1)\n",
    "df_analysis = pd.concat([df1[prediction_cols], df2[prediction_cols], df3[prediction_cols]], axis=1)\n",
    "df_analysis = df_analysis[:1300]\n",
    "df_analysis = df_analysis.dropna()\n",
    "print(df_analysis.shape)\n",
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_relevance_score\n",
      "Standard deviation: 0.09370838984539312\n",
      "prediction_coherence_score\n",
      "Standard deviation: 0.14022152655810963\n",
      "prediction_suitableness_score\n",
      "Standard deviation: 0.1043905062653532\n",
      "prediction_aggressiveness_score\n",
      "Standard deviation: 0.14999206957516478\n"
     ]
    }
   ],
   "source": [
    "for col in prediction_cols:\n",
    "    print(col)\n",
    "    print(f\"Standard deviation: {df_analysis[col].std(axis=1).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_relevance_score\n",
      "Kruskal-Wallis H-statistic: 2.8135023553270098, p-value: 0.24493775114894545\n",
      "prediction_coherence_score\n",
      "Kruskal-Wallis H-statistic: 0.8002685402755404, p-value: 0.6702300481128598\n",
      "prediction_suitableness_score\n",
      "Kruskal-Wallis H-statistic: 1.8396297907360921, p-value: 0.39859281563273546\n",
      "prediction_aggressiveness_score\n",
      "Kruskal-Wallis H-statistic: 0.38873138618738207, p-value: 0.8233567533291871\n"
     ]
    }
   ],
   "source": [
    "for col in prediction_cols:\n",
    "    print(col)\n",
    "    values = df_analysis[col].values.tolist()\n",
    "    values1 = [x[0] for x in values]\n",
    "    values2 = [x[1] for x in values]\n",
    "    values3 = [x[2] for x in values]\n",
    "\n",
    "    h_statistic, p_value = stats.kruskal(values1, values2, values3)\n",
    "    print(f\"Kruskal-Wallis H-statistic: {h_statistic}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.0, 4.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 4.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 3.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 4.0, 3.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 2.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [3.0, 2.0, 2.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [2.0, 3.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [3.0, 3.0, 2.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [3.0, 4.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 3.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [1.0, 1.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [4.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 3.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 3.0, 3.0],\n",
       " [4.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 3.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [1.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [2.0, 2.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 1.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 2.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 3.0, 3.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [2.0, 3.0, 2.0],\n",
       " [3.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 4.0, 3.0],\n",
       " [3.0, 3.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [2.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 1.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 5.0, 5.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [3.0, 4.0, 3.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 2.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [3.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [1.0, 1.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 3.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 2.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 2.0, 1.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [3.0, 3.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [4.0, 3.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 3.0, 4.0],\n",
       " [3.0, 3.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [3.0, 3.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 5.0, 5.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [3.0, 3.0, 3.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [2.0, 2.0, 2.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [1.0, 1.0, 2.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [5.0, 5.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [5.0, 5.0, 5.0],\n",
       " [4.0, 5.0, 4.0],\n",
       " [1.0, 1.0, 1.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 4.0],\n",
       " [4.0, 4.0, 5.0],\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis['prediction_coherence_score'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis H-statistic: 0.8002685402755404, p-value: 0.6702300481128598\n"
     ]
    }
   ],
   "source": [
    "values = df_analysis['prediction_coherence_score'].values.tolist()\n",
    "values1 = [x[0] for x in values]\n",
    "values2 = [x[1] for x in values]\n",
    "values3 = [x[2] for x in values]\n",
    "\n",
    "h_statistic, p_value = stats.kruskal(values1, values2, values3)\n",
    "print(f\"Kruskal-Wallis H-statistic: {h_statistic}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New paired t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: inf\n",
      "P-value: 0.0000\n",
      "Reject the null hypothesis: The difference is statistically significant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amey/miniconda3/envs/socionet/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:531: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "def paired_t_test(ratings_A, ratings_B):\n",
    "    # Perform the paired t-test\n",
    "    t_stat, p_value = ttest_rel(ratings_A, ratings_B)\n",
    "    \n",
    "    return t_stat, p_value\n",
    "\n",
    "# Example ratings for models A and B\n",
    "ratings_A = [4, 3, 5, 2, 4, 3, 4, 2, 5, 3]\n",
    "ratings_B = [3, 2, 4, 1, 3, 2, 3, 1, 4, 2]\n",
    "\n",
    "# Perform the paired t-test\n",
    "t_stat, p_value = paired_t_test(ratings_A, ratings_B)\n",
    "\n",
    "# Print the results\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Decision based on p-value\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The difference is statistically significant.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The difference is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>counterspeech</th>\n",
       "      <th>predicted_counterspeech</th>\n",
       "      <th>csType</th>\n",
       "      <th>suitableness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>aggressiveness_score</th>\n",
       "      <th>...</th>\n",
       "      <th>zs_Llama-3-8b-chat-hf_suitableness_score</th>\n",
       "      <th>zs_Llama-3-8b-chat-hf_aggressiveness_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_relevance_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_coherence_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_suitableness_score</th>\n",
       "      <th>Mistral-7B-Instruct-v03_aggressiveness_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_relevance_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_coherence_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_suitableness_score</th>\n",
       "      <th>zs_Mistral-7B-Instruct-v03_aggressiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jews have no place here. They are not a part o...</td>\n",
       "      <td>Jews are part of most societies, why should we...</td>\n",
       "      <td>Why do you believe that jews are not part of t...</td>\n",
       "      <td>Questioning</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                                         hatespeech  \\\n",
       "0        0    0.0  Jews have no place here. They are not a part o...   \n",
       "\n",
       "                                       counterspeech  \\\n",
       "0  Jews are part of most societies, why should we...   \n",
       "\n",
       "                             predicted_counterspeech       csType  \\\n",
       "0  Why do you believe that jews are not part of t...  Questioning   \n",
       "\n",
       "   suitableness_score  relevance_score  coherence_score  aggressiveness_score  \\\n",
       "0            1.666667         3.333333         2.333333              1.666667   \n",
       "\n",
       "   ... zs_Llama-3-8b-chat-hf_suitableness_score  \\\n",
       "0  ...                                      3.0   \n",
       "\n",
       "  zs_Llama-3-8b-chat-hf_aggressiveness_score  \\\n",
       "0                                        1.0   \n",
       "\n",
       "  Mistral-7B-Instruct-v03_relevance_score  \\\n",
       "0                                    -1.0   \n",
       "\n",
       "  Mistral-7B-Instruct-v03_coherence_score  \\\n",
       "0                                    -1.0   \n",
       "\n",
       "  Mistral-7B-Instruct-v03_suitableness_score  \\\n",
       "0                                       -1.0   \n",
       "\n",
       "  Mistral-7B-Instruct-v03_aggressiveness_score  \\\n",
       "0                                         -1.0   \n",
       "\n",
       "  zs_Mistral-7B-Instruct-v03_relevance_score  \\\n",
       "0                                        5.0   \n",
       "\n",
       "  zs_Mistral-7B-Instruct-v03_coherence_score  \\\n",
       "0                                        3.0   \n",
       "\n",
       "  zs_Mistral-7B-Instruct-v03_suitableness_score  \\\n",
       "0                                           3.0   \n",
       "\n",
       "   zs_Mistral-7B-Instruct-v03_aggressiveness_score  \n",
       "0                                              2.0  \n",
       "\n",
       "[1 rows x 111 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.read_csv('/home/amey/depository/cs-eval/data/annotations/dataset_metrics_calculated_renamecols.csv')\n",
    "df_results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level_0\n",
      "index\n",
      "hatespeech\n",
      "counterspeech\n",
      "predicted_counterspeech\n",
      "csType\n",
      "suitableness_score\n",
      "relevance_score\n",
      "coherence_score\n",
      "aggressiveness_score\n",
      "annotator\n",
      "source\n",
      "prediction_(prompt_aggressiveness_score)_(gpt-4)\n",
      "prediction_(prompt_relevance_score)_(gpt-4)\n",
      "uuid\n",
      "prediction_(prompt_aggressiveness_score)_(gpt3.5-turbo)\n",
      "prediction_(prompt_coherence_score)_(gpt-3.5-turbo)\n",
      "prediction_(prompt_relevance_score)_(gpt-3.5-turbo)\n",
      "prediction_(prompt_suitableness_score)_(gpt-3.5-turbo)\n",
      "bert_score_(pred_cs, cs)\n",
      "bm25_score_(pred_cs, cs)\n",
      "obscenity_(pred_cs)\n",
      "identity_attack_(pred_cs)\n",
      "insult_(pred_cs)\n",
      "bleu_1_(pred_cs, cs)\n",
      "bleu_2_(pred_cs, cs)\n",
      "rouge_l_(pred_cs, cs)\n",
      "rouge_1_(pred_cs, cs)\n",
      "rouge_2_(pred_cs, cs)\n",
      "meteor_score_(pred_cs, cs)\n",
      "bert_score_(hs, pred_cs)\n",
      "toxicity_(pred_cs)\n",
      "pc_score_(hs, pred_cs)\n",
      "cd_score_(hs, pred_cs)\n",
      "aq_score_(pred_cs)\n",
      "bm25_score_(hs, pred_cs)\n",
      "mauve_score_(hs, pred_cs)\n",
      "mauve_score_(pred_cs, cs)\n",
      "coherence_UniEval\n",
      "relevance_UniEval\n",
      "aggressiveness_UniEval\n",
      "suitableness_UniEval\n",
      "prompt_relevance_score\n",
      "prompt_coherence_score\n",
      "prompt_aggressiveness_score\n",
      "prompt_suitableness_score\n",
      "prediction_gpt-4_relevance_score\n",
      "prediction_gpt-4_coherence_score\n",
      "prediction_gpt-4_suitableness_score\n",
      "prediction_gpt-4_aggressiveness_score\n",
      "id\n",
      "temp_id\n",
      "used_for_interannotations\n",
      "overall_score\n",
      "is_artificially_generated_data\n",
      "gpt-4_relevance_score\n",
      "gpt-4_aggressiveness_score\n",
      "gpt-4_coherence_score\n",
      "gpt-4_suitableness_score\n",
      "gpt-4_suitablness_score\n",
      "gpt-4-zs_relevance_score\n",
      "gpt-4-zs_coherence_score\n",
      "gpt-4-zs_aggressiveness_score\n",
      "gpt-4-zs_suitableness_score\n",
      "gpt-4-zs_relevance_score\"\n",
      "GEVAL-4_relevance_score\n",
      "GEVAL-4_coherence_score\n",
      "GEVAL-4_aggressiveness_score\n",
      "GEVAL-4_suitableness_score\n",
      "GPTScore_relevance_score\n",
      "GPTScore_coherence_score\n",
      "GPTScore_aggressiveness_score\n",
      "GPTScore_suitableness_score\n",
      "bleu_3_(pred_cs, cs)\n",
      "bleu_4_(pred_cs, cs)\n",
      "prediction_gpt-4o_relevance_score\n",
      "prediction_gpt-4o_coherence_score\n",
      "prediction_gpt-4o_suitableness_score\n",
      "prediction_gpt-4o_aggressiveness_score\n",
      "Llama-3-8b-chat-hf_relevance_score\n",
      "Llama-3-8b-chat-hf_coherence_score\n",
      "Llama-3-8b-chat-hf_suitableness_score\n",
      "Llama-3-8b-chat-hf_aggressiveness_score\n",
      "Llama-3-8b-chat-hf_suitableness_score.1\n",
      "Llama-3-8b-chat-hf_relevance_score.1\n",
      "Llama-3-8b-chat-hf_coherence_score.1\n",
      "Llama-3-8b-chat-hf_aggressiveness_score.1\n",
      "Mistral-7B-Instruct-v0.3_relevance_score\n",
      "Mistral-7B-Instruct-v0.3_coherence_score\n",
      "Mistral-7B-Instruct-v0.3_suitableness_score\n",
      "Mistral-7B-Instruct-v0.3_aggressiveness_score\n",
      "Llama-3-8b-chat-hf_relevance_score.\n",
      "Llama-3-8b-chat-hf_coherence_score.\n",
      "Llama-3-8b-chat-hf_suitableness_score.\n",
      "Llama-3-8b-chat-hf_aggressiveness_score.\n",
      "Llama-3-8b-chat-hf_relevance_score.2\n",
      "Llama-3-8b-chat-hf_coherence_score.2\n",
      "Llama-3-8b-chat-hf_suitableness_score.2\n",
      "Llama-3-8b-chat-hf_aggressiveness_score.2\n",
      "zs_Llama-3-8b-chat-hf_relevance_score\n",
      "zs_Llama-3-8b-chat-hf_coherence_score\n",
      "zs_Llama-3-8b-chat-hf_suitableness_score\n",
      "zs_Llama-3-8b-chat-hf_aggressiveness_score\n",
      "Mistral-7B-Instruct-v03_relevance_score\n",
      "Mistral-7B-Instruct-v03_coherence_score\n",
      "Mistral-7B-Instruct-v03_suitableness_score\n",
      "Mistral-7B-Instruct-v03_aggressiveness_score\n",
      "zs_Mistral-7B-Instruct-v03_relevance_score\n",
      "zs_Mistral-7B-Instruct-v03_coherence_score\n",
      "zs_Mistral-7B-Instruct-v03_suitableness_score\n",
      "zs_Mistral-7B-Instruct-v03_aggressiveness_score\n"
     ]
    }
   ],
   "source": [
    "for col in df_results.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: nan\n",
      "P-value: nan\n",
      "Fail to reject the null hypothesis: The difference is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "aspect_name = 'gpt-4_relevance_score'\n",
    "\n",
    "ratings_A = df_results['gpt-4_relevance_score'].values.tolist()\n",
    "ratings_B = df_results['GEVAL-4_relevance_score'].values.tolist()\n",
    "\n",
    "\n",
    "ratings_A = [x for x in ratings_A if x > -1]\n",
    "ratings_B = [x for x in ratings_A if x > -1]\n",
    "\n",
    "# Perform the paired t-test\n",
    "t_stat, p_value = paired_t_test(ratings_A, ratings_B)\n",
    "\n",
    "# Print the results\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Decision based on p-value\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The difference is statistically significant.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The difference is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
